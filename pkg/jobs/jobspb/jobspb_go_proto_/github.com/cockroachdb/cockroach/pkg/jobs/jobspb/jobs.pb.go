// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: jobs/jobspb/jobs.proto

package jobspb

import (
	bytes "bytes"
	encoding_binary "encoding/binary"
	fmt "fmt"
	github_com_cockroachdb_cockroach_pkg_base "github.com/cockroachdb/cockroach/pkg/base"
	clusterversion "github.com/cockroachdb/cockroach/pkg/clusterversion"
	kvpb "github.com/cockroachdb/cockroach/pkg/kv/kvpb"
	mtinfopb "github.com/cockroachdb/cockroach/pkg/multitenant/mtinfopb"
	github_com_cockroachdb_cockroach_pkg_roachpb "github.com/cockroachdb/cockroach/pkg/roachpb"
	roachpb "github.com/cockroachdb/cockroach/pkg/roachpb"
	github_com_cockroachdb_cockroach_pkg_security_username "github.com/cockroachdb/cockroach/pkg/security/username"
	catpb "github.com/cockroachdb/cockroach/pkg/sql/catalog/catpb"
	github_com_cockroachdb_cockroach_pkg_sql_catalog_catpb "github.com/cockroachdb/cockroach/pkg/sql/catalog/catpb"
	descpb "github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb"
	github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb "github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb"
	externalpb "github.com/cockroachdb/cockroach/pkg/sql/catalog/externalcatalog/externalpb"
	github_com_cockroachdb_cockroach_pkg_sql_sem_tree "github.com/cockroachdb/cockroach/pkg/sql/sem/tree"
	sessiondatapb "github.com/cockroachdb/cockroach/pkg/sql/sessiondatapb"
	hlc "github.com/cockroachdb/cockroach/pkg/util/hlc"
	github_com_cockroachdb_cockroach_pkg_util_tracing_tracingpb "github.com/cockroachdb/cockroach/pkg/util/tracing/tracingpb"
	tracingpb "github.com/cockroachdb/cockroach/pkg/util/tracing/tracingpb"
	github_com_cockroachdb_cockroach_pkg_util_uuid "github.com/cockroachdb/cockroach/pkg/util/uuid"
	errorspb "github.com/cockroachdb/errors/errorspb"
	_ "github.com/gogo/protobuf/gogoproto"
	proto "github.com/gogo/protobuf/proto"
	github_com_gogo_protobuf_sortkeys "github.com/gogo/protobuf/sortkeys"
	_ "github.com/gogo/protobuf/types"
	github_com_gogo_protobuf_types "github.com/gogo/protobuf/types"
	io "io"
	math "math"
	math_bits "math/bits"
	slices "slices"
	time "time"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf
var _ = time.Kitchen

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

type EncryptionMode int32

const (
	EncryptionMode_Passphrase EncryptionMode = 0
	EncryptionMode_KMS        EncryptionMode = 1
	EncryptionMode_None       EncryptionMode = 2
)

var EncryptionMode_name = map[int32]string{
	0: "Passphrase",
	1: "KMS",
	2: "None",
}

var EncryptionMode_value = map[string]int32{
	"Passphrase": 0,
	"KMS":        1,
	"None":       2,
}

func (x EncryptionMode) String() string {
	return proto.EnumName(EncryptionMode_name, int32(x))
}

func (EncryptionMode) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{0}
}

type Status int32

const (
	Status_DRAINING_NAMES       Status = 0
	Status_WAIT_FOR_GC_INTERVAL Status = 1
	Status_ROCKSDB_COMPACTION   Status = 2
	Status_DONE                 Status = 10
)

var Status_name = map[int32]string{
	0:  "DRAINING_NAMES",
	1:  "WAIT_FOR_GC_INTERVAL",
	2:  "ROCKSDB_COMPACTION",
	10: "DONE",
}

var Status_value = map[string]int32{
	"DRAINING_NAMES":       0,
	"WAIT_FOR_GC_INTERVAL": 1,
	"ROCKSDB_COMPACTION":   2,
	"DONE":                 10,
}

func (x Status) String() string {
	return proto.EnumName(Status_name, int32(x))
}

func (Status) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{1}
}

type Type int32

const (
	TypeUnspecified     Type = 0
	TypeBackup          Type = 1
	TypeRestore         Type = 2
	TypeSchemaChange    Type = 3
	TypeImport          Type = 4
	TypeChangefeed      Type = 5
	TypeCreateStats     Type = 6
	TypeAutoCreateStats Type = 7
	TypeSchemaChangeGC  Type = 8
	// We can't name this TYPE_SCHEMA_CHANGE due to how proto generates actual
	// names for this enum, which cause a conflict with the SCHEMA_CHANGE entry.
	TypeTypeSchemaChange             Type = 9
	TypeReplicationStreamIngestion   Type = 10
	TypeNewSchemaChange              Type = 11
	TypeMigration                    Type = 12
	TypeAutoSpanConfigReconciliation Type = 13
	TypeAutoSQLStatsCompaction       Type = 14
	TypeReplicationStreamProducer    Type = 15
	TypeRowLevelTTL                  Type = 16
	TypeAutoSchemaTelemetry          Type = 17
	TypeKeyVisualizer                Type = 18
	TypePollJobsStats                Type = 19
	TypeAutoConfigRunner             Type = 20
	TypeAutoConfigEnvRunner          Type = 21
	TypeAutoConfigTask               Type = 22
	TypeAutoUpdateSQLActivity        Type = 23
	TypeMVCCStatisticsUpdate         Type = 24
	TypeImportRollback               Type = 25
	TypeHistoryRetention             Type = 26
	TypeLogicalReplication           Type = 27
	TypeAutoCreatePartialStats       Type = 28
	TypeUpdateTableMetadataCache     Type = 29
	TypeStandbyReadTSPoller          Type = 30
	TypeSQLActivityFlush             Type = 31
	TypeHotRangesLogger              Type = 32
	TypeInspect                      Type = 33
)

var Type_name = map[int32]string{
	0:  "UNSPECIFIED",
	1:  "BACKUP",
	2:  "RESTORE",
	3:  "SCHEMA_CHANGE",
	4:  "IMPORT",
	5:  "CHANGEFEED",
	6:  "CREATE_STATS",
	7:  "AUTO_CREATE_STATS",
	8:  "SCHEMA_CHANGE_GC",
	9:  "TYPEDESC_SCHEMA_CHANGE",
	10: "REPLICATION_STREAM_INGESTION",
	11: "NEW_SCHEMA_CHANGE",
	12: "MIGRATION",
	13: "AUTO_SPAN_CONFIG_RECONCILIATION",
	14: "AUTO_SQL_STATS_COMPACTION",
	15: "REPLICATION_STREAM_PRODUCER",
	16: "ROW_LEVEL_TTL",
	17: "AUTO_SCHEMA_TELEMETRY",
	18: "KEY_VISUALIZER",
	19: "POLL_JOBS_STATS",
	20: "AUTO_CONFIG_RUNNER",
	21: "AUTO_CONFIG_ENV_RUNNER",
	22: "AUTO_CONFIG_TASK",
	23: "AUTO_UPDATE_SQL_ACTIVITY",
	24: "MVCC_STATISTICS_UPDATE",
	25: "IMPORT_ROLLBACK",
	26: "HISTORY_RETENTION",
	27: "LOGICAL_REPLICATION",
	28: "AUTO_CREATE_PARTIAL_STATS",
	29: "UPDATE_TABLE_METADATA_CACHE",
	30: "STANDBY_READ_TS_POLLER",
	31: "SQL_ACTIVITY_FLUSH",
	32: "HOT_RANGES_LOGGER",
	33: "INSPECT",
}

var Type_value = map[string]int32{
	"UNSPECIFIED":                     0,
	"BACKUP":                          1,
	"RESTORE":                         2,
	"SCHEMA_CHANGE":                   3,
	"IMPORT":                          4,
	"CHANGEFEED":                      5,
	"CREATE_STATS":                    6,
	"AUTO_CREATE_STATS":               7,
	"SCHEMA_CHANGE_GC":                8,
	"TYPEDESC_SCHEMA_CHANGE":          9,
	"REPLICATION_STREAM_INGESTION":    10,
	"NEW_SCHEMA_CHANGE":               11,
	"MIGRATION":                       12,
	"AUTO_SPAN_CONFIG_RECONCILIATION": 13,
	"AUTO_SQL_STATS_COMPACTION":       14,
	"REPLICATION_STREAM_PRODUCER":     15,
	"ROW_LEVEL_TTL":                   16,
	"AUTO_SCHEMA_TELEMETRY":           17,
	"KEY_VISUALIZER":                  18,
	"POLL_JOBS_STATS":                 19,
	"AUTO_CONFIG_RUNNER":              20,
	"AUTO_CONFIG_ENV_RUNNER":          21,
	"AUTO_CONFIG_TASK":                22,
	"AUTO_UPDATE_SQL_ACTIVITY":        23,
	"MVCC_STATISTICS_UPDATE":          24,
	"IMPORT_ROLLBACK":                 25,
	"HISTORY_RETENTION":               26,
	"LOGICAL_REPLICATION":             27,
	"AUTO_CREATE_PARTIAL_STATS":       28,
	"UPDATE_TABLE_METADATA_CACHE":     29,
	"STANDBY_READ_TS_POLLER":          30,
	"SQL_ACTIVITY_FLUSH":              31,
	"HOT_RANGES_LOGGER":               32,
	"INSPECT":                         33,
}

func (Type) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{2}
}

type EncryptionInfo_Scheme int32

const (
	EncryptionInfo_AES256GCM EncryptionInfo_Scheme = 0
)

var EncryptionInfo_Scheme_name = map[int32]string{
	0: "AES256GCM",
}

var EncryptionInfo_Scheme_value = map[string]int32{
	"AES256GCM": 0,
}

func (x EncryptionInfo_Scheme) String() string {
	return proto.EnumName(EncryptionInfo_Scheme_name, int32(x))
}

func (EncryptionInfo_Scheme) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{1, 0}
}

type LogicalReplicationDetails_ApplyMode int32

const (
	LogicalReplicationDetails_Immediate LogicalReplicationDetails_ApplyMode = 0
	LogicalReplicationDetails_Validated LogicalReplicationDetails_ApplyMode = 1
)

var LogicalReplicationDetails_ApplyMode_name = map[int32]string{
	0: "Immediate",
	1: "Validated",
}

var LogicalReplicationDetails_ApplyMode_value = map[string]int32{
	"Immediate": 0,
	"Validated": 1,
}

func (x LogicalReplicationDetails_ApplyMode) String() string {
	return proto.EnumName(LogicalReplicationDetails_ApplyMode_name, int32(x))
}

func (LogicalReplicationDetails_ApplyMode) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{7, 0}
}

type LogicalReplicationDetails_Discard int32

const (
	LogicalReplicationDetails_DiscardNothing              LogicalReplicationDetails_Discard = 0
	LogicalReplicationDetails_DiscardCDCIgnoredTTLDeletes LogicalReplicationDetails_Discard = 1
	LogicalReplicationDetails_DiscardAllDeletes           LogicalReplicationDetails_Discard = 2
)

var LogicalReplicationDetails_Discard_name = map[int32]string{
	0: "DiscardNothing",
	1: "DiscardCDCIgnoredTTLDeletes",
	2: "DiscardAllDeletes",
}

var LogicalReplicationDetails_Discard_value = map[string]int32{
	"DiscardNothing":              0,
	"DiscardCDCIgnoredTTLDeletes": 1,
	"DiscardAllDeletes":           2,
}

func (x LogicalReplicationDetails_Discard) String() string {
	return proto.EnumName(LogicalReplicationDetails_Discard_name, int32(x))
}

func (LogicalReplicationDetails_Discard) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{7, 1}
}

type LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution int32

const (
	LogicalReplicationDetails_DefaultConflictResolution_LWW LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution = 0
	LogicalReplicationDetails_DefaultConflictResolution_DLQ LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution = 1
	LogicalReplicationDetails_DefaultConflictResolution_UDF LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution = 2
)

var LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution_name = map[int32]string{
	0: "LWW",
	1: "DLQ",
	2: "UDF",
}

var LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution_value = map[string]int32{
	"LWW": 0,
	"DLQ": 1,
	"UDF": 2,
}

func (x LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution) String() string {
	return proto.EnumName(LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution_name, int32(x))
}

func (LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{7, 1, 0}
}

type StreamReplicationProgress_StreamIngestionStatus int32

const (
	StreamReplicationProgress_NOT_FINISHED            StreamReplicationProgress_StreamIngestionStatus = 0
	StreamReplicationProgress_FINISHED_SUCCESSFULLY   StreamReplicationProgress_StreamIngestionStatus = 1
	StreamReplicationProgress_FINISHED_UNSUCCESSFULLY StreamReplicationProgress_StreamIngestionStatus = 2
)

var StreamReplicationProgress_StreamIngestionStatus_name = map[int32]string{
	0: "NOT_FINISHED",
	1: "FINISHED_SUCCESSFULLY",
	2: "FINISHED_UNSUCCESSFULLY",
}

var StreamReplicationProgress_StreamIngestionStatus_value = map[string]int32{
	"NOT_FINISHED":            0,
	"FINISHED_SUCCESSFULLY":   1,
	"FINISHED_UNSUCCESSFULLY": 2,
}

func (x StreamReplicationProgress_StreamIngestionStatus) String() string {
	return proto.EnumName(StreamReplicationProgress_StreamIngestionStatus_name, int32(x))
}

func (StreamReplicationProgress_StreamIngestionStatus) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{10, 0}
}

type SchedulePTSChainingRecord_PTSAction int32

const (
	SchedulePTSChainingRecord_UPDATE  SchedulePTSChainingRecord_PTSAction = 0
	SchedulePTSChainingRecord_RELEASE SchedulePTSChainingRecord_PTSAction = 1
)

var SchedulePTSChainingRecord_PTSAction_name = map[int32]string{
	0: "UPDATE",
	1: "RELEASE",
}

var SchedulePTSChainingRecord_PTSAction_value = map[string]int32{
	"UPDATE":  0,
	"RELEASE": 1,
}

func (x SchedulePTSChainingRecord_PTSAction) String() string {
	return proto.EnumName(SchedulePTSChainingRecord_PTSAction_name, int32(x))
}

func (SchedulePTSChainingRecord_PTSAction) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{11, 0}
}

type SchemaChangeGCProgress_Status int32

const (
	// Waiting for the index/table to expire before issuing ClearRange
	// requests over the table span.
	//
	// TODO(ajwerner): Remove this in 23.1.
	SchemaChangeGCProgress_WAITING_FOR_CLEAR SchemaChangeGCProgress_Status = 0
	// The GC TTL has expired. This element is marked for imminent deletion
	// or is being cleared.
	//
	// TODO(ajwerner): Remove this in 23.1.
	SchemaChangeGCProgress_CLEARING SchemaChangeGCProgress_Status = 1
	// This element has been deleted. The job is done when all elements are in
	// this state.
	SchemaChangeGCProgress_CLEARED SchemaChangeGCProgress_Status = 2
	// The index has been deleted, but we need to wait for the data to be
	// removed before the relevant descriptors and zone configs can be deleted.
	SchemaChangeGCProgress_WAITING_FOR_MVCC_GC SchemaChangeGCProgress_Status = 3
)

var SchemaChangeGCProgress_Status_name = map[int32]string{
	0: "WAITING_FOR_CLEAR",
	1: "CLEARING",
	2: "CLEARED",
	3: "WAITING_FOR_MVCC_GC",
}

var SchemaChangeGCProgress_Status_value = map[string]int32{
	"WAITING_FOR_CLEAR":   0,
	"CLEARING":            1,
	"CLEARED":             2,
	"WAITING_FOR_MVCC_GC": 3,
}

func (x SchemaChangeGCProgress_Status) String() string {
	return proto.EnumName(SchemaChangeGCProgress_Status_name, int32(x))
}

func (SchemaChangeGCProgress_Status) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{36, 0}
}

type ChangefeedTargetSpecification_TargetType int32

const (
	// The primary index of the table with table_id descriptor id.
	// Fail if there are ever multiple column families.
	ChangefeedTargetSpecification_PRIMARY_FAMILY_ONLY ChangefeedTargetSpecification_TargetType = 0
	// The primary index of the table with table_id descriptor id.
	// Each column family gets its own record schema and events.
	ChangefeedTargetSpecification_EACH_FAMILY ChangefeedTargetSpecification_TargetType = 1
	// Column family family_name of table table_id.
	ChangefeedTargetSpecification_COLUMN_FAMILY ChangefeedTargetSpecification_TargetType = 2
	ChangefeedTargetSpecification_DATABASE      ChangefeedTargetSpecification_TargetType = 3
)

var ChangefeedTargetSpecification_TargetType_name = map[int32]string{
	0: "PRIMARY_FAMILY_ONLY",
	1: "EACH_FAMILY",
	2: "COLUMN_FAMILY",
	3: "DATABASE",
}

var ChangefeedTargetSpecification_TargetType_value = map[string]int32{
	"PRIMARY_FAMILY_ONLY": 0,
	"EACH_FAMILY":         1,
	"COLUMN_FAMILY":       2,
	"DATABASE":            3,
}

func (x ChangefeedTargetSpecification_TargetType) String() string {
	return proto.EnumName(ChangefeedTargetSpecification_TargetType_name, int32(x))
}

func (ChangefeedTargetSpecification_TargetType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{38, 0}
}

type ResolvedSpan_BoundaryType int32

const (
	// NONE indicates that this resolved span does not correspond to a
	// boundary.
	ResolvedSpan_NONE ResolvedSpan_BoundaryType = 0
	// BACKFILL indicates that this resolved span corresponds to a boundary
	// requiring a backfill internally and perhaps indicates the need for a
	// protected timestamp.
	ResolvedSpan_BACKFILL ResolvedSpan_BoundaryType = 1
	// EXIT indicates that this resolved span corresponds to a boundary which
	// should result in the changefeed exiting.
	ResolvedSpan_EXIT ResolvedSpan_BoundaryType = 2
	// RESTART indicates that this resolved span corresponds to a boundary which
	// should result in the changefeed restarting.
	ResolvedSpan_RESTART ResolvedSpan_BoundaryType = 3
)

var ResolvedSpan_BoundaryType_name = map[int32]string{
	0: "NONE",
	1: "BACKFILL",
	2: "EXIT",
	3: "RESTART",
}

var ResolvedSpan_BoundaryType_value = map[string]int32{
	"NONE":     0,
	"BACKFILL": 1,
	"EXIT":     2,
	"RESTART":  3,
}

func (x ResolvedSpan_BoundaryType) String() string {
	return proto.EnumName(ResolvedSpan_BoundaryType_name, int32(x))
}

func (ResolvedSpan_BoundaryType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{40, 0}
}

type InspectDetails_Check_InspectCheckType int32

const (
	// UNSPECIFIED indicates an unset check type. This is invalid.
	InspectCheckUnspecified InspectDetails_Check_InspectCheckType = 0
	// INDEX_CONSISTENCY performs validation between primary and secondary indexes
	// to detect missing or dangling index entries.
	InspectCheckIndexConsistency InspectDetails_Check_InspectCheckType = 1
)

var InspectDetails_Check_InspectCheckType_name = map[int32]string{
	0: "INSPECT_CHECK_UNSPECIFIED",
	1: "INSPECT_CHECK_INDEX_CONSISTENCY",
}

var InspectDetails_Check_InspectCheckType_value = map[string]int32{
	"INSPECT_CHECK_UNSPECIFIED":       0,
	"INSPECT_CHECK_INDEX_CONSISTENCY": 1,
}

func (InspectDetails_Check_InspectCheckType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{70, 0, 0}
}

type UpdateTableMetadataCacheProgress_Status int32

const (
	UpdateTableMetadataCacheProgress_NOT_RUNNING UpdateTableMetadataCacheProgress_Status = 0
	UpdateTableMetadataCacheProgress_RUNNING     UpdateTableMetadataCacheProgress_Status = 1
)

var UpdateTableMetadataCacheProgress_Status_name = map[int32]string{
	0: "NOT_RUNNING",
	1: "RUNNING",
}

var UpdateTableMetadataCacheProgress_Status_value = map[string]int32{
	"NOT_RUNNING": 0,
	"RUNNING":     1,
}

func (x UpdateTableMetadataCacheProgress_Status) String() string {
	return proto.EnumName(UpdateTableMetadataCacheProgress_Status_name, int32(x))
}

func (UpdateTableMetadataCacheProgress_Status) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{72, 0}
}

// BackupEncryptionOptions stores information resolved during the BACKUP/RESTORE
// planning stage, and by the BACKUP/RESTORE job to encrypt or decrypt BACKUP
// data and manifest files.
type BackupEncryptionOptions struct {
	// Key specifies the key to use for encryption or decryption.
	Key  []byte         `protobuf:"bytes,1,opt,name=key,proto3" json:"key,omitempty"`
	Mode EncryptionMode `protobuf:"varint,2,opt,name=mode,proto3,enum=cockroach.sql.jobs.jobspb.EncryptionMode" json:"mode,omitempty"`
	// KMSInfo specifies the KMS and encrypted DataKey pair to use for
	// encryption or decryption when mode == KMS.
	KMSInfo       *BackupEncryptionOptions_KMSInfo `protobuf:"bytes,3,opt,name=kms_info,json=kmsInfo,proto3" json:"kms_info,omitempty"`
	RawPassphrase string                           `protobuf:"bytes,4,opt,name=raw_passphrase,json=rawPassphrase,proto3" json:"raw_passphrase,omitempty"`
	RawKmsUris    []string                         `protobuf:"bytes,5,rep,name=raw_kms_uris,json=rawKmsUris,proto3" json:"raw_kms_uris,omitempty"`
}

func (m *BackupEncryptionOptions) Reset()         { *m = BackupEncryptionOptions{} }
func (m *BackupEncryptionOptions) String() string { return proto.CompactTextString(m) }
func (*BackupEncryptionOptions) ProtoMessage()    {}
func (*BackupEncryptionOptions) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{0}
}
func (m *BackupEncryptionOptions) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *BackupEncryptionOptions) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *BackupEncryptionOptions) XXX_Merge(src proto.Message) {
	xxx_messageInfo_BackupEncryptionOptions.Merge(m, src)
}
func (m *BackupEncryptionOptions) XXX_Size() int {
	return m.Size()
}
func (m *BackupEncryptionOptions) XXX_DiscardUnknown() {
	xxx_messageInfo_BackupEncryptionOptions.DiscardUnknown(m)
}

var xxx_messageInfo_BackupEncryptionOptions proto.InternalMessageInfo

type BackupEncryptionOptions_KMSInfo struct {
	Uri              string `protobuf:"bytes,1,opt,name=uri,proto3" json:"uri,omitempty"`
	EncryptedDataKey []byte `protobuf:"bytes,2,opt,name=encrypted_data_key,json=encryptedDataKey,proto3" json:"encrypted_data_key,omitempty"`
}

func (m *BackupEncryptionOptions_KMSInfo) Reset()         { *m = BackupEncryptionOptions_KMSInfo{} }
func (m *BackupEncryptionOptions_KMSInfo) String() string { return proto.CompactTextString(m) }
func (*BackupEncryptionOptions_KMSInfo) ProtoMessage()    {}
func (*BackupEncryptionOptions_KMSInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{0, 0}
}
func (m *BackupEncryptionOptions_KMSInfo) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *BackupEncryptionOptions_KMSInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *BackupEncryptionOptions_KMSInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_BackupEncryptionOptions_KMSInfo.Merge(m, src)
}
func (m *BackupEncryptionOptions_KMSInfo) XXX_Size() int {
	return m.Size()
}
func (m *BackupEncryptionOptions_KMSInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_BackupEncryptionOptions_KMSInfo.DiscardUnknown(m)
}

var xxx_messageInfo_BackupEncryptionOptions_KMSInfo proto.InternalMessageInfo

// EncryptionInfo is stored IN PLAINTEXT along side collections of encrypted
// files stored outside of cockroach, for example by BACKUP/RESTORE.
type EncryptionInfo struct {
	Scheme EncryptionInfo_Scheme `protobuf:"varint,1,opt,name=scheme,proto3,enum=cockroach.sql.jobs.jobspb.EncryptionInfo_Scheme" json:"scheme,omitempty"`
	Salt   []byte                `protobuf:"bytes,2,opt,name=salt,proto3" json:"salt,omitempty"`
	// EncryptedDataKeyByKMSMasterKeyID is a mapping from the hashed master key
	// identifier of a KMS to the encrypted version of the DataKey obtained from
	// that KMS.
	EncryptedDataKeyByKMSMasterKeyID map[string][]byte `protobuf:"bytes,3,rep,name=encryptedDataKeyByKMSMasterKeyID,proto3" json:"encryptedDataKeyByKMSMasterKeyID,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
}

func (m *EncryptionInfo) Reset()         { *m = EncryptionInfo{} }
func (m *EncryptionInfo) String() string { return proto.CompactTextString(m) }
func (*EncryptionInfo) ProtoMessage()    {}
func (*EncryptionInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{1}
}
func (m *EncryptionInfo) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *EncryptionInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *EncryptionInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_EncryptionInfo.Merge(m, src)
}
func (m *EncryptionInfo) XXX_Size() int {
	return m.Size()
}
func (m *EncryptionInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_EncryptionInfo.DiscardUnknown(m)
}

var xxx_messageInfo_EncryptionInfo proto.InternalMessageInfo

type StreamIngestionDetails struct {
	// SourceClusterConnUri is the user-provided address of the source cluster.
	SourceClusterConnUri string `protobuf:"bytes,1,opt,name=source_cluster_conn_uri,json=sourceClusterConnUri,proto3" json:"source_cluster_conn_uri,omitempty"`
	StreamID             uint64 `protobuf:"varint,4,opt,name=stream_id,json=streamId,proto3" json:"stream_id,omitempty"`
	// Span is the keyspan into which this job will ingest KVs.
	//
	// The stream should emit all changes for a given span, and no changes outside
	// a span. Note that KVs received from the stream may need to be re-keyed into
	// this span.
	Span roachpb.Span `protobuf:"bytes,2,opt,name=span,proto3" json:"span"`
	// Stream of tenant data will be ingested as a new tenant with 'new_tenant_id'.
	DestinationTenantID roachpb.TenantID                                        `protobuf:"bytes,7,opt,name=destination_tenant_id,json=destinationTenantId,proto3" json:"destination_tenant_id"`
	SourceTenantName    github_com_cockroachdb_cockroach_pkg_roachpb.TenantName `protobuf:"bytes,8,opt,name=source_tenant_name,json=sourceTenantName,proto3,customtype=github.com/cockroachdb/cockroach/pkg/roachpb.TenantName" json:"source_tenant_name"`
	// ID of the protected timestamp record that protects the destination tenant's
	// keyspan from GC while it is being replicated into.
	ProtectedTimestampRecordID *github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,10,opt,name=protected_timestamp_record_id,json=protectedTimestampRecordId,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"protected_timestamp_record_id,omitempty"`
	// ReplicationTTLSeconds specifies the maximum age of a value relative to the
	// replication job's frontier timestamp, before the value is made eligible for
	// garbage collection. Note, only older versions of values are eligible for
	// GC. All values newer than this maximum age will be protected from GC by a
	// protected timestamp record managed by the replication job.
	//
	// In other words, the `replication job's frontier timestamp - ReplicationTTLSeconds`
	// is the earliest timestamp that the replication job can be cut-over to.
	ReplicationTTLSeconds int32 `protobuf:"varint,11,opt,name=replication_ttl_seconds,json=replicationTtlSeconds,proto3" json:"replication_ttl_seconds,omitempty"`
	// ReplicationStartTime is the initial timestamp from which the replication
	// producer job will begin streaming MVCC revisions. This timestamp is picked
	// once when the replication producer job is created, and is never updated
	// through the lifetime of a replication stream. This will be the timestamp as
	// of which each partition will perform its initial rangefeed scan on the
	// source cluster.
	ReplicationStartTime hlc.Timestamp                                       `protobuf:"bytes,12,opt,name=replication_start_time,json=replicationStartTime,proto3" json:"replication_start_time"`
	SourceTenantID       roachpb.TenantID                                    `protobuf:"bytes,13,opt,name=source_tenant_id,json=sourceTenantId,proto3" json:"source_tenant_id"`
	SourceClusterID      github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,14,opt,name=source_cluster_id,json=sourceClusterId,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"source_cluster_id"`
	// If ReaderTenantID is non-zero, this ID is associated with the reader tenant
	// from which users can run read queries.
	ReadTenantID roachpb.TenantID `protobuf:"bytes,15,opt,name=read_tenant_id,json=readTenantId,proto3" json:"read_tenant_id"`
}

func (m *StreamIngestionDetails) Reset()         { *m = StreamIngestionDetails{} }
func (m *StreamIngestionDetails) String() string { return proto.CompactTextString(m) }
func (*StreamIngestionDetails) ProtoMessage()    {}
func (*StreamIngestionDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{2}
}
func (m *StreamIngestionDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *StreamIngestionDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *StreamIngestionDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_StreamIngestionDetails.Merge(m, src)
}
func (m *StreamIngestionDetails) XXX_Size() int {
	return m.Size()
}
func (m *StreamIngestionDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_StreamIngestionDetails.DiscardUnknown(m)
}

var xxx_messageInfo_StreamIngestionDetails proto.InternalMessageInfo

type StreamIngestionCheckpoint struct {
	ResolvedSpans []ResolvedSpan `protobuf:"bytes,1,rep,name=resolved_spans,json=resolvedSpans,proto3" json:"resolved_spans"`
}

func (m *StreamIngestionCheckpoint) Reset()         { *m = StreamIngestionCheckpoint{} }
func (m *StreamIngestionCheckpoint) String() string { return proto.CompactTextString(m) }
func (*StreamIngestionCheckpoint) ProtoMessage()    {}
func (*StreamIngestionCheckpoint) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{3}
}
func (m *StreamIngestionCheckpoint) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *StreamIngestionCheckpoint) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *StreamIngestionCheckpoint) XXX_Merge(src proto.Message) {
	xxx_messageInfo_StreamIngestionCheckpoint.Merge(m, src)
}
func (m *StreamIngestionCheckpoint) XXX_Size() int {
	return m.Size()
}
func (m *StreamIngestionCheckpoint) XXX_DiscardUnknown() {
	xxx_messageInfo_StreamIngestionCheckpoint.DiscardUnknown(m)
}

var xxx_messageInfo_StreamIngestionCheckpoint proto.InternalMessageInfo

type StreamIngestionProgress struct {
	// CutoverTime is set to signal to the stream ingestion job to complete its
	// ingestion. This involves stopping any subsequent ingestion, and rolling
	// back any additional ingested data, to bring the ingested cluster to a
	// consistent state as of the CutoverTime.
	CutoverTime hlc.Timestamp `protobuf:"bytes,1,opt,name=cutover_time,json=cutoverTime,proto3" json:"cutover_time"`
	// ReplicatedTime is the ingestion frontier. This is the canonical
	// value of the frontier. The HighWater in the job progress is for
	// informational purposes only.
	ReplicatedTime hlc.Timestamp `protobuf:"bytes,7,opt,name=replicated_time,json=replicatedTime,proto3" json:"replicated_time"`
	// ReplicationStatus is the status of the tenant that has a replication
	// (ingestion) job.
	ReplicationStatus ReplicationStatus `protobuf:"varint,6,opt,name=replication_status,json=replicationStatus,proto3,customtype=ReplicationStatus" json:"replication_status"`
	// Checkpoint stores a set of resolved spans denoting completed ingestion progress
	Checkpoint StreamIngestionCheckpoint `protobuf:"bytes,4,opt,name=checkpoint,proto3" json:"checkpoint"`
	// PartitionPgUris are the source cluster addresses read from the latest
	// topology.
	PartitionConnUris []string `protobuf:"bytes,5,rep,name=partition_conn_uris,json=partitionConnUris,proto3" json:"partition_conn_uris,omitempty"`
	// RemainingCutoverSpans contains the spans that still need to be cutover once
	// the cutover time gets set.
	RemainingCutoverSpans []roachpb.Span `protobuf:"bytes,8,rep,name=remaining_cutover_spans,json=remainingCutoverSpans,proto3" json:"remaining_cutover_spans"`
	// InitialSplitComplete is true if the stream ingestion job has
	// already split the tenant's keyspace according to the plan from
	// the source tenant.
	InitialSplitComplete bool `protobuf:"varint,9,opt,name=initial_split_complete,json=initialSplitComplete,proto3" json:"initial_split_complete,omitempty"`
	// InitialRevertRequiredd is true if the stream requires an initial revert to
	// the start time before it can continue (e.g. when reusing a tenant's data).
	InitialRevertRequired bool `protobuf:"varint,10,opt,name=initial_revert_required,json=initialRevertRequired,proto3" json:"initial_revert_required,omitempty"`
	// InitialRevertTo is a timestamp to which the initial revert should be done
	// if different than ReplicatedTime.
	InitialRevertTo         hlc.Timestamp `protobuf:"bytes,11,opt,name=initial_revert_to,json=initialRevertTo,proto3" json:"initial_revert_to"`
	ReplicatedTimeAtCutover hlc.Timestamp `protobuf:"bytes,12,opt,name=replicated_time_at_cutover,json=replicatedTimeAtCutover,proto3" json:"replicated_time_at_cutover"`
}

func (m *StreamIngestionProgress) Reset()         { *m = StreamIngestionProgress{} }
func (m *StreamIngestionProgress) String() string { return proto.CompactTextString(m) }
func (*StreamIngestionProgress) ProtoMessage()    {}
func (*StreamIngestionProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{4}
}
func (m *StreamIngestionProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *StreamIngestionProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *StreamIngestionProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_StreamIngestionProgress.Merge(m, src)
}
func (m *StreamIngestionProgress) XXX_Size() int {
	return m.Size()
}
func (m *StreamIngestionProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_StreamIngestionProgress.DiscardUnknown(m)
}

var xxx_messageInfo_StreamIngestionProgress proto.InternalMessageInfo

type HistoryRetentionDetails struct {
	// ID of the protected timestamp record this job is managing.
	ProtectedTimestampRecordID github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,1,opt,name=protected_timestamp_record_id,json=protectedTimestampRecordId,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"protected_timestamp_record_id"`
	// ExpirationWindow specifies the length of time since the last
	// heartbeat that the protected timestamp record is valid for.
	ExpirationWindow time.Duration `protobuf:"varint,4,opt,name=expiration_window,json=expirationWindow,proto3,casttype=time.Duration" json:"expiration_window,omitempty"`
}

func (m *HistoryRetentionDetails) Reset()         { *m = HistoryRetentionDetails{} }
func (m *HistoryRetentionDetails) String() string { return proto.CompactTextString(m) }
func (*HistoryRetentionDetails) ProtoMessage()    {}
func (*HistoryRetentionDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{5}
}
func (m *HistoryRetentionDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *HistoryRetentionDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *HistoryRetentionDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_HistoryRetentionDetails.Merge(m, src)
}
func (m *HistoryRetentionDetails) XXX_Size() int {
	return m.Size()
}
func (m *HistoryRetentionDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_HistoryRetentionDetails.DiscardUnknown(m)
}

var xxx_messageInfo_HistoryRetentionDetails proto.InternalMessageInfo

type HistoryRetentionProgress struct {
	LastHeartbeatTime time.Time `protobuf:"bytes,1,opt,name=last_heartbeat_time,json=lastHeartbeatTime,proto3,stdtime" json:"last_heartbeat_time"`
}

func (m *HistoryRetentionProgress) Reset()         { *m = HistoryRetentionProgress{} }
func (m *HistoryRetentionProgress) String() string { return proto.CompactTextString(m) }
func (*HistoryRetentionProgress) ProtoMessage()    {}
func (*HistoryRetentionProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{6}
}
func (m *HistoryRetentionProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *HistoryRetentionProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *HistoryRetentionProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_HistoryRetentionProgress.Merge(m, src)
}
func (m *HistoryRetentionProgress) XXX_Size() int {
	return m.Size()
}
func (m *HistoryRetentionProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_HistoryRetentionProgress.DiscardUnknown(m)
}

var xxx_messageInfo_HistoryRetentionProgress proto.InternalMessageInfo

type LogicalReplicationDetails struct {
	// SourceClusterConnUri is the user-provided address of the source cluster.
	SourceClusterConnUri string `protobuf:"bytes,1,opt,name=source_cluster_conn_uri,json=sourceClusterConnUri,proto3" json:"source_cluster_conn_uri,omitempty"`
	// TableNames is the original list of source table names given by the user.
	TableNames       []string                                    `protobuf:"bytes,2,rep,name=table_names,json=tableNames,proto3" json:"table_names,omitempty"`
	ReplicationPairs []LogicalReplicationDetails_ReplicationPair `protobuf:"bytes,3,rep,name=replication_pairs,json=replicationPairs,proto3" json:"replication_pairs"`
	StreamID         uint64                                      `protobuf:"varint,4,opt,name=stream_id,json=streamId,proto3" json:"stream_id,omitempty"`
	// ReplicationStartTime is the initial timestamp from which the replication
	// producer job will begin streaming MVCC revisions. This timestamp is picked
	// once when the replication producer job is created, and is never updated
	// through the lifetime of a replication stream. This will be the timestamp as
	// of which each partition will perform its initial rangefeed scan on the
	// source cluster.
	ReplicationStartTime      hlc.Timestamp                                       `protobuf:"bytes,5,opt,name=replication_start_time,json=replicationStartTime,proto3" json:"replication_start_time"`
	SourceClusterID           github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,6,opt,name=source_cluster_id,json=sourceClusterId,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"source_cluster_id"`
	DefaultConflictResolution LogicalReplicationDetails_DefaultConflictResolution `protobuf:"bytes,7,opt,name=default_conflict_resolution,json=defaultConflictResolution,proto3" json:"default_conflict_resolution"`
	Mode                      LogicalReplicationDetails_ApplyMode                 `protobuf:"varint,9,opt,name=mode,proto3,enum=cockroach.sql.jobs.jobspb.LogicalReplicationDetails_ApplyMode" json:"mode,omitempty"`
	MetricsLabel              string                                              `protobuf:"bytes,10,opt,name=metrics_label,json=metricsLabel,proto3" json:"metrics_label,omitempty"`
	Discard                   LogicalReplicationDetails_Discard                   `protobuf:"varint,11,opt,name=discard,proto3,enum=cockroach.sql.jobs.jobspb.LogicalReplicationDetails_Discard" json:"discard,omitempty"`
	// CreateTable is true if the job should create the table(s) in the
	// destination.
	CreateTable bool `protobuf:"varint,12,opt,name=create_table,json=createTable,proto3" json:"create_table,omitempty"`
	// IngestedExternalCatalog is the catalog written to the destination cluster
	// when CreateTable is true.
	IngestedExternalCatalog externalpb.ExternalCatalog `protobuf:"bytes,13,opt,name=ingested_external_catalog,json=ingestedExternalCatalog,proto3" json:"ingested_external_catalog"`
	// ReverseStreamCommand is CREATE LDR command the coordinator will issue once
	// the offline initial scan completes, but before the tables are made public.
	ReverseStreamCommand string `protobuf:"bytes,14,opt,name=reverse_stream_command,json=reverseStreamCommand,proto3" json:"reverse_stream_command,omitempty"`
	// ParentID is set on the reverse stream job in automatic bidirectional
	// replication, and is equal to the job ID that issued the reverse stream
	// command.
	ParentID        int64  `protobuf:"varint,15,opt,name=parent_id,json=parentId,proto3" json:"parent_id,omitempty"`
	Command         string `protobuf:"bytes,16,opt,name=command,proto3" json:"command,omitempty"`
	SkipSchemaCheck bool   `protobuf:"varint,17,opt,name=skip_schema_check,json=skipSchemaCheck,proto3" json:"skip_schema_check,omitempty"`
}

func (m *LogicalReplicationDetails) Reset()         { *m = LogicalReplicationDetails{} }
func (m *LogicalReplicationDetails) String() string { return proto.CompactTextString(m) }
func (*LogicalReplicationDetails) ProtoMessage()    {}
func (*LogicalReplicationDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{7}
}
func (m *LogicalReplicationDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *LogicalReplicationDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *LogicalReplicationDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_LogicalReplicationDetails.Merge(m, src)
}
func (m *LogicalReplicationDetails) XXX_Size() int {
	return m.Size()
}
func (m *LogicalReplicationDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_LogicalReplicationDetails.DiscardUnknown(m)
}

var xxx_messageInfo_LogicalReplicationDetails proto.InternalMessageInfo

// DescriptorIDMap is a map from the source descriptor ID
// are being replicated by this job.
//
// TODO(ssd): We need to decode how to account for full-database replication.
type LogicalReplicationDetails_ReplicationPair struct {
	SrcDescriptorID int32 `protobuf:"varint,1,opt,name=src_descriptor_id,json=srcDescriptorId,proto3" json:"src_descriptor_id,omitempty"`
	DstDescriptorID int32 `protobuf:"varint,2,opt,name=dst_descriptor_id,json=dstDescriptorId,proto3" json:"dst_descriptor_id,omitempty"`
	DstFunctionID   int32 `protobuf:"varint,3,opt,name=function_id,json=functionId,proto3" json:"function_id,omitempty"`
}

func (m *LogicalReplicationDetails_ReplicationPair) Reset() {
	*m = LogicalReplicationDetails_ReplicationPair{}
}
func (m *LogicalReplicationDetails_ReplicationPair) String() string {
	return proto.CompactTextString(m)
}
func (*LogicalReplicationDetails_ReplicationPair) ProtoMessage() {}
func (*LogicalReplicationDetails_ReplicationPair) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{7, 0}
}
func (m *LogicalReplicationDetails_ReplicationPair) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *LogicalReplicationDetails_ReplicationPair) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *LogicalReplicationDetails_ReplicationPair) XXX_Merge(src proto.Message) {
	xxx_messageInfo_LogicalReplicationDetails_ReplicationPair.Merge(m, src)
}
func (m *LogicalReplicationDetails_ReplicationPair) XXX_Size() int {
	return m.Size()
}
func (m *LogicalReplicationDetails_ReplicationPair) XXX_DiscardUnknown() {
	xxx_messageInfo_LogicalReplicationDetails_ReplicationPair.DiscardUnknown(m)
}

var xxx_messageInfo_LogicalReplicationDetails_ReplicationPair proto.InternalMessageInfo

type LogicalReplicationDetails_DefaultConflictResolution struct {
	ConflictResolutionType LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution `protobuf:"varint,1,opt,name=conflict_resolution_type,json=conflictResolutionType,proto3,enum=cockroach.sql.jobs.jobspb.LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution" json:"conflict_resolution_type,omitempty"`
	FunctionId             int32                                                                         `protobuf:"varint,2,opt,name=function_id,json=functionId,proto3" json:"function_id,omitempty"`
}

func (m *LogicalReplicationDetails_DefaultConflictResolution) Reset() {
	*m = LogicalReplicationDetails_DefaultConflictResolution{}
}
func (m *LogicalReplicationDetails_DefaultConflictResolution) String() string {
	return proto.CompactTextString(m)
}
func (*LogicalReplicationDetails_DefaultConflictResolution) ProtoMessage() {}
func (*LogicalReplicationDetails_DefaultConflictResolution) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{7, 1}
}
func (m *LogicalReplicationDetails_DefaultConflictResolution) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *LogicalReplicationDetails_DefaultConflictResolution) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *LogicalReplicationDetails_DefaultConflictResolution) XXX_Merge(src proto.Message) {
	xxx_messageInfo_LogicalReplicationDetails_DefaultConflictResolution.Merge(m, src)
}
func (m *LogicalReplicationDetails_DefaultConflictResolution) XXX_Size() int {
	return m.Size()
}
func (m *LogicalReplicationDetails_DefaultConflictResolution) XXX_DiscardUnknown() {
	xxx_messageInfo_LogicalReplicationDetails_DefaultConflictResolution.DiscardUnknown(m)
}

var xxx_messageInfo_LogicalReplicationDetails_DefaultConflictResolution proto.InternalMessageInfo

type LogicalReplicationProgress struct {
	// ReplicatedTime is the ingestion frontier. This is the canonical
	// value of the frontier. The HighWater in the job progress is for
	// informational purposes only.
	ReplicatedTime hlc.Timestamp `protobuf:"bytes,5,opt,name=replicated_time,json=replicatedTime,proto3" json:"replicated_time"`
	// Checkpoint stores a set of resolved spans denoting completed ingestion progress
	Checkpoint StreamIngestionCheckpoint `protobuf:"bytes,6,opt,name=checkpoint,proto3" json:"checkpoint"`
	// PartitionConnUris are the source cluster addresses read from the latest
	// topology.
	PartitionConnUris    []string `protobuf:"bytes,8,rep,name=partition_conn_uris,json=partitionConnUris,proto3" json:"partition_conn_uris,omitempty"`
	PublishedNewTables   bool     `protobuf:"varint,9,opt,name=published_new_tables,json=publishedNewTables,proto3" json:"published_new_tables,omitempty"`
	StartedReverseStream bool     `protobuf:"varint,10,opt,name=started_reverse_stream,json=startedReverseStream,proto3" json:"started_reverse_stream,omitempty"`
}

func (m *LogicalReplicationProgress) Reset()         { *m = LogicalReplicationProgress{} }
func (m *LogicalReplicationProgress) String() string { return proto.CompactTextString(m) }
func (*LogicalReplicationProgress) ProtoMessage()    {}
func (*LogicalReplicationProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{8}
}
func (m *LogicalReplicationProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *LogicalReplicationProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *LogicalReplicationProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_LogicalReplicationProgress.Merge(m, src)
}
func (m *LogicalReplicationProgress) XXX_Size() int {
	return m.Size()
}
func (m *LogicalReplicationProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_LogicalReplicationProgress.DiscardUnknown(m)
}

var xxx_messageInfo_LogicalReplicationProgress proto.InternalMessageInfo

type StreamReplicationDetails struct {
	// Key spans we are replicating
	Spans []roachpb.Span `protobuf:"bytes,1,rep,name=spans,proto3" json:"spans"`
	// ID of the protected timestamp record that protects the above spans
	ProtectedTimestampRecordID github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,2,opt,name=protected_timestamp_record_id,json=protectedTimestampRecordId,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"protected_timestamp_record_id"`
	// TenantID is the ID of the source tenant being streamed.
	TenantID roachpb.TenantID `protobuf:"bytes,3,opt,name=tenant_id,json=tenantId,proto3" json:"tenant_id"`
	// ExpirationWindow specifies the length of time a producer job will stay
	// alive without a heartbeat from the consumer job.
	ExpirationWindow time.Duration `protobuf:"varint,4,opt,name=expiration_window,json=expirationWindow,proto3,casttype=time.Duration" json:"expiration_window,omitempty"`
	TableIDs         []uint32      `protobuf:"varint,5,rep,packed,name=table_ids,json=tableIds,proto3" json:"table_ids,omitempty"`
}

func (m *StreamReplicationDetails) Reset()         { *m = StreamReplicationDetails{} }
func (m *StreamReplicationDetails) String() string { return proto.CompactTextString(m) }
func (*StreamReplicationDetails) ProtoMessage()    {}
func (*StreamReplicationDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{9}
}
func (m *StreamReplicationDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *StreamReplicationDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *StreamReplicationDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_StreamReplicationDetails.Merge(m, src)
}
func (m *StreamReplicationDetails) XXX_Size() int {
	return m.Size()
}
func (m *StreamReplicationDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_StreamReplicationDetails.DiscardUnknown(m)
}

var xxx_messageInfo_StreamReplicationDetails proto.InternalMessageInfo

type StreamReplicationProgress struct {
	// Expiration timestamp of consumer heartbeat
	Expiration time.Time `protobuf:"bytes,1,opt,name=expiration,proto3,stdtime" json:"expiration"`
	// Status of the corresponding stream ingestion. The producer job tracks this
	// to determine its fate.
	StreamIngestionStatus StreamReplicationProgress_StreamIngestionStatus `protobuf:"varint,2,opt,name=stream_ingestion_status,json=streamIngestionStatus,proto3,enum=cockroach.sql.jobs.jobspb.StreamReplicationProgress_StreamIngestionStatus" json:"stream_ingestion_status,omitempty"`
}

func (m *StreamReplicationProgress) Reset()         { *m = StreamReplicationProgress{} }
func (m *StreamReplicationProgress) String() string { return proto.CompactTextString(m) }
func (*StreamReplicationProgress) ProtoMessage()    {}
func (*StreamReplicationProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{10}
}
func (m *StreamReplicationProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *StreamReplicationProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *StreamReplicationProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_StreamReplicationProgress.Merge(m, src)
}
func (m *StreamReplicationProgress) XXX_Size() int {
	return m.Size()
}
func (m *StreamReplicationProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_StreamReplicationProgress.DiscardUnknown(m)
}

var xxx_messageInfo_StreamReplicationProgress proto.InternalMessageInfo

type SchedulePTSChainingRecord struct {
	ProtectedTimestampRecord *github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,1,opt,name=protected_timestamp_record,json=protectedTimestampRecord,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"protected_timestamp_record,omitempty"`
	Action                   SchedulePTSChainingRecord_PTSAction                  `protobuf:"varint,2,opt,name=action,proto3,enum=cockroach.sql.jobs.jobspb.SchedulePTSChainingRecord_PTSAction" json:"action,omitempty"`
}

func (m *SchedulePTSChainingRecord) Reset()         { *m = SchedulePTSChainingRecord{} }
func (m *SchedulePTSChainingRecord) String() string { return proto.CompactTextString(m) }
func (*SchedulePTSChainingRecord) ProtoMessage()    {}
func (*SchedulePTSChainingRecord) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{11}
}
func (m *SchedulePTSChainingRecord) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchedulePTSChainingRecord) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchedulePTSChainingRecord) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchedulePTSChainingRecord.Merge(m, src)
}
func (m *SchedulePTSChainingRecord) XXX_Size() int {
	return m.Size()
}
func (m *SchedulePTSChainingRecord) XXX_DiscardUnknown() {
	xxx_messageInfo_SchedulePTSChainingRecord.DiscardUnknown(m)
}

var xxx_messageInfo_SchedulePTSChainingRecord proto.InternalMessageInfo

type BackupDetails struct {
	StartTime hlc.Timestamp `protobuf:"bytes,1,opt,name=start_time,json=startTime,proto3" json:"start_time"`
	EndTime   hlc.Timestamp `protobuf:"bytes,2,opt,name=end_time,json=endTime,proto3" json:"end_time"`
	// URI is the URI for the main backup destination. For partitioned backups,
	// the main BACKUP manifest and files with no other specified destination are
	// written to this location. For regular backups, all files are written to
	// this location.
	URI         string                    `protobuf:"bytes,3,opt,name=uri,proto3" json:"uri,omitempty"`
	Destination BackupDetails_Destination `protobuf:"bytes,11,opt,name=destination,proto3" json:"destination"`
	// URIsByLocalityKV is a map of locality KVs to store URIs, used for
	// partitioned backups. The map does not include the default locality.
	URIsByLocalityKV         map[string]string `protobuf:"bytes,5,rep,name=uris_by_locality_kv,json=urisByLocalityKv,proto3" json:"uris_by_locality_kv,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	DeprecatedBackupManifest []byte            `protobuf:"bytes,4,opt,name=deprecated_backup_manifest,json=deprecatedBackupManifest,proto3" json:"deprecated_backup_manifest,omitempty"`
	// EncryptionOptions contains user inputed data initially, but once
	// ResolveDest is called at the beginning of resumption, this field will
	// contain the encryption key.
	//
	// TODO(msbutler): use seperate job info key to persist hydrated encryption
	// keys so encrypted backup logic becomes easier to reason about. This
	// shouldn't be as complicated as rocket science.
	EncryptionOptions *BackupEncryptionOptions `protobuf:"bytes,6,opt,name=encryption_options,json=encryptionOptions,proto3" json:"encryption_options,omitempty"`
	// EncryptionInfo should only ever get set on the first encrypted backup in
	// the chain because it persists the salt that each key in the chain must
	// have.
	//
	// TODO(msbutler): understand if only the full ever sets EncryptionInfo.
	EncryptionInfo *EncryptionInfo `protobuf:"bytes,9,opt,name=encryption_info,json=encryptionInfo,proto3" json:"encryption_info,omitempty"`
	// ProtectedTimestampRecord is the ID of the protected timestamp record
	// corresponding to this job. While the job ought to clean up the record
	// when it enters a terminal state, there may be cases where it cannot or
	// does not run the code to do so. To deal with this there is a background
	// reconciliation loop to ensure that protected timestamps are cleaned up.
	ProtectedTimestampRecord *github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,7,opt,name=protected_timestamp_record,json=protectedTimestampRecord,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"protected_timestamp_record,omitempty"`
	// CollectionURI is the path to the collection into which this backup is being
	// written, i.e. the URI the user provided before a chosen suffix was appended
	// to its path.
	CollectionURI string     `protobuf:"bytes,8,opt,name=collection_URI,json=collectionURI,proto3" json:"collection_URI,omitempty"`
	ScheduleID    ScheduleID `protobuf:"varint,12,opt,name=schedule_id,json=scheduleId,proto3,casttype=ScheduleID" json:"schedule_id,omitempty"`
	// SchedulePTSChainingRecord is used by scheduled backups to chain protected
	// timestamp records. For more details about the chaining scheme refer to the
	// comment at the top of `schedule_pts_chaining.go`.
	SchedulePTSChainingRecord *SchedulePTSChainingRecord `protobuf:"bytes,10,opt,name=schedule_pts_chaining_record,json=schedulePtsChainingRecord,proto3" json:"schedule_pts_chaining_record,omitempty"`
	RevisionHistory           bool                       `protobuf:"varint,13,opt,name=revision_history,json=revisionHistory,proto3" json:"revision_history,omitempty"`
	FullCluster               bool                       `protobuf:"varint,15,opt,name=full_cluster,json=fullCluster,proto3" json:"full_cluster,omitempty"`
	// SpecificTenantIds if set indicates the IDs of explicit tenant targets.
	SpecificTenantIds []roachpb.TenantID `protobuf:"bytes,19,rep,name=specific_tenant_ids,json=specificTenantIds,proto3" json:"specific_tenant_ids"`
	// ResolvedTargets contains all descriptors resolved from any explicit targets
	// (and is empty for full-cluster backups, which have no explicit targets).
	ResolvedTargets []descpb.Descriptor `protobuf:"bytes,17,rep,name=resolved_targets,json=resolvedTargets,proto3" json:"resolved_targets"`
	// ResolvedCompleteDbs contains the DBs in ResolvedTargets that are "complete"
	// as discussed in backup and restore planning checks.
	ResolvedCompleteDbs []github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,18,rep,packed,name=resolved_complete_dbs,json=resolvedCompleteDbs,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"resolved_complete_dbs,omitempty"`
	// RequestedTargets contains descriptors resolved from any explicit targets
	// (and is empty for full-cluster backups, which have no explicit targets).
	// This is different from ResolvedTargets in that it contains exactly one
	// entry per target from the original backup statement. For targets that
	// specify exactly one table or database, the entry is just the descriptor of
	// the table or database. For targets that specify all tables in a database or
	// schema with a wildcard, the descriptor is that of the database or schema.
	RequestedTargets []descpb.Descriptor `protobuf:"bytes,20,rep,name=requested_targets,json=requestedTargets,proto3" json:"requested_targets"`
	// Detached is true if the backup is running DETACHED mode.
	Detached bool `protobuf:"varint,21,opt,name=detached,proto3" json:"detached,omitempty"`
	// AsOfInterval is the time interval in nanoseconds between the statement
	// timestamp and the timestamp resolved by the AS OF SYSTEM TIME expression.
	// The interval is expressed in nanoseconds.
	AsOfInterval int64 `protobuf:"varint,22,opt,name=as_of_interval,json=asOfInterval,proto3" json:"as_of_interval,omitempty"`
	// ApplicationName is the application name in the session where the backup was
	// invoked.
	ApplicationName   string           `protobuf:"bytes,23,opt,name=application_name,json=applicationName,proto3" json:"application_name,omitempty"`
	ExecutionLocality roachpb.Locality `protobuf:"bytes,24,opt,name=execution_locality,json=executionLocality,proto3" json:"execution_locality"`
	// IncludeAllSecondaryTenants indicates whether a full tenant backup
	// should also include a tenant backup of all existing secondary
	// tenants.
	IncludeAllSecondaryTenants bool `protobuf:"varint,25,opt,name=include_all_secondary_tenants,json=includeAllSecondaryTenants,proto3" json:"include_all_secondary_tenants,omitempty"`
	// UpdatesClusterMonitoring indicates whether the backup job should update
	// cluster-wide metrics, such as the last successful backup time, or the last
	// time of a backup failure due to a KMS error.
	UpdatesClusterMonitoringMetrics bool `protobuf:"varint,26,opt,name=updates_cluster_monitoring_metrics,json=updatesClusterMonitoringMetrics,proto3" json:"updates_cluster_monitoring_metrics,omitempty"`
	// Compact is set if the job is a compaction job. In that case, the StartTime
	// and EndTime describe the time range of the compaction. StartTime will be
	// the start time of the first backup to be compacted and EndTime will be the
	// end time of the last backup to be compacted.
	// NB: If Compact is set, the job is not a regular backup job and only a limited
	//  set of fields are set meaningfully.
	Compact bool `protobuf:"varint,27,opt,name=compact,proto3" json:"compact,omitempty"`
}

func (m *BackupDetails) Reset()         { *m = BackupDetails{} }
func (m *BackupDetails) String() string { return proto.CompactTextString(m) }
func (*BackupDetails) ProtoMessage()    {}
func (*BackupDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{12}
}
func (m *BackupDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *BackupDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *BackupDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_BackupDetails.Merge(m, src)
}
func (m *BackupDetails) XXX_Size() int {
	return m.Size()
}
func (m *BackupDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_BackupDetails.DiscardUnknown(m)
}

var xxx_messageInfo_BackupDetails proto.InternalMessageInfo

// Destination describes the specification of where to backup to, either the
// path or collection and subdir of that collection. This may not be the same
// however as the actual path this backup will end up writing to, as that is
// determined by scanning this destination for existing backups, composing new
// sub-paths of it based on date and time, etc. The actual path -- which is
// derived from this destination -- is then captured in the field "URI" below.
type BackupDetails_Destination struct {
	// To is a collection path
	To []string `protobuf:"bytes,1,rep,name=to,proto3" json:"to,omitempty"`
	// Subdir is the path within the collection path in to to backup to.
	Subdir             string   `protobuf:"bytes,2,opt,name=subdir,proto3" json:"subdir,omitempty"`
	IncrementalStorage []string `protobuf:"bytes,3,rep,name=incremental_storage,json=incrementalStorage,proto3" json:"incremental_storage,omitempty"`
	// Exists is true if a backup should already exist at the destination
	Exists bool `protobuf:"varint,4,opt,name=exists,proto3" json:"exists,omitempty"`
}

func (m *BackupDetails_Destination) Reset()         { *m = BackupDetails_Destination{} }
func (m *BackupDetails_Destination) String() string { return proto.CompactTextString(m) }
func (*BackupDetails_Destination) ProtoMessage()    {}
func (*BackupDetails_Destination) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{12, 0}
}
func (m *BackupDetails_Destination) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *BackupDetails_Destination) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *BackupDetails_Destination) XXX_Merge(src proto.Message) {
	xxx_messageInfo_BackupDetails_Destination.Merge(m, src)
}
func (m *BackupDetails_Destination) XXX_Size() int {
	return m.Size()
}
func (m *BackupDetails_Destination) XXX_DiscardUnknown() {
	xxx_messageInfo_BackupDetails_Destination.DiscardUnknown(m)
}

var xxx_messageInfo_BackupDetails_Destination proto.InternalMessageInfo

type BackupProgress struct {
}

func (m *BackupProgress) Reset()         { *m = BackupProgress{} }
func (m *BackupProgress) String() string { return proto.CompactTextString(m) }
func (*BackupProgress) ProtoMessage()    {}
func (*BackupProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{13}
}
func (m *BackupProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *BackupProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *BackupProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_BackupProgress.Merge(m, src)
}
func (m *BackupProgress) XXX_Size() int {
	return m.Size()
}
func (m *BackupProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_BackupProgress.DiscardUnknown(m)
}

var xxx_messageInfo_BackupProgress proto.InternalMessageInfo

// DescriptorRewrite specifies a remapping from one descriptor ID to another for
// use in rewritting descriptors themselves or things that reference them such
// as is done during RESTORE or IMPORT.
type DescriptorRewrite struct {
	ID             github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,1,opt,name=id,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"id,omitempty"`
	ParentID       github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,2,opt,name=parent_id,json=parentId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"parent_id,omitempty"`
	ParentSchemaID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,5,opt,name=parent_schema_id,json=parentSchemaId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"parent_schema_id,omitempty"`
	// ToExisting represents whether this descriptor is being remapped to a
	// descriptor that already exists in the cluster.
	ToExisting bool `protobuf:"varint,3,opt,name=to_existing,json=toExisting,proto3" json:"to_existing,omitempty"`
	// NewDBName represents the new name given to a restored database during a database restore
	NewDBName string `protobuf:"bytes,4,opt,name=new_db_name,json=newDbName,proto3" json:"new_db_name,omitempty"`
}

func (m *DescriptorRewrite) Reset()         { *m = DescriptorRewrite{} }
func (m *DescriptorRewrite) String() string { return proto.CompactTextString(m) }
func (*DescriptorRewrite) ProtoMessage()    {}
func (*DescriptorRewrite) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{14}
}
func (m *DescriptorRewrite) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *DescriptorRewrite) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *DescriptorRewrite) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DescriptorRewrite.Merge(m, src)
}
func (m *DescriptorRewrite) XXX_Size() int {
	return m.Size()
}
func (m *DescriptorRewrite) XXX_DiscardUnknown() {
	xxx_messageInfo_DescriptorRewrite.DiscardUnknown(m)
}

var xxx_messageInfo_DescriptorRewrite proto.InternalMessageInfo

type RestoreDetails struct {
	EndTime            hlc.Timestamp                                                                     `protobuf:"bytes,4,opt,name=end_time,json=endTime,proto3" json:"end_time"`
	DescriptorRewrites map[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID]*DescriptorRewrite `protobuf:"bytes,2,rep,name=descriptor_rewrites,json=descriptorRewrites,proto3,castkey=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"descriptor_rewrites,omitempty" protobuf_key:"varint,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	// URIs contains one URI for each backup (full or incremental) corresponding
	// to the location of the main BACKUP manifest. For partitioned backups, each
	// backup may also have files in other stores.
	URIs               []string                            `protobuf:"bytes,3,rep,name=uris,proto3" json:"uris,omitempty"`
	BackupLocalityInfo []RestoreDetails_BackupLocalityInfo `protobuf:"bytes,7,rep,name=backup_locality_info,json=backupLocalityInfo,proto3" json:"backup_locality_info"`
	// DatabaseDescs contain the database descriptors for the whole databases we're restoring,
	// remapped to their new IDs.
	DatabaseDescs []*descpb.DatabaseDescriptor `protobuf:"bytes,16,rep,name=database_descs,json=databaseDescs,proto3" json:"database_descs,omitempty"`
	// TableDescs contain the table descriptors for the whole tables we're restoring,
	// remapped to their new IDs.
	TableDescs []*descpb.TableDescriptor `protobuf:"bytes,5,rep,name=table_descs,json=tableDescs,proto3" json:"table_descs,omitempty"`
	// TypeDescs contains the type descriptors written as part of this restore,
	// remapped with their new IDs. Note that it does not include type descriptors
	// existing in the cluster that backed up types are remapped to.
	TypeDescs []*descpb.TypeDescriptor `protobuf:"bytes,14,rep,name=type_descs,json=typeDescs,proto3" json:"type_descs,omitempty"`
	// SchemaDescs contains schema descriptors written as part of this restore,
	// remapped with their new IDs. Like TypeDescs, it does not include existing
	// schema descriptors in the cluster that backed up schemas are remapped to.
	SchemaDescs []*descpb.SchemaDescriptor `protobuf:"bytes,15,rep,name=schema_descs,json=schemaDescs,proto3" json:"schema_descs,omitempty"`
	// FunctionDescs contains function descriptors written as part of this
	// restore, remapped with their new IDs.
	FunctionDescs []*descpb.FunctionDescriptor `protobuf:"bytes,27,rep,name=function_descs,json=functionDescs,proto3" json:"function_descs,omitempty"`
	// Tenants contain info on each tenant to restore. Note this field contains the backed up
	// tenant id.
	Tenants    []mtinfopb.TenantInfoWithUsage `protobuf:"bytes,21,rep,name=tenants,proto3" json:"tenants"`
	OverrideDB string                         `protobuf:"bytes,6,opt,name=override_db,json=overrideDb,proto3" json:"override_db,omitempty"`
	// The restore job has several atomic stages. For now, we keep track of which
	// stages have completed via these flags.
	PrepareCompleted bool `protobuf:"varint,8,opt,name=prepare_completed,json=prepareCompleted,proto3" json:"prepare_completed,omitempty"`
	StatsInserted    bool `protobuf:"varint,9,opt,name=stats_inserted,json=statsInserted,proto3" json:"stats_inserted,omitempty"`
	// SystemTablesMigrated keeps track of which system tables data have been
	// migrated. We need to keep track of this because if we've modified the
	// restored data via a migration, we can't restore back into that span as the
	// migrated keys will shadow the ones that will be restored.
	// Note, that this state may be shared between job versions, so updates to
	// this map must be considered carefully.
	SystemTablesMigrated map[string]bool `protobuf:"bytes,17,rep,name=system_tables_migrated,json=systemTablesMigrated,proto3" json:"system_tables_migrated,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"varint,2,opt,name=value,proto3"`
	// DescriptorsPublished indicates whether or not the descriptors written in
	// the job have been transactionally updated after the data was restored.
	DescriptorsPublished bool                                                                 `protobuf:"varint,10,opt,name=descriptors_published,json=descriptorsPublished,proto3" json:"descriptors_published,omitempty"`
	DescriptorCoverage   github_com_cockroachdb_cockroach_pkg_sql_sem_tree.DescriptorCoverage `protobuf:"varint,11,opt,name=descriptor_coverage,json=descriptorCoverage,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/sem/tree.DescriptorCoverage" json:"descriptor_coverage,omitempty"`
	Encryption           *BackupEncryptionOptions                                             `protobuf:"bytes,12,opt,name=encryption,proto3" json:"encryption,omitempty"`
	// DatabaseModifiers contains extra modifications to make to the databases
	// being restored.
	DatabaseModifiers map[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID]*RestoreDetails_DatabaseModifier `protobuf:"bytes,19,rep,name=database_modifiers,json=databaseModifiers,proto3,castkey=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"database_modifiers,omitempty" protobuf_key:"varint,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	// RestoreSystemUsers is set to true if user runs RESTORE SYSTEM USERS.
	// TODO(msbutler): delete in 23.1
	RestoreSystemUsers bool `protobuf:"varint,22,opt,name=restore_system_users,json=restoreSystemUsers,proto3" json:"restore_system_users,omitempty"`
	// PreRewrittenTenantID is the ID of tenants[0] in the backup, aka its old ID;
	// it is only valid to set this if len(tenants) == 1.
	PreRewriteTenantId *roachpb.TenantID `protobuf:"bytes,23,opt,name=pre_rewrite_tenant_id,json=preRewriteTenantId,proto3" json:"pre_rewrite_tenant_id,omitempty"`
	// SchemaOnly determines whether to only restore the schema in the backup.
	SchemaOnly bool `protobuf:"varint,25,opt,name=schema_only,json=schemaOnly,proto3" json:"schema_only,omitempty"`
	VerifyData bool `protobuf:"varint,26,opt,name=VerifyData,proto3" json:"VerifyData,omitempty"`
	// ProtectedTimestampRecord is the ID of the protected timestamp record
	// corresponding to this job.
	ProtectedTimestampRecord *github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,28,opt,name=protected_timestamp_record,json=protectedTimestampRecord,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"protected_timestamp_record,omitempty"`
	// Disables loacality checking for zone configs.
	SkipLocalitiesCheck bool             `protobuf:"varint,29,opt,name=SkipLocalitiesCheck,proto3" json:"SkipLocalitiesCheck,omitempty"`
	ExecutionLocality   roachpb.Locality `protobuf:"bytes,30,opt,name=execution_locality,json=executionLocality,proto3" json:"execution_locality"`
	ExperimentalOnline  bool             `protobuf:"varint,31,opt,name=experimental_online,json=experimentalOnline,proto3" json:"experimental_online,omitempty"`
	// DownloadSpans indicates this job has run a link phase. These spans must be
	// downloaded, else the OnFailOrCancel has to excice these spans.
	DownloadSpans []roachpb.Span `protobuf:"bytes,32,rep,name=download_spans,json=downloadSpans,proto3" json:"download_spans"`
	// Removes regions.
	RemoveRegions bool `protobuf:"varint,33,opt,name=RemoveRegions,proto3" json:"RemoveRegions,omitempty"`
	// UnsafeRestoreIncompatibleVersion allows restoring a backup older than the min compatible
	// version.
	UnsafeRestoreIncompatibleVersion bool `protobuf:"varint,34,opt,name=unsafe_restore_incompatible_version,json=unsafeRestoreIncompatibleVersion,proto3" json:"unsafe_restore_incompatible_version,omitempty"`
	// PostDownloadTableAutoStatsSettings contains the backed up auto stats
	// settings for online restored tables. These setting will be restored at the
	// end of the download job.
	PostDownloadTableAutoStatsSettings map[uint32]*catpb.AutoStatsSettings `protobuf:"bytes,35,rep,name=post_download_table_auto_stats_settings,json=postDownloadTableAutoStatsSettings,proto3" json:"post_download_table_auto_stats_settings,omitempty" protobuf_key:"varint,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	DownloadJob                        bool                                `protobuf:"varint,36,opt,name=download_job,json=downloadJob,proto3" json:"download_job,omitempty"`
	ExperimentalCopy                   bool                                `protobuf:"varint,37,opt,name=experimental_copy,json=experimentalCopy,proto3" json:"experimental_copy,omitempty"`
}

func (m *RestoreDetails) Reset()         { *m = RestoreDetails{} }
func (m *RestoreDetails) String() string { return proto.CompactTextString(m) }
func (*RestoreDetails) ProtoMessage()    {}
func (*RestoreDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{15}
}
func (m *RestoreDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *RestoreDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *RestoreDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RestoreDetails.Merge(m, src)
}
func (m *RestoreDetails) XXX_Size() int {
	return m.Size()
}
func (m *RestoreDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_RestoreDetails.DiscardUnknown(m)
}

var xxx_messageInfo_RestoreDetails proto.InternalMessageInfo

type RestoreDetails_BackupLocalityInfo struct {
	URIsByOriginalLocalityKV map[string]string `protobuf:"bytes,1,rep,name=uris_by_original_locality_kv,json=urisByOriginalLocalityKv,proto3" json:"uris_by_original_locality_kv,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
}

func (m *RestoreDetails_BackupLocalityInfo) Reset()         { *m = RestoreDetails_BackupLocalityInfo{} }
func (m *RestoreDetails_BackupLocalityInfo) String() string { return proto.CompactTextString(m) }
func (*RestoreDetails_BackupLocalityInfo) ProtoMessage()    {}
func (*RestoreDetails_BackupLocalityInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{15, 0}
}
func (m *RestoreDetails_BackupLocalityInfo) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *RestoreDetails_BackupLocalityInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *RestoreDetails_BackupLocalityInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RestoreDetails_BackupLocalityInfo.Merge(m, src)
}
func (m *RestoreDetails_BackupLocalityInfo) XXX_Size() int {
	return m.Size()
}
func (m *RestoreDetails_BackupLocalityInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_RestoreDetails_BackupLocalityInfo.DiscardUnknown(m)
}

var xxx_messageInfo_RestoreDetails_BackupLocalityInfo proto.InternalMessageInfo

type RestoreDetails_DatabaseModifier struct {
	// ExtraTypeDescs enumerates additional type descriptors to add as part of
	// restoring this database.
	ExtraTypeDescs []*descpb.TypeDescriptor `protobuf:"bytes,1,rep,name=extra_type_descs,json=extraTypeDescs,proto3" json:"extra_type_descs,omitempty"`
	// RegionConfig describes the region config to override the database descriptor
	// with.
	RegionConfig *descpb.DatabaseDescriptor_RegionConfig `protobuf:"bytes,2,opt,name=region_config,json=regionConfig,proto3" json:"region_config,omitempty"`
}

func (m *RestoreDetails_DatabaseModifier) Reset()         { *m = RestoreDetails_DatabaseModifier{} }
func (m *RestoreDetails_DatabaseModifier) String() string { return proto.CompactTextString(m) }
func (*RestoreDetails_DatabaseModifier) ProtoMessage()    {}
func (*RestoreDetails_DatabaseModifier) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{15, 3}
}
func (m *RestoreDetails_DatabaseModifier) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *RestoreDetails_DatabaseModifier) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *RestoreDetails_DatabaseModifier) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RestoreDetails_DatabaseModifier.Merge(m, src)
}
func (m *RestoreDetails_DatabaseModifier) XXX_Size() int {
	return m.Size()
}
func (m *RestoreDetails_DatabaseModifier) XXX_DiscardUnknown() {
	xxx_messageInfo_RestoreDetails_DatabaseModifier.DiscardUnknown(m)
}

var xxx_messageInfo_RestoreDetails_DatabaseModifier proto.InternalMessageInfo

type RestoreProgress struct {
	HighWater  []byte                          `protobuf:"bytes,1,opt,name=high_water,json=highWater,proto3" json:"high_water,omitempty"`
	Checkpoint []RestoreProgress_FrontierEntry `protobuf:"bytes,2,rep,name=checkpoint,proto3" json:"checkpoint"`
	// TotalDownloadRequired is set in the download job for an online restore, and
	// reflects the total amount that was initially found to be needing to be
	// downloaded.
	TotalDownloadRequired uint64 `protobuf:"varint,3,opt,name=total_download_required,json=totalDownloadRequired,proto3" json:"total_download_required,omitempty"`
}

func (m *RestoreProgress) Reset()         { *m = RestoreProgress{} }
func (m *RestoreProgress) String() string { return proto.CompactTextString(m) }
func (*RestoreProgress) ProtoMessage()    {}
func (*RestoreProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{16}
}
func (m *RestoreProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *RestoreProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *RestoreProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RestoreProgress.Merge(m, src)
}
func (m *RestoreProgress) XXX_Size() int {
	return m.Size()
}
func (m *RestoreProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_RestoreProgress.DiscardUnknown(m)
}

var xxx_messageInfo_RestoreProgress proto.InternalMessageInfo

type RestoreProgress_FrontierEntry struct {
	Span      roachpb.Span  `protobuf:"bytes,1,opt,name=span,proto3" json:"span"`
	Timestamp hlc.Timestamp `protobuf:"bytes,2,opt,name=timestamp,proto3" json:"timestamp"`
}

func (m *RestoreProgress_FrontierEntry) Reset()         { *m = RestoreProgress_FrontierEntry{} }
func (m *RestoreProgress_FrontierEntry) String() string { return proto.CompactTextString(m) }
func (*RestoreProgress_FrontierEntry) ProtoMessage()    {}
func (*RestoreProgress_FrontierEntry) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{16, 0}
}
func (m *RestoreProgress_FrontierEntry) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *RestoreProgress_FrontierEntry) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *RestoreProgress_FrontierEntry) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RestoreProgress_FrontierEntry.Merge(m, src)
}
func (m *RestoreProgress_FrontierEntry) XXX_Size() int {
	return m.Size()
}
func (m *RestoreProgress_FrontierEntry) XXX_DiscardUnknown() {
	xxx_messageInfo_RestoreProgress_FrontierEntry.DiscardUnknown(m)
}

var xxx_messageInfo_RestoreProgress_FrontierEntry proto.InternalMessageInfo

type ImportDetails struct {
	// TODO(yuzefovich): we now can only support importing into a single table via
	// a single IMPORT job, so we could change this field.
	Tables []ImportDetails_Table `protobuf:"bytes,1,rep,name=tables,proto3" json:"tables"`
	Types  []ImportDetails_Type  `protobuf:"bytes,26,rep,name=types,proto3" json:"types"`
	URIs   []string              `protobuf:"bytes,2,rep,name=uris,proto3" json:"uris,omitempty"`
	Format roachpb.IOFileFormat  `protobuf:"bytes,3,opt,name=format,proto3" json:"format"`
	// walltime is the time at which an import job will write KVs.
	Walltime        int64                                                      `protobuf:"varint,5,opt,name=walltime,proto3" json:"walltime,omitempty"`
	ParentID        github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,6,opt,name=parent_id,json=parentId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"parent_id,omitempty"`
	PrepareComplete bool                                                       `protobuf:"varint,12,opt,name=prepare_complete,json=prepareComplete,proto3" json:"prepare_complete,omitempty"`
	TablesPublished bool                                                       `protobuf:"varint,13,opt,name=tables_published,json=tablesPublished,proto3" json:"tables_published,omitempty"`
	// If the database being imported into is a multi-region database, then this
	// field stores the databases' primary region.
	DatabasePrimaryRegion github_com_cockroachdb_cockroach_pkg_sql_catalog_catpb.RegionName `protobuf:"bytes,27,opt,name=database_primary_region,json=databasePrimaryRegion,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/catpb.RegionName" json:"database_primary_region,omitempty"`
}

func (m *ImportDetails) Reset()         { *m = ImportDetails{} }
func (m *ImportDetails) String() string { return proto.CompactTextString(m) }
func (*ImportDetails) ProtoMessage()    {}
func (*ImportDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{17}
}
func (m *ImportDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ImportDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ImportDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ImportDetails.Merge(m, src)
}
func (m *ImportDetails) XXX_Size() int {
	return m.Size()
}
func (m *ImportDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_ImportDetails.DiscardUnknown(m)
}

var xxx_messageInfo_ImportDetails proto.InternalMessageInfo

type ImportDetails_Table struct {
	Desc       *descpb.TableDescriptor `protobuf:"bytes,1,opt,name=desc,proto3" json:"desc,omitempty"`
	Name       string                  `protobuf:"bytes,18,opt,name=name,proto3" json:"name,omitempty"`
	SeqVal     int64                   `protobuf:"varint,19,opt,name=seq_val,json=seqVal,proto3" json:"seq_val,omitempty"`
	WasEmpty   bool                    `protobuf:"varint,22,opt,name=was_empty,json=wasEmpty,proto3" json:"was_empty,omitempty"`
	TargetCols []string                `protobuf:"bytes,21,rep,name=target_cols,json=targetCols,proto3" json:"target_cols,omitempty"`
}

func (m *ImportDetails_Table) Reset()         { *m = ImportDetails_Table{} }
func (m *ImportDetails_Table) String() string { return proto.CompactTextString(m) }
func (*ImportDetails_Table) ProtoMessage()    {}
func (*ImportDetails_Table) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{17, 0}
}
func (m *ImportDetails_Table) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ImportDetails_Table) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ImportDetails_Table) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ImportDetails_Table.Merge(m, src)
}
func (m *ImportDetails_Table) XXX_Size() int {
	return m.Size()
}
func (m *ImportDetails_Table) XXX_DiscardUnknown() {
	xxx_messageInfo_ImportDetails_Table.DiscardUnknown(m)
}

var xxx_messageInfo_ImportDetails_Table proto.InternalMessageInfo

type ImportDetails_Type struct {
	Desc *descpb.TypeDescriptor `protobuf:"bytes,1,opt,name=desc,proto3" json:"desc,omitempty"`
}

func (m *ImportDetails_Type) Reset()         { *m = ImportDetails_Type{} }
func (m *ImportDetails_Type) String() string { return proto.CompactTextString(m) }
func (*ImportDetails_Type) ProtoMessage()    {}
func (*ImportDetails_Type) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{17, 1}
}
func (m *ImportDetails_Type) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ImportDetails_Type) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ImportDetails_Type) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ImportDetails_Type.Merge(m, src)
}
func (m *ImportDetails_Type) XXX_Size() int {
	return m.Size()
}
func (m *ImportDetails_Type) XXX_DiscardUnknown() {
	xxx_messageInfo_ImportDetails_Type.DiscardUnknown(m)
}

var xxx_messageInfo_ImportDetails_Type proto.InternalMessageInfo

// SequenceValChunks represents a single chunk of sequence values allocated
// during an IMPORT.
type SequenceValChunk struct {
	ChunkStartVal int64 `protobuf:"varint,1,opt,name=chunk_start_val,json=chunkStartVal,proto3" json:"chunk_start_val,omitempty"`
	ChunkSize     int64 `protobuf:"varint,2,opt,name=chunk_size,json=chunkSize,proto3" json:"chunk_size,omitempty"`
	// The first row in the file being imported from which the current chunk of
	// sequence values is being used.
	ChunkStartRow int64 `protobuf:"varint,3,opt,name=chunk_start_row,json=chunkStartRow,proto3" json:"chunk_start_row,omitempty"`
	// The row in the file being imported at which the import will need to use a
	// new chunk of sequence values.
	NextChunkStartRow int64 `protobuf:"varint,4,opt,name=next_chunk_start_row,json=nextChunkStartRow,proto3" json:"next_chunk_start_row,omitempty"`
}

func (m *SequenceValChunk) Reset()         { *m = SequenceValChunk{} }
func (m *SequenceValChunk) String() string { return proto.CompactTextString(m) }
func (*SequenceValChunk) ProtoMessage()    {}
func (*SequenceValChunk) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{18}
}
func (m *SequenceValChunk) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SequenceValChunk) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SequenceValChunk) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SequenceValChunk.Merge(m, src)
}
func (m *SequenceValChunk) XXX_Size() int {
	return m.Size()
}
func (m *SequenceValChunk) XXX_DiscardUnknown() {
	xxx_messageInfo_SequenceValChunk.DiscardUnknown(m)
}

var xxx_messageInfo_SequenceValChunk proto.InternalMessageInfo

// SequenceDetails represents information about the sequences processed in a
// single file during IMPORT.
type SequenceDetails struct {
	// Mapping from sequence ID to allocated sequence chunks.
	SeqIdToChunks map[int32]*SequenceDetails_SequenceChunks `protobuf:"bytes,1,rep,name=seq_id_to_chunks,json=seqIdToChunks,proto3" json:"seq_id_to_chunks,omitempty" protobuf_key:"varint,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
}

func (m *SequenceDetails) Reset()         { *m = SequenceDetails{} }
func (m *SequenceDetails) String() string { return proto.CompactTextString(m) }
func (*SequenceDetails) ProtoMessage()    {}
func (*SequenceDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{19}
}
func (m *SequenceDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SequenceDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SequenceDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SequenceDetails.Merge(m, src)
}
func (m *SequenceDetails) XXX_Size() int {
	return m.Size()
}
func (m *SequenceDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_SequenceDetails.DiscardUnknown(m)
}

var xxx_messageInfo_SequenceDetails proto.InternalMessageInfo

// SequenceChunks represents all the chunks reserved for a particular sequence
// during an IMPORT.
type SequenceDetails_SequenceChunks struct {
	Chunks []*SequenceValChunk `protobuf:"bytes,1,rep,name=chunks,proto3" json:"chunks,omitempty"`
}

func (m *SequenceDetails_SequenceChunks) Reset()         { *m = SequenceDetails_SequenceChunks{} }
func (m *SequenceDetails_SequenceChunks) String() string { return proto.CompactTextString(m) }
func (*SequenceDetails_SequenceChunks) ProtoMessage()    {}
func (*SequenceDetails_SequenceChunks) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{19, 0}
}
func (m *SequenceDetails_SequenceChunks) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SequenceDetails_SequenceChunks) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SequenceDetails_SequenceChunks) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SequenceDetails_SequenceChunks.Merge(m, src)
}
func (m *SequenceDetails_SequenceChunks) XXX_Size() int {
	return m.Size()
}
func (m *SequenceDetails_SequenceChunks) XXX_DiscardUnknown() {
	xxx_messageInfo_SequenceDetails_SequenceChunks.DiscardUnknown(m)
}

var xxx_messageInfo_SequenceDetails_SequenceChunks proto.InternalMessageInfo

type ImportProgress struct {
	SamplingProgress []float32 `protobuf:"fixed32,1,rep,packed,name=sampling_progress,json=samplingProgress,proto3" json:"sampling_progress,omitempty"`
	ReadProgress     []float32 `protobuf:"fixed32,2,rep,packed,name=read_progress,json=readProgress,proto3" json:"read_progress,omitempty"`
	WriteProgress    []float32 `protobuf:"fixed32,3,rep,packed,name=write_progress,json=writeProgress,proto3" json:"write_progress,omitempty"`
	// The spans of split keys which have had their SSTable's generated.
	// This allows us to skip the shuffle stage for already-completed
	// spans when resuming an import job.
	SpanProgress []roachpb.Span `protobuf:"bytes,4,rep,name=span_progress,json=spanProgress,proto3" json:"span_progress"`
	// In direct-ingest import, once the KVs for i'th row of an input file have
	// been flushed, we can advance the count here and then on resume skip over
	// that many rows without needing to convert/process them at all.
	ResumePos []int64 `protobuf:"varint,5,rep,packed,name=resume_pos,json=resumePos,proto3" json:"resume_pos,omitempty"`
	// Holds metadata related to sequences for every file processed during an
	// IMPORT.
	SequenceDetails []*SequenceDetails `protobuf:"bytes,6,rep,name=sequence_details,json=sequenceDetails,proto3" json:"sequence_details,omitempty"`
	Summary         kvpb.BulkOpSummary `protobuf:"bytes,7,opt,name=summary,proto3" json:"summary"`
}

func (m *ImportProgress) Reset()         { *m = ImportProgress{} }
func (m *ImportProgress) String() string { return proto.CompactTextString(m) }
func (*ImportProgress) ProtoMessage()    {}
func (*ImportProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{20}
}
func (m *ImportProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ImportProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ImportProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ImportProgress.Merge(m, src)
}
func (m *ImportProgress) XXX_Size() int {
	return m.Size()
}
func (m *ImportProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_ImportProgress.DiscardUnknown(m)
}

var xxx_messageInfo_ImportProgress proto.InternalMessageInfo

// TypeSchemaChangeDetails is the job detail information for a type schema change job.
type TypeSchemaChangeDetails struct {
	TypeID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,1,opt,name=type_id,json=typeId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"type_id,omitempty"`
	// TransitioningMembers is a list of enum members, represented by their
	// physical representation, that are transitioning in the current job. This
	// is used to group transitions together and ensure that rollback is limited
	// to this list in the face of job failure. It is also worth noting that we
	// cannot use the logical representation or index of the member to identify
	// a member, as both of these may change due to a concurrent rename or
	// addition with a specified placement. Physical representations are
	// guaranteed to be stable.
	TransitioningMembers [][]byte `protobuf:"bytes,2,rep,name=transitioning_members,json=transitioningMembers,proto3" json:"transitioning_members,omitempty"`
}

func (m *TypeSchemaChangeDetails) Reset()         { *m = TypeSchemaChangeDetails{} }
func (m *TypeSchemaChangeDetails) String() string { return proto.CompactTextString(m) }
func (*TypeSchemaChangeDetails) ProtoMessage()    {}
func (*TypeSchemaChangeDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{21}
}
func (m *TypeSchemaChangeDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *TypeSchemaChangeDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *TypeSchemaChangeDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_TypeSchemaChangeDetails.Merge(m, src)
}
func (m *TypeSchemaChangeDetails) XXX_Size() int {
	return m.Size()
}
func (m *TypeSchemaChangeDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_TypeSchemaChangeDetails.DiscardUnknown(m)
}

var xxx_messageInfo_TypeSchemaChangeDetails proto.InternalMessageInfo

// TypeSchemaChangeProgress is the persisted progress for a type schema change job.
type TypeSchemaChangeProgress struct {
}

func (m *TypeSchemaChangeProgress) Reset()         { *m = TypeSchemaChangeProgress{} }
func (m *TypeSchemaChangeProgress) String() string { return proto.CompactTextString(m) }
func (*TypeSchemaChangeProgress) ProtoMessage()    {}
func (*TypeSchemaChangeProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{22}
}
func (m *TypeSchemaChangeProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *TypeSchemaChangeProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *TypeSchemaChangeProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_TypeSchemaChangeProgress.Merge(m, src)
}
func (m *TypeSchemaChangeProgress) XXX_Size() int {
	return m.Size()
}
func (m *TypeSchemaChangeProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_TypeSchemaChangeProgress.DiscardUnknown(m)
}

var xxx_messageInfo_TypeSchemaChangeProgress proto.InternalMessageInfo

// NewSchemaChangeDetails is the job detail information for the new schema change job.
type NewSchemaChangeDetails struct {
	// BackfillProgress stores the progress for index backfills which may
	// be ongoing.
	BackfillProgress []BackfillProgress `protobuf:"bytes,4,rep,name=backfill_progress,json=backfillProgress,proto3" json:"backfill_progress"`
	// MergeProgress stores the progress for index merges which may
	// be ongoing.
	MergeProgress []MergeProgress `protobuf:"bytes,6,rep,name=merge_progress,json=mergeProgress,proto3" json:"merge_progress"`
	// ProtectedTimestampRecord is the ID of the protected timestamp record
	// corresponding to this job.
	ProtectedTimestampRecord *github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,7,opt,name=protected_timestamp_record,json=protectedTimestampRecord,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"protected_timestamp_record,omitempty"`
}

func (m *NewSchemaChangeDetails) Reset()         { *m = NewSchemaChangeDetails{} }
func (m *NewSchemaChangeDetails) String() string { return proto.CompactTextString(m) }
func (*NewSchemaChangeDetails) ProtoMessage()    {}
func (*NewSchemaChangeDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{23}
}
func (m *NewSchemaChangeDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *NewSchemaChangeDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *NewSchemaChangeDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_NewSchemaChangeDetails.Merge(m, src)
}
func (m *NewSchemaChangeDetails) XXX_Size() int {
	return m.Size()
}
func (m *NewSchemaChangeDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_NewSchemaChangeDetails.DiscardUnknown(m)
}

var xxx_messageInfo_NewSchemaChangeDetails proto.InternalMessageInfo

// BackfillProgress is used to track backfill progress in the declarative
// schema changer.
type BackfillProgress struct {
	// ID is the ID of the descriptor to which this checkpoint corresponds.
	TableID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,1,opt,name=id,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"id,omitempty"`
	// SourceIndexID is the ID of the source index for the backfill.
	// This could be a primary index or it could be a temporary index for
	// a merge.
	SourceIndexID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID `protobuf:"varint,2,opt,name=source_index_id,json=sourceIndexId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.IndexID" json:"source_index_id,omitempty"`
	// DestIndexIDs is the set of IDs which are being backfilled from the
	// SourceIndexID.
	DestIndexIDs []github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID `protobuf:"varint,3,rep,packed,name=dest_index_ids,json=destIndexIds,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.IndexID" json:"dest_index_ids,omitempty"`
	// MinimumWriteTimestamp is the timestamp at which a backfill may want to
	// write, e.g. a time that has been identified via a scan as safe for
	// writing.
	WriteTimestamp hlc.Timestamp `protobuf:"bytes,4,opt,name=write_timestamp,json=writeTimestamp,proto3" json:"write_timestamp"`
	// CompletedSpans are the set of spans of the source index which have been
	// backfilled into the destination indexes. Note that this will never contain
	// tenant prefixes even if the data corresponds to a secondary tenant.
	CompletedSpans []roachpb.Span `protobuf:"bytes,5,rep,name=completed_spans,json=completedSpans,proto3" json:"completed_spans"`
}

func (m *BackfillProgress) Reset()         { *m = BackfillProgress{} }
func (m *BackfillProgress) String() string { return proto.CompactTextString(m) }
func (*BackfillProgress) ProtoMessage()    {}
func (*BackfillProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{24}
}
func (m *BackfillProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *BackfillProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *BackfillProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_BackfillProgress.Merge(m, src)
}
func (m *BackfillProgress) XXX_Size() int {
	return m.Size()
}
func (m *BackfillProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_BackfillProgress.DiscardUnknown(m)
}

var xxx_messageInfo_BackfillProgress proto.InternalMessageInfo

// MergeProgress is used to track index merge progress in the declarative
// schema changer.
type MergeProgress struct {
	// ID is the ID of the descriptor to which this checkpoint corresponds.
	TableID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,1,opt,name=id,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"id,omitempty"`
	// MergePairs holds the progress for each (temporary index, added index) pair.
	MergePairs []MergeProgress_MergePair `protobuf:"bytes,2,rep,name=merge_pairs,json=mergePairs,proto3" json:"merge_pairs"`
}

func (m *MergeProgress) Reset()         { *m = MergeProgress{} }
func (m *MergeProgress) String() string { return proto.CompactTextString(m) }
func (*MergeProgress) ProtoMessage()    {}
func (*MergeProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{25}
}
func (m *MergeProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *MergeProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *MergeProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MergeProgress.Merge(m, src)
}
func (m *MergeProgress) XXX_Size() int {
	return m.Size()
}
func (m *MergeProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_MergeProgress.DiscardUnknown(m)
}

var xxx_messageInfo_MergeProgress proto.InternalMessageInfo

type MergeProgress_MergePair struct {
	// SourceIndexID is the IDs of the temporary index to merge from.
	SourceIndexID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID `protobuf:"varint,2,opt,name=source_index_id,json=sourceIndexId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.IndexID" json:"source_index_id,omitempty"`
	// DestIndexID is the ID of the added index to merge into.
	DestIndexID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID `protobuf:"varint,3,opt,name=dest_index_id,json=destIndexId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.IndexID" json:"dest_index_id,omitempty"`
	// CompletedSpans is the set of spans of the temporary index which have
	// been merged into the destination index. Note that this will never
	// contain tenant prefixes even if the data corresponds to a secondary
	// tenant.
	CompletedSpans []roachpb.Span `protobuf:"bytes,4,rep,name=completed_spans,json=completedSpans,proto3" json:"completed_spans"`
}

func (m *MergeProgress_MergePair) Reset()         { *m = MergeProgress_MergePair{} }
func (m *MergeProgress_MergePair) String() string { return proto.CompactTextString(m) }
func (*MergeProgress_MergePair) ProtoMessage()    {}
func (*MergeProgress_MergePair) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{25, 0}
}
func (m *MergeProgress_MergePair) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *MergeProgress_MergePair) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *MergeProgress_MergePair) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MergeProgress_MergePair.Merge(m, src)
}
func (m *MergeProgress_MergePair) XXX_Size() int {
	return m.Size()
}
func (m *MergeProgress_MergePair) XXX_DiscardUnknown() {
	xxx_messageInfo_MergeProgress_MergePair.DiscardUnknown(m)
}

var xxx_messageInfo_MergeProgress_MergePair proto.InternalMessageInfo

// NewSchemaChangeProgress is the persisted progress for the new schema change job.
type NewSchemaChangeProgress struct {
}

func (m *NewSchemaChangeProgress) Reset()         { *m = NewSchemaChangeProgress{} }
func (m *NewSchemaChangeProgress) String() string { return proto.CompactTextString(m) }
func (*NewSchemaChangeProgress) ProtoMessage()    {}
func (*NewSchemaChangeProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{26}
}
func (m *NewSchemaChangeProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *NewSchemaChangeProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *NewSchemaChangeProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_NewSchemaChangeProgress.Merge(m, src)
}
func (m *NewSchemaChangeProgress) XXX_Size() int {
	return m.Size()
}
func (m *NewSchemaChangeProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_NewSchemaChangeProgress.DiscardUnknown(m)
}

var xxx_messageInfo_NewSchemaChangeProgress proto.InternalMessageInfo

// AutoSpanConfigReconciliationDetails is the job detail information for the
// automatic span config reconciliation job.
type AutoSpanConfigReconciliationDetails struct {
}

func (m *AutoSpanConfigReconciliationDetails) Reset()         { *m = AutoSpanConfigReconciliationDetails{} }
func (m *AutoSpanConfigReconciliationDetails) String() string { return proto.CompactTextString(m) }
func (*AutoSpanConfigReconciliationDetails) ProtoMessage()    {}
func (*AutoSpanConfigReconciliationDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{27}
}
func (m *AutoSpanConfigReconciliationDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoSpanConfigReconciliationDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoSpanConfigReconciliationDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoSpanConfigReconciliationDetails.Merge(m, src)
}
func (m *AutoSpanConfigReconciliationDetails) XXX_Size() int {
	return m.Size()
}
func (m *AutoSpanConfigReconciliationDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoSpanConfigReconciliationDetails.DiscardUnknown(m)
}

var xxx_messageInfo_AutoSpanConfigReconciliationDetails proto.InternalMessageInfo

// AutoSpanConfigReconciliationProgress is the persisted progress for the span
// config reconciliation job.
type AutoSpanConfigReconciliationProgress struct {
	Checkpoint hlc.Timestamp `protobuf:"bytes,1,opt,name=checkpoint,proto3" json:"checkpoint"`
}

func (m *AutoSpanConfigReconciliationProgress) Reset()         { *m = AutoSpanConfigReconciliationProgress{} }
func (m *AutoSpanConfigReconciliationProgress) String() string { return proto.CompactTextString(m) }
func (*AutoSpanConfigReconciliationProgress) ProtoMessage()    {}
func (*AutoSpanConfigReconciliationProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{28}
}
func (m *AutoSpanConfigReconciliationProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoSpanConfigReconciliationProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoSpanConfigReconciliationProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoSpanConfigReconciliationProgress.Merge(m, src)
}
func (m *AutoSpanConfigReconciliationProgress) XXX_Size() int {
	return m.Size()
}
func (m *AutoSpanConfigReconciliationProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoSpanConfigReconciliationProgress.DiscardUnknown(m)
}

var xxx_messageInfo_AutoSpanConfigReconciliationProgress proto.InternalMessageInfo

// KeyVisualizerDetails is the job detail information for the
// key visualizer job.
type KeyVisualizerDetails struct {
}

func (m *KeyVisualizerDetails) Reset()         { *m = KeyVisualizerDetails{} }
func (m *KeyVisualizerDetails) String() string { return proto.CompactTextString(m) }
func (*KeyVisualizerDetails) ProtoMessage()    {}
func (*KeyVisualizerDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{29}
}
func (m *KeyVisualizerDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *KeyVisualizerDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *KeyVisualizerDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KeyVisualizerDetails.Merge(m, src)
}
func (m *KeyVisualizerDetails) XXX_Size() int {
	return m.Size()
}
func (m *KeyVisualizerDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_KeyVisualizerDetails.DiscardUnknown(m)
}

var xxx_messageInfo_KeyVisualizerDetails proto.InternalMessageInfo

// KeyVisualizerProgress is the persisted progress for the
// key visualizer job.
type KeyVisualizerProgress struct {
}

func (m *KeyVisualizerProgress) Reset()         { *m = KeyVisualizerProgress{} }
func (m *KeyVisualizerProgress) String() string { return proto.CompactTextString(m) }
func (*KeyVisualizerProgress) ProtoMessage()    {}
func (*KeyVisualizerProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{30}
}
func (m *KeyVisualizerProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *KeyVisualizerProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *KeyVisualizerProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KeyVisualizerProgress.Merge(m, src)
}
func (m *KeyVisualizerProgress) XXX_Size() int {
	return m.Size()
}
func (m *KeyVisualizerProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_KeyVisualizerProgress.DiscardUnknown(m)
}

var xxx_messageInfo_KeyVisualizerProgress proto.InternalMessageInfo

type ResumeSpanList struct {
	ResumeSpans []roachpb.Span `protobuf:"bytes,1,rep,name=resume_spans,json=resumeSpans,proto3" json:"resume_spans"`
}

func (m *ResumeSpanList) Reset()         { *m = ResumeSpanList{} }
func (m *ResumeSpanList) String() string { return proto.CompactTextString(m) }
func (*ResumeSpanList) ProtoMessage()    {}
func (*ResumeSpanList) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{31}
}
func (m *ResumeSpanList) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ResumeSpanList) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ResumeSpanList) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ResumeSpanList.Merge(m, src)
}
func (m *ResumeSpanList) XXX_Size() int {
	return m.Size()
}
func (m *ResumeSpanList) XXX_DiscardUnknown() {
	xxx_messageInfo_ResumeSpanList.DiscardUnknown(m)
}

var xxx_messageInfo_ResumeSpanList proto.InternalMessageInfo

type DroppedTableDetails struct {
	Name   string                                                     `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	ID     github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,2,opt,name=ID,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"ID,omitempty"`
	Status Status                                                     `protobuf:"varint,3,opt,name=status,proto3,enum=cockroach.sql.jobs.jobspb.Status" json:"status,omitempty"`
}

func (m *DroppedTableDetails) Reset()         { *m = DroppedTableDetails{} }
func (m *DroppedTableDetails) String() string { return proto.CompactTextString(m) }
func (*DroppedTableDetails) ProtoMessage()    {}
func (*DroppedTableDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{32}
}
func (m *DroppedTableDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *DroppedTableDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *DroppedTableDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DroppedTableDetails.Merge(m, src)
}
func (m *DroppedTableDetails) XXX_Size() int {
	return m.Size()
}
func (m *DroppedTableDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_DroppedTableDetails.DiscardUnknown(m)
}

var xxx_messageInfo_DroppedTableDetails proto.InternalMessageInfo

// SchemaChangeGCDetails should resemble one of the following:
//
// 1. Index (non-interleaved) deletions: One or more deletions of an index on a
// table.
//
//	details.Indexes -> the indexes to GC. These indexes must be
//	non-interleaved.
//	details.ParentID -> the table with the indexes.
//
//  2. Table deletions: The deletion of a single table.
//     details.Tables -> the tables to be deleted.
//
//  3. Database deletions: The deletion of a database and therefore all its tables.
//     details.Tables -> the IDs of the tables to GC.
//     details.ParentID -> the ID of the database to drop.
//
//  4. Tenant deletion: The deletion of a tenant key range.
//     details.TenantID -> the ID of the tenant to delete.
type SchemaChangeGCDetails struct {
	// Indexes to GC.
	Indexes []SchemaChangeGCDetails_DroppedIndex `protobuf:"bytes,1,rep,name=indexes,proto3" json:"indexes"`
	// Entire tables to GC.
	Tables []SchemaChangeGCDetails_DroppedID `protobuf:"bytes,2,rep,name=tables,proto3" json:"tables"`
	// If dropping indexes, the table ID which has those indexes. If dropping a
	// database, the database ID.
	ParentID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,3,opt,name=parent_id,json=parentId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"parent_id,omitempty"`
	// Tenant to GC.
	Tenant *SchemaChangeGCDetails_DroppedTenant `protobuf:"bytes,6,opt,name=tenant,proto3" json:"tenant,omitempty"`
}

func (m *SchemaChangeGCDetails) Reset()         { *m = SchemaChangeGCDetails{} }
func (m *SchemaChangeGCDetails) String() string { return proto.CompactTextString(m) }
func (*SchemaChangeGCDetails) ProtoMessage()    {}
func (*SchemaChangeGCDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{33}
}
func (m *SchemaChangeGCDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaChangeGCDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaChangeGCDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaChangeGCDetails.Merge(m, src)
}
func (m *SchemaChangeGCDetails) XXX_Size() int {
	return m.Size()
}
func (m *SchemaChangeGCDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaChangeGCDetails.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaChangeGCDetails proto.InternalMessageInfo

type SchemaChangeGCDetails_DroppedIndex struct {
	IndexID  github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID `protobuf:"varint,1,opt,name=index_id,json=indexId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.IndexID" json:"index_id,omitempty"`
	DropTime int64                                                           `protobuf:"varint,2,opt,name=drop_time,json=dropTime,proto3" json:"drop_time,omitempty"`
}

func (m *SchemaChangeGCDetails_DroppedIndex) Reset()         { *m = SchemaChangeGCDetails_DroppedIndex{} }
func (m *SchemaChangeGCDetails_DroppedIndex) String() string { return proto.CompactTextString(m) }
func (*SchemaChangeGCDetails_DroppedIndex) ProtoMessage()    {}
func (*SchemaChangeGCDetails_DroppedIndex) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{33, 0}
}
func (m *SchemaChangeGCDetails_DroppedIndex) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaChangeGCDetails_DroppedIndex) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaChangeGCDetails_DroppedIndex) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaChangeGCDetails_DroppedIndex.Merge(m, src)
}
func (m *SchemaChangeGCDetails_DroppedIndex) XXX_Size() int {
	return m.Size()
}
func (m *SchemaChangeGCDetails_DroppedIndex) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaChangeGCDetails_DroppedIndex.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaChangeGCDetails_DroppedIndex proto.InternalMessageInfo

type SchemaChangeGCDetails_DroppedID struct {
	ID       github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,1,opt,name=id,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"id,omitempty"`
	DropTime int64                                                      `protobuf:"varint,2,opt,name=drop_time,json=dropTime,proto3" json:"drop_time,omitempty"`
}

func (m *SchemaChangeGCDetails_DroppedID) Reset()         { *m = SchemaChangeGCDetails_DroppedID{} }
func (m *SchemaChangeGCDetails_DroppedID) String() string { return proto.CompactTextString(m) }
func (*SchemaChangeGCDetails_DroppedID) ProtoMessage()    {}
func (*SchemaChangeGCDetails_DroppedID) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{33, 1}
}
func (m *SchemaChangeGCDetails_DroppedID) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaChangeGCDetails_DroppedID) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaChangeGCDetails_DroppedID) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaChangeGCDetails_DroppedID.Merge(m, src)
}
func (m *SchemaChangeGCDetails_DroppedID) XXX_Size() int {
	return m.Size()
}
func (m *SchemaChangeGCDetails_DroppedID) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaChangeGCDetails_DroppedID.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaChangeGCDetails_DroppedID proto.InternalMessageInfo

type SchemaChangeGCDetails_DroppedTenant struct {
	ID       uint64 `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`
	DropTime int64  `protobuf:"varint,2,opt,name=drop_time,json=dropTime,proto3" json:"drop_time,omitempty"`
}

func (m *SchemaChangeGCDetails_DroppedTenant) Reset()         { *m = SchemaChangeGCDetails_DroppedTenant{} }
func (m *SchemaChangeGCDetails_DroppedTenant) String() string { return proto.CompactTextString(m) }
func (*SchemaChangeGCDetails_DroppedTenant) ProtoMessage()    {}
func (*SchemaChangeGCDetails_DroppedTenant) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{33, 2}
}
func (m *SchemaChangeGCDetails_DroppedTenant) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaChangeGCDetails_DroppedTenant) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaChangeGCDetails_DroppedTenant) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaChangeGCDetails_DroppedTenant.Merge(m, src)
}
func (m *SchemaChangeGCDetails_DroppedTenant) XXX_Size() int {
	return m.Size()
}
func (m *SchemaChangeGCDetails_DroppedTenant) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaChangeGCDetails_DroppedTenant.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaChangeGCDetails_DroppedTenant proto.InternalMessageInfo

type SchemaChangeDetails struct {
	// A schema change can involve running multiple processors backfilling
	// or deleting data. They occasionally checkpoint Spans so that the
	// processing can resume in the event of a node failure. The spans are
	// non-overlapping contiguous areas of the KV space that still need to
	// be processed. The index represents the index of a mutation in a
	// mutation list containing mutations for the same mutationID.
	ResumeSpanList []ResumeSpanList      `protobuf:"bytes,2,rep,name=resume_span_list,json=resumeSpanList,proto3" json:"resume_span_list"`
	DroppedTables  []DroppedTableDetails `protobuf:"bytes,3,rep,name=dropped_tables,json=droppedTables,proto3" json:"dropped_tables"`
	// dropped_types holds the set of types to drop as part of a DROP DATABASE
	// statement. We collect the types here rather than creating individual DROP
	// TYPE jobs for each dropped type.
	DroppedTypes []github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,8,rep,packed,name=dropped_types,json=droppedTypes,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"dropped_types,omitempty"`
	// dropped_schemas holds the set of schemas to drop as part of a DROP SCHEMA
	// or DROP DATABASE cascade statement.
	DroppedSchemas []github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,9,rep,packed,name=dropped_schemas,json=droppedSchemas,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"dropped_schemas,omitempty"`
	// The descriptor ID of the dropped database which created this job.
	DroppedDatabaseID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,4,opt,name=dropped_database_id,json=droppedDatabaseId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"dropped_database_id,omitempty"`
	// dropped_functions holds the set of functions to drop as part of DROP
	// FUNCTION, DROP DATABASE or DROP SCHEMA statement.
	DroppedFunctions []github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,12,rep,packed,name=dropped_functions,json=droppedFunctions,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"dropped_functions,omitempty"`
	// desc_id is the target descriptor for this schema change. Note that this ID
	// is not always a table ID! We allow referencing any descriptor here to allow
	// generic schema changes on descriptors whose schema change process involves
	// only draining names and existing leases. This allows us to implement the
	// simple schema changes on SchemaDescriptors and DatabaseDescriptors without
	// implementing a new job for each.
	DescID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,5,opt,name=desc_id,json=descId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"desc_id,omitempty"`
	// table_mutation_id is the mutation ID that the schema changer is to process. It is
	// only set when desc_id references a TableDescriptor.
	TableMutationID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.MutationID `protobuf:"varint,6,opt,name=table_mutation_id,json=tableMutationId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.MutationID" json:"table_mutation_id,omitempty"`
	// The format version of the schema change job details. This is used to
	// distinguish between jobs as they existed in 19.2 and earlier versions
	// (controlled and updated by a SchemaChanger) and jobs as they exist in 20.1
	// (scheduled and run by the job registry).
	FormatVersion SchemaChangeDetailsFormatVersion `protobuf:"varint,7,opt,name=format_version,json=formatVersion,proto3,casttype=SchemaChangeDetailsFormatVersion" json:"format_version,omitempty"`
	// WriteTimestamp is the timestamp at which a backfill may want to write, e.g.
	// a time that has been identified via a scan as safe for writing.
	WriteTimestamp hlc.Timestamp `protobuf:"bytes,10,opt,name=write_timestamp,json=writeTimestamp,proto3" json:"write_timestamp"`
	// ProtectedTimestampRecord is the ID of the protected timestamp record
	// corresponding to this job.
	ProtectedTimestampRecord *github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,11,opt,name=protected_timestamp_record,json=protectedTimestampRecord,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"protected_timestamp_record,omitempty"`
	SessionData              *sessiondatapb.SessionData                           `protobuf:"bytes,13,opt,name=session_data,json=sessionData,proto3" json:"session_data,omitempty"`
}

func (m *SchemaChangeDetails) Reset()         { *m = SchemaChangeDetails{} }
func (m *SchemaChangeDetails) String() string { return proto.CompactTextString(m) }
func (*SchemaChangeDetails) ProtoMessage()    {}
func (*SchemaChangeDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{34}
}
func (m *SchemaChangeDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaChangeDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaChangeDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaChangeDetails.Merge(m, src)
}
func (m *SchemaChangeDetails) XXX_Size() int {
	return m.Size()
}
func (m *SchemaChangeDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaChangeDetails.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaChangeDetails proto.InternalMessageInfo

type SchemaChangeProgress struct {
}

func (m *SchemaChangeProgress) Reset()         { *m = SchemaChangeProgress{} }
func (m *SchemaChangeProgress) String() string { return proto.CompactTextString(m) }
func (*SchemaChangeProgress) ProtoMessage()    {}
func (*SchemaChangeProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{35}
}
func (m *SchemaChangeProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaChangeProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaChangeProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaChangeProgress.Merge(m, src)
}
func (m *SchemaChangeProgress) XXX_Size() int {
	return m.Size()
}
func (m *SchemaChangeProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaChangeProgress.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaChangeProgress proto.InternalMessageInfo

type SchemaChangeGCProgress struct {
	// Indexes to GC.
	Indexes []SchemaChangeGCProgress_IndexProgress `protobuf:"bytes,1,rep,name=indexes,proto3" json:"indexes"`
	// Entire tables to GC.
	Tables []SchemaChangeGCProgress_TableProgress `protobuf:"bytes,2,rep,name=tables,proto3" json:"tables"`
	// The status of the tenant to be deleted.
	Tenant *SchemaChangeGCProgress_TenantProgress `protobuf:"bytes,3,opt,name=tenant,proto3" json:"tenant,omitempty"`
	// RangesUnsplitDone indicates whether ranges or gc-ed indexes and tables are
	// already unsplit.
	RangesUnsplitDone bool `protobuf:"varint,4,opt,name=ranges_unsplit_done,json=rangesUnsplitDone,proto3" json:"ranges_unsplit_done,omitempty"`
}

func (m *SchemaChangeGCProgress) Reset()         { *m = SchemaChangeGCProgress{} }
func (m *SchemaChangeGCProgress) String() string { return proto.CompactTextString(m) }
func (*SchemaChangeGCProgress) ProtoMessage()    {}
func (*SchemaChangeGCProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{36}
}
func (m *SchemaChangeGCProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaChangeGCProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaChangeGCProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaChangeGCProgress.Merge(m, src)
}
func (m *SchemaChangeGCProgress) XXX_Size() int {
	return m.Size()
}
func (m *SchemaChangeGCProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaChangeGCProgress.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaChangeGCProgress proto.InternalMessageInfo

type SchemaChangeGCProgress_IndexProgress struct {
	IndexID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID `protobuf:"varint,1,opt,name=index_id,json=indexId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.IndexID" json:"index_id,omitempty"`
	Status  SchemaChangeGCProgress_Status                                   `protobuf:"varint,2,opt,name=status,proto3,enum=cockroach.sql.jobs.jobspb.SchemaChangeGCProgress_Status" json:"status,omitempty"`
}

func (m *SchemaChangeGCProgress_IndexProgress) Reset()         { *m = SchemaChangeGCProgress_IndexProgress{} }
func (m *SchemaChangeGCProgress_IndexProgress) String() string { return proto.CompactTextString(m) }
func (*SchemaChangeGCProgress_IndexProgress) ProtoMessage()    {}
func (*SchemaChangeGCProgress_IndexProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{36, 0}
}
func (m *SchemaChangeGCProgress_IndexProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaChangeGCProgress_IndexProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaChangeGCProgress_IndexProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaChangeGCProgress_IndexProgress.Merge(m, src)
}
func (m *SchemaChangeGCProgress_IndexProgress) XXX_Size() int {
	return m.Size()
}
func (m *SchemaChangeGCProgress_IndexProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaChangeGCProgress_IndexProgress.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaChangeGCProgress_IndexProgress proto.InternalMessageInfo

type SchemaChangeGCProgress_TableProgress struct {
	ID     github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,1,opt,name=id,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"id,omitempty"`
	Status SchemaChangeGCProgress_Status                              `protobuf:"varint,2,opt,name=status,proto3,enum=cockroach.sql.jobs.jobspb.SchemaChangeGCProgress_Status" json:"status,omitempty"`
}

func (m *SchemaChangeGCProgress_TableProgress) Reset()         { *m = SchemaChangeGCProgress_TableProgress{} }
func (m *SchemaChangeGCProgress_TableProgress) String() string { return proto.CompactTextString(m) }
func (*SchemaChangeGCProgress_TableProgress) ProtoMessage()    {}
func (*SchemaChangeGCProgress_TableProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{36, 1}
}
func (m *SchemaChangeGCProgress_TableProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaChangeGCProgress_TableProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaChangeGCProgress_TableProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaChangeGCProgress_TableProgress.Merge(m, src)
}
func (m *SchemaChangeGCProgress_TableProgress) XXX_Size() int {
	return m.Size()
}
func (m *SchemaChangeGCProgress_TableProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaChangeGCProgress_TableProgress.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaChangeGCProgress_TableProgress proto.InternalMessageInfo

type SchemaChangeGCProgress_TenantProgress struct {
	Status SchemaChangeGCProgress_Status `protobuf:"varint,1,opt,name=status,proto3,enum=cockroach.sql.jobs.jobspb.SchemaChangeGCProgress_Status" json:"status,omitempty"`
}

func (m *SchemaChangeGCProgress_TenantProgress) Reset()         { *m = SchemaChangeGCProgress_TenantProgress{} }
func (m *SchemaChangeGCProgress_TenantProgress) String() string { return proto.CompactTextString(m) }
func (*SchemaChangeGCProgress_TenantProgress) ProtoMessage()    {}
func (*SchemaChangeGCProgress_TenantProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{36, 2}
}
func (m *SchemaChangeGCProgress_TenantProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaChangeGCProgress_TenantProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaChangeGCProgress_TenantProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaChangeGCProgress_TenantProgress.Merge(m, src)
}
func (m *SchemaChangeGCProgress_TenantProgress) XXX_Size() int {
	return m.Size()
}
func (m *SchemaChangeGCProgress_TenantProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaChangeGCProgress_TenantProgress.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaChangeGCProgress_TenantProgress proto.InternalMessageInfo

type ChangefeedTargetTable struct {
	StatementTimeName string `protobuf:"bytes,1,opt,name=statement_time_name,json=statementTimeName,proto3" json:"statement_time_name,omitempty"`
}

func (m *ChangefeedTargetTable) Reset()         { *m = ChangefeedTargetTable{} }
func (m *ChangefeedTargetTable) String() string { return proto.CompactTextString(m) }
func (*ChangefeedTargetTable) ProtoMessage()    {}
func (*ChangefeedTargetTable) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{37}
}
func (m *ChangefeedTargetTable) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ChangefeedTargetTable) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ChangefeedTargetTable) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ChangefeedTargetTable.Merge(m, src)
}
func (m *ChangefeedTargetTable) XXX_Size() int {
	return m.Size()
}
func (m *ChangefeedTargetTable) XXX_DiscardUnknown() {
	xxx_messageInfo_ChangefeedTargetTable.DiscardUnknown(m)
}

var xxx_messageInfo_ChangefeedTargetTable proto.InternalMessageInfo

type ChangefeedTargetSpecification struct {
	Type              ChangefeedTargetSpecification_TargetType                   `protobuf:"varint,1,opt,name=type,proto3,enum=cockroach.sql.jobs.jobspb.ChangefeedTargetSpecification_TargetType" json:"type,omitempty"`
	DescID            github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,2,opt,name=descriptor_id,json=descriptorId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"descriptor_id,omitempty"`
	FamilyName        string                                                     `protobuf:"bytes,3,opt,name=family_name,json=familyName,proto3" json:"family_name,omitempty"`
	StatementTimeName string                                                     `protobuf:"bytes,4,opt,name=statement_time_name,json=statementTimeName,proto3" json:"statement_time_name,omitempty"`
}

func (m *ChangefeedTargetSpecification) Reset()         { *m = ChangefeedTargetSpecification{} }
func (m *ChangefeedTargetSpecification) String() string { return proto.CompactTextString(m) }
func (*ChangefeedTargetSpecification) ProtoMessage()    {}
func (*ChangefeedTargetSpecification) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{38}
}
func (m *ChangefeedTargetSpecification) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ChangefeedTargetSpecification) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ChangefeedTargetSpecification) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ChangefeedTargetSpecification.Merge(m, src)
}
func (m *ChangefeedTargetSpecification) XXX_Size() int {
	return m.Size()
}
func (m *ChangefeedTargetSpecification) XXX_DiscardUnknown() {
	xxx_messageInfo_ChangefeedTargetSpecification.DiscardUnknown(m)
}

var xxx_messageInfo_ChangefeedTargetSpecification proto.InternalMessageInfo

type ChangefeedDetails struct {
	// Targets contains the user-specified tables to watch, mapping
	// the descriptor id to the name at the time of changefeed creation.
	// The names at resolution time are included so that table and database
	// renames can be tolerated and derived topic names remain immutable.
	//
	Tables  ChangefeedTargets `protobuf:"bytes,6,rep,name=tables,proto3,casttype=ChangefeedTargets,castkey=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"tables" protobuf_key:"varint,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	SinkURI string            `protobuf:"bytes,3,opt,name=sink_uri,json=sinkUri,proto3" json:"sink_uri,omitempty"`
	Opts    map[string]string `protobuf:"bytes,4,rep,name=opts,proto3" json:"opts,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	// TODO(sherman): Now that we update the statement time in some situations
	// while performing an initial scan on newly added targets, StatementTime is
	// no longer a suitable name for this field. This is because the name
	// StatementTime gives off an impression that the field indicates the creation
	// time of the changefeed, which is no longer the case. We should rename this
	// field to ScanTime instead.
	StatementTime        hlc.Timestamp                   `protobuf:"bytes,7,opt,name=statement_time,json=statementTime,proto3" json:"statement_time"`
	EndTime              hlc.Timestamp                   `protobuf:"bytes,9,opt,name=end_time,json=endTime,proto3" json:"end_time"`
	TargetSpecifications []ChangefeedTargetSpecification `protobuf:"bytes,8,rep,name=target_specifications,json=targetSpecifications,proto3" json:"target_specifications"`
	Select               string                          `protobuf:"bytes,10,opt,name=select,proto3" json:"select,omitempty"`
	SessionData          *sessiondatapb.SessionData      `protobuf:"bytes,11,opt,name=session_data,json=sessionData,proto3" json:"session_data,omitempty"`
}

func (m *ChangefeedDetails) Reset()         { *m = ChangefeedDetails{} }
func (m *ChangefeedDetails) String() string { return proto.CompactTextString(m) }
func (*ChangefeedDetails) ProtoMessage()    {}
func (*ChangefeedDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{39}
}
func (m *ChangefeedDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ChangefeedDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ChangefeedDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ChangefeedDetails.Merge(m, src)
}
func (m *ChangefeedDetails) XXX_Size() int {
	return m.Size()
}
func (m *ChangefeedDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_ChangefeedDetails.DiscardUnknown(m)
}

var xxx_messageInfo_ChangefeedDetails proto.InternalMessageInfo

type ResolvedSpan struct {
	Span         roachpb.Span              `protobuf:"bytes,1,opt,name=span,proto3" json:"span"`
	Timestamp    hlc.Timestamp             `protobuf:"bytes,2,opt,name=timestamp,proto3" json:"timestamp"`
	BoundaryType ResolvedSpan_BoundaryType `protobuf:"varint,4,opt,name=boundary_type,json=boundaryType,proto3,enum=cockroach.sql.jobs.jobspb.ResolvedSpan_BoundaryType" json:"boundary_type,omitempty"`
}

func (m *ResolvedSpan) Reset()         { *m = ResolvedSpan{} }
func (m *ResolvedSpan) String() string { return proto.CompactTextString(m) }
func (*ResolvedSpan) ProtoMessage()    {}
func (*ResolvedSpan) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{40}
}
func (m *ResolvedSpan) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ResolvedSpan) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ResolvedSpan) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ResolvedSpan.Merge(m, src)
}
func (m *ResolvedSpan) XXX_Size() int {
	return m.Size()
}
func (m *ResolvedSpan) XXX_DiscardUnknown() {
	xxx_messageInfo_ResolvedSpan.DiscardUnknown(m)
}

var xxx_messageInfo_ResolvedSpan proto.InternalMessageInfo

type ResolvedSpans struct {
	ResolvedSpans []ResolvedSpan      `protobuf:"bytes,1,rep,name=resolved_spans,json=resolvedSpans,proto3" json:"resolved_spans"`
	Stats         ResolvedSpans_Stats `protobuf:"bytes,2,opt,name=stats,proto3" json:"stats"`
}

func (m *ResolvedSpans) Reset()         { *m = ResolvedSpans{} }
func (m *ResolvedSpans) String() string { return proto.CompactTextString(m) }
func (*ResolvedSpans) ProtoMessage()    {}
func (*ResolvedSpans) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{41}
}
func (m *ResolvedSpans) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ResolvedSpans) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ResolvedSpans) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ResolvedSpans.Merge(m, src)
}
func (m *ResolvedSpans) XXX_Size() int {
	return m.Size()
}
func (m *ResolvedSpans) XXX_DiscardUnknown() {
	xxx_messageInfo_ResolvedSpans.DiscardUnknown(m)
}

var xxx_messageInfo_ResolvedSpans proto.InternalMessageInfo

type ResolvedSpans_Stats struct {
	RecentKvCount uint64 `protobuf:"varint,1,opt,name=recent_kv_count,json=recentKvCount,proto3" json:"recent_kv_count,omitempty"`
}

func (m *ResolvedSpans_Stats) Reset()         { *m = ResolvedSpans_Stats{} }
func (m *ResolvedSpans_Stats) String() string { return proto.CompactTextString(m) }
func (*ResolvedSpans_Stats) ProtoMessage()    {}
func (*ResolvedSpans_Stats) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{41, 0}
}
func (m *ResolvedSpans_Stats) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ResolvedSpans_Stats) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ResolvedSpans_Stats) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ResolvedSpans_Stats.Merge(m, src)
}
func (m *ResolvedSpans_Stats) XXX_Size() int {
	return m.Size()
}
func (m *ResolvedSpans_Stats) XXX_DiscardUnknown() {
	xxx_messageInfo_ResolvedSpans_Stats.DiscardUnknown(m)
}

var xxx_messageInfo_ResolvedSpans_Stats proto.InternalMessageInfo

// TimestampSpansMap is a map from timestamps to lists of spans.
//
// You should create a go map and call NewTimestampSpansMap on it
// instead of creating one directly.
//
// NB: This can't be a protobuf map because that requires the key
// to be integral/string, but the language guide notes that this
// structure is equivalent on the wire to a map:
// https://protobuf.dev/programming-guides/proto3/#backwards.
type TimestampSpansMap struct {
	Entries []TimestampSpansMap_Entry `protobuf:"bytes,1,rep,name=entries,proto3" json:"entries"`
}

func (m *TimestampSpansMap) Reset()         { *m = TimestampSpansMap{} }
func (m *TimestampSpansMap) String() string { return proto.CompactTextString(m) }
func (*TimestampSpansMap) ProtoMessage()    {}
func (*TimestampSpansMap) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{42}
}
func (m *TimestampSpansMap) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *TimestampSpansMap) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *TimestampSpansMap) XXX_Merge(src proto.Message) {
	xxx_messageInfo_TimestampSpansMap.Merge(m, src)
}
func (m *TimestampSpansMap) XXX_Size() int {
	return m.Size()
}
func (m *TimestampSpansMap) XXX_DiscardUnknown() {
	xxx_messageInfo_TimestampSpansMap.DiscardUnknown(m)
}

var xxx_messageInfo_TimestampSpansMap proto.InternalMessageInfo

type TimestampSpansMap_Entry struct {
	Timestamp hlc.Timestamp  `protobuf:"bytes,1,opt,name=timestamp,proto3" json:"timestamp"`
	Spans     []roachpb.Span `protobuf:"bytes,2,rep,name=spans,proto3" json:"spans"`
}

func (m *TimestampSpansMap_Entry) Reset()         { *m = TimestampSpansMap_Entry{} }
func (m *TimestampSpansMap_Entry) String() string { return proto.CompactTextString(m) }
func (*TimestampSpansMap_Entry) ProtoMessage()    {}
func (*TimestampSpansMap_Entry) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{42, 0}
}
func (m *TimestampSpansMap_Entry) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *TimestampSpansMap_Entry) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *TimestampSpansMap_Entry) XXX_Merge(src proto.Message) {
	xxx_messageInfo_TimestampSpansMap_Entry.Merge(m, src)
}
func (m *TimestampSpansMap_Entry) XXX_Size() int {
	return m.Size()
}
func (m *TimestampSpansMap_Entry) XXX_DiscardUnknown() {
	xxx_messageInfo_TimestampSpansMap_Entry.DiscardUnknown(m)
}

var xxx_messageInfo_TimestampSpansMap_Entry proto.InternalMessageInfo

type ChangefeedProgress struct {
	// ProtectedTimestampRecord is the ID of the protected timestamp record
	// corresponding to this job. While the job ought to clean up the record
	// when it enters a terminal state, there may be cases where it cannot or
	// does not run the code to do so. To deal with this there is a background
	// reconciliation loop to ensure that protected timestamps are cleaned up.
	//
	// A record is created with the job if the job requires an initial backfill.
	// Furthermore, once subsequent backfills begin, record will be created and
	// released accordingly.
	ProtectedTimestampRecord github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,3,opt,name=protected_timestamp_record,json=protectedTimestampRecord,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"protected_timestamp_record"`
	// SpanLevelCheckpoint is the span-level checkpoint for a changefeed.
	// It consists of a map from resolved timestamps to lists of spans
	// with that resolved timestamp.
	//
	// On restart, the changefeed can restore the progress of spans in the
	// checkpoint to its corresponding resolved timestamp, which will be higher
	// than the overall resolved timestamp and thus allow us to do less work.
	// This is especially useful during backfills or if some spans are lagging.
	//
	// Invariant: At most one of Checkpoint and SpanLevelCheckpoint should be
	// non-nil at any time.
	SpanLevelCheckpoint *TimestampSpansMap `protobuf:"bytes,5,opt,name=span_level_checkpoint,json=spanLevelCheckpoint,proto3" json:"span_level_checkpoint,omitempty"`
}

func (m *ChangefeedProgress) Reset()         { *m = ChangefeedProgress{} }
func (m *ChangefeedProgress) String() string { return proto.CompactTextString(m) }
func (*ChangefeedProgress) ProtoMessage()    {}
func (*ChangefeedProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{43}
}
func (m *ChangefeedProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ChangefeedProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ChangefeedProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ChangefeedProgress.Merge(m, src)
}
func (m *ChangefeedProgress) XXX_Size() int {
	return m.Size()
}
func (m *ChangefeedProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_ChangefeedProgress.DiscardUnknown(m)
}

var xxx_messageInfo_ChangefeedProgress proto.InternalMessageInfo

// CreateStatsDetails are used for the CreateStats job, which is triggered
// whenever the `CREATE STATISTICS` SQL statement is run. The CreateStats job
// collects table statistics, which contain info such as the number of rows in
// the table or the number of distinct values in a column.
type CreateStatsDetails struct {
	Name            string                       `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Table           descpb.TableDescriptor       `protobuf:"bytes,2,opt,name=table,proto3" json:"table"`
	ColumnStats     []CreateStatsDetails_ColStat `protobuf:"bytes,3,rep,name=column_stats,json=columnStats,proto3" json:"column_stats"`
	Statement       string                       `protobuf:"bytes,4,opt,name=statement,proto3" json:"statement,omitempty"`
	AsOf            *hlc.Timestamp               `protobuf:"bytes,5,opt,name=as_of,json=asOf,proto3" json:"as_of,omitempty"`
	MaxFractionIdle float64                      `protobuf:"fixed64,7,opt,name=max_fraction_idle,json=maxFractionIdle,proto3" json:"max_fraction_idle,omitempty"`
	// Fully qualified table name.
	FQTableName string `protobuf:"bytes,6,opt,name=fq_table_name,json=fqTableName,proto3" json:"fq_table_name,omitempty"`
	// If true, delete old stats for columns not included in this message.
	DeleteOtherStats bool `protobuf:"varint,8,opt,name=delete_other_stats,json=deleteOtherStats,proto3" json:"delete_other_stats,omitempty"`
	// If true, will collect partial table statistics at extreme values.
	UsingExtremes bool `protobuf:"varint,9,opt,name=using_extremes,json=usingExtremes,proto3" json:"using_extremes,omitempty"`
	// WHERE clause for partial statistics collection. This field is only used
	// to populate the predicate in the system.table_statistics table and to
	// determine if this is a constrained stats collection. The actual constrained
	// scan is done over the spans in the where_spans field.
	WhereClause string `protobuf:"bytes,10,opt,name=where_clause,json=whereClause,proto3" json:"where_clause,omitempty"`
	// Spans over which to collect partial statistics with a WHERE clause.
	WhereSpans []roachpb.Span `protobuf:"bytes,11,rep,name=where_spans,json=whereSpans,proto3" json:"where_spans"`
	// The ID of the index used to collect partial statistics with a WHERE clause.
	WhereIndexID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID `protobuf:"varint,12,opt,name=where_index_id,json=whereIndexId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.IndexID" json:"where_index_id,omitempty"`
}

func (m *CreateStatsDetails) Reset()         { *m = CreateStatsDetails{} }
func (m *CreateStatsDetails) String() string { return proto.CompactTextString(m) }
func (*CreateStatsDetails) ProtoMessage()    {}
func (*CreateStatsDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{44}
}
func (m *CreateStatsDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *CreateStatsDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *CreateStatsDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CreateStatsDetails.Merge(m, src)
}
func (m *CreateStatsDetails) XXX_Size() int {
	return m.Size()
}
func (m *CreateStatsDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_CreateStatsDetails.DiscardUnknown(m)
}

var xxx_messageInfo_CreateStatsDetails proto.InternalMessageInfo

type CreateStatsDetails_ColStat struct {
	ColumnIDs []github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ColumnID `protobuf:"varint,1,rep,packed,name=column_ids,json=columnIds,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ColumnID" json:"column_ids,omitempty"`
	// Indicates whether this column stat should include a histogram.
	HasHistogram bool `protobuf:"varint,2,opt,name=has_histogram,json=hasHistogram,proto3" json:"has_histogram,omitempty"`
	// Indicates whether this column stat is over an inverted index.
	Inverted bool `protobuf:"varint,3,opt,name=inverted,proto3" json:"inverted,omitempty"`
	// If this column stat includes a histogram, indicates the maximum number
	// of buckets that should be created. If this field is unset, a default
	// maximum of 200 buckets are created.
	HistogramMaxBuckets uint32 `protobuf:"varint,4,opt,name=histogram_max_buckets,json=histogramMaxBuckets,proto3" json:"histogram_max_buckets,omitempty"`
}

func (m *CreateStatsDetails_ColStat) Reset()         { *m = CreateStatsDetails_ColStat{} }
func (m *CreateStatsDetails_ColStat) String() string { return proto.CompactTextString(m) }
func (*CreateStatsDetails_ColStat) ProtoMessage()    {}
func (*CreateStatsDetails_ColStat) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{44, 0}
}
func (m *CreateStatsDetails_ColStat) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *CreateStatsDetails_ColStat) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *CreateStatsDetails_ColStat) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CreateStatsDetails_ColStat.Merge(m, src)
}
func (m *CreateStatsDetails_ColStat) XXX_Size() int {
	return m.Size()
}
func (m *CreateStatsDetails_ColStat) XXX_DiscardUnknown() {
	xxx_messageInfo_CreateStatsDetails_ColStat.DiscardUnknown(m)
}

var xxx_messageInfo_CreateStatsDetails_ColStat proto.InternalMessageInfo

type CreateStatsProgress struct {
}

func (m *CreateStatsProgress) Reset()         { *m = CreateStatsProgress{} }
func (m *CreateStatsProgress) String() string { return proto.CompactTextString(m) }
func (*CreateStatsProgress) ProtoMessage()    {}
func (*CreateStatsProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{45}
}
func (m *CreateStatsProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *CreateStatsProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *CreateStatsProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CreateStatsProgress.Merge(m, src)
}
func (m *CreateStatsProgress) XXX_Size() int {
	return m.Size()
}
func (m *CreateStatsProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_CreateStatsProgress.DiscardUnknown(m)
}

var xxx_messageInfo_CreateStatsProgress proto.InternalMessageInfo

type MigrationDetails struct {
	ClusterVersion *clusterversion.ClusterVersion `protobuf:"bytes,1,opt,name=cluster_version,json=clusterVersion,proto3" json:"cluster_version,omitempty"`
}

func (m *MigrationDetails) Reset()         { *m = MigrationDetails{} }
func (m *MigrationDetails) String() string { return proto.CompactTextString(m) }
func (*MigrationDetails) ProtoMessage()    {}
func (*MigrationDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{46}
}
func (m *MigrationDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *MigrationDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *MigrationDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MigrationDetails.Merge(m, src)
}
func (m *MigrationDetails) XXX_Size() int {
	return m.Size()
}
func (m *MigrationDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_MigrationDetails.DiscardUnknown(m)
}

var xxx_messageInfo_MigrationDetails proto.InternalMessageInfo

type MigrationProgress struct {
	Watermark []byte `protobuf:"bytes,1,opt,name=watermark,proto3" json:"watermark,omitempty"`
}

func (m *MigrationProgress) Reset()         { *m = MigrationProgress{} }
func (m *MigrationProgress) String() string { return proto.CompactTextString(m) }
func (*MigrationProgress) ProtoMessage()    {}
func (*MigrationProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{47}
}
func (m *MigrationProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *MigrationProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *MigrationProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MigrationProgress.Merge(m, src)
}
func (m *MigrationProgress) XXX_Size() int {
	return m.Size()
}
func (m *MigrationProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_MigrationProgress.DiscardUnknown(m)
}

var xxx_messageInfo_MigrationProgress proto.InternalMessageInfo

type AutoSQLStatsCompactionDetails struct {
}

func (m *AutoSQLStatsCompactionDetails) Reset()         { *m = AutoSQLStatsCompactionDetails{} }
func (m *AutoSQLStatsCompactionDetails) String() string { return proto.CompactTextString(m) }
func (*AutoSQLStatsCompactionDetails) ProtoMessage()    {}
func (*AutoSQLStatsCompactionDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{48}
}
func (m *AutoSQLStatsCompactionDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoSQLStatsCompactionDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoSQLStatsCompactionDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoSQLStatsCompactionDetails.Merge(m, src)
}
func (m *AutoSQLStatsCompactionDetails) XXX_Size() int {
	return m.Size()
}
func (m *AutoSQLStatsCompactionDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoSQLStatsCompactionDetails.DiscardUnknown(m)
}

var xxx_messageInfo_AutoSQLStatsCompactionDetails proto.InternalMessageInfo

type AutoSQLStatsCompactionProgress struct {
}

func (m *AutoSQLStatsCompactionProgress) Reset()         { *m = AutoSQLStatsCompactionProgress{} }
func (m *AutoSQLStatsCompactionProgress) String() string { return proto.CompactTextString(m) }
func (*AutoSQLStatsCompactionProgress) ProtoMessage()    {}
func (*AutoSQLStatsCompactionProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{49}
}
func (m *AutoSQLStatsCompactionProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoSQLStatsCompactionProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoSQLStatsCompactionProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoSQLStatsCompactionProgress.Merge(m, src)
}
func (m *AutoSQLStatsCompactionProgress) XXX_Size() int {
	return m.Size()
}
func (m *AutoSQLStatsCompactionProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoSQLStatsCompactionProgress.DiscardUnknown(m)
}

var xxx_messageInfo_AutoSQLStatsCompactionProgress proto.InternalMessageInfo

type RowLevelTTLDetails struct {
	// TableID is the ID of the table that the TTL job removes records from.
	TableID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,1,opt,name=table_id,json=tableId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"table_id,omitempty"`
	// Cutoff is compared against execinfrapb.TTLSpec.TTLExpr by the
	// ttlProcessor to determine what records to delete. Records are deleted
	// if TTLExpr <= Cutoff.
	Cutoff time.Time `protobuf:"bytes,2,opt,name=cutoff,proto3,stdtime" json:"cutoff"`
	// TableVersion is the table descriptor version of the table when the TTLJob
	// started.
	TableVersion github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.DescriptorVersion `protobuf:"varint,3,opt,name=table_version,json=tableVersion,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.DescriptorVersion" json:"table_version,omitempty"`
}

func (m *RowLevelTTLDetails) Reset()         { *m = RowLevelTTLDetails{} }
func (m *RowLevelTTLDetails) String() string { return proto.CompactTextString(m) }
func (*RowLevelTTLDetails) ProtoMessage()    {}
func (*RowLevelTTLDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{50}
}
func (m *RowLevelTTLDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *RowLevelTTLDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *RowLevelTTLDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RowLevelTTLDetails.Merge(m, src)
}
func (m *RowLevelTTLDetails) XXX_Size() int {
	return m.Size()
}
func (m *RowLevelTTLDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_RowLevelTTLDetails.DiscardUnknown(m)
}

var xxx_messageInfo_RowLevelTTLDetails proto.InternalMessageInfo

type RowLevelTTLProgress struct {
	// JobDeletedRowCount is the number of rows deleted by TTL job so far.
	JobDeletedRowCount int64 `protobuf:"varint,1,opt,name=job_deleted_row_count,json=jobDeletedRowCount,proto3" json:"job_deleted_row_count,omitempty"`
	// ProcessorProgresses is the progress per DistSQL processor.
	ProcessorProgresses []RowLevelTTLProcessorProgress `protobuf:"bytes,2,rep,name=processor_progresses,json=processorProgresses,proto3" json:"processor_progresses"`
	// JobTotalSpanCount is the number of spans for the entire TTL job.
	JobTotalSpanCount int64 `protobuf:"varint,4,opt,name=job_total_span_count,json=jobTotalSpanCount,proto3" json:"job_total_span_count,omitempty"`
	// JobProcessedSpanCount is the number of spans that have been processed by
	// the TTL job so far.
	JobProcessedSpanCount int64 `protobuf:"varint,5,opt,name=job_processed_span_count,json=jobProcessedSpanCount,proto3" json:"job_processed_span_count,omitempty"`
}

func (m *RowLevelTTLProgress) Reset()         { *m = RowLevelTTLProgress{} }
func (m *RowLevelTTLProgress) String() string { return proto.CompactTextString(m) }
func (*RowLevelTTLProgress) ProtoMessage()    {}
func (*RowLevelTTLProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{51}
}
func (m *RowLevelTTLProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *RowLevelTTLProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *RowLevelTTLProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RowLevelTTLProgress.Merge(m, src)
}
func (m *RowLevelTTLProgress) XXX_Size() int {
	return m.Size()
}
func (m *RowLevelTTLProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_RowLevelTTLProgress.DiscardUnknown(m)
}

var xxx_messageInfo_RowLevelTTLProgress proto.InternalMessageInfo

type RowLevelTTLProcessorProgress struct {
	// ProcessorID is the ID of the DistSQL processor.
	ProcessorID int32 `protobuf:"varint,1,opt,name=processor_id,json=processorId,proto3" json:"processor_id,omitempty"`
	// SQLInstanceID is the instance ID of the DistSQL processor.
	SQLInstanceID github_com_cockroachdb_cockroach_pkg_base.SQLInstanceID `protobuf:"varint,2,opt,name=sql_instance_id,json=sqlInstanceId,proto3,customtype=github.com/cockroachdb/cockroach/pkg/base.SQLInstanceID" json:"sql_instance_id"`
	// DeletedRowCount is the number of rows deleted by this DistSQL processor.
	DeletedRowCount int64 `protobuf:"varint,3,opt,name=deleted_row_count,json=deletedRowCount,proto3" json:"deleted_row_count,omitempty"`
	// TotalSpanCount is the total number of spans assigned to the DistSQL processor.
	TotalSpanCount int64 `protobuf:"varint,4,opt,name=total_span_count,json=totalSpanCount,proto3" json:"total_span_count,omitempty"`
	// ProcessedSpanCount is the number of spans already processed.
	ProcessedSpanCount int64 `protobuf:"varint,6,opt,name=processed_span_count,json=processedSpanCount,proto3" json:"processed_span_count,omitempty"`
	// ProcessorConcurrency is the number parallel tasks the processor will do at once.
	ProcessorConcurrency int64 `protobuf:"varint,5,opt,name=processor_concurrency,json=processorConcurrency,proto3" json:"processor_concurrency,omitempty"`
}

func (m *RowLevelTTLProcessorProgress) Reset()         { *m = RowLevelTTLProcessorProgress{} }
func (m *RowLevelTTLProcessorProgress) String() string { return proto.CompactTextString(m) }
func (*RowLevelTTLProcessorProgress) ProtoMessage()    {}
func (*RowLevelTTLProcessorProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{52}
}
func (m *RowLevelTTLProcessorProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *RowLevelTTLProcessorProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *RowLevelTTLProcessorProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RowLevelTTLProcessorProgress.Merge(m, src)
}
func (m *RowLevelTTLProcessorProgress) XXX_Size() int {
	return m.Size()
}
func (m *RowLevelTTLProcessorProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_RowLevelTTLProcessorProgress.DiscardUnknown(m)
}

var xxx_messageInfo_RowLevelTTLProcessorProgress proto.InternalMessageInfo

type SchemaTelemetryDetails struct {
}

func (m *SchemaTelemetryDetails) Reset()         { *m = SchemaTelemetryDetails{} }
func (m *SchemaTelemetryDetails) String() string { return proto.CompactTextString(m) }
func (*SchemaTelemetryDetails) ProtoMessage()    {}
func (*SchemaTelemetryDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{53}
}
func (m *SchemaTelemetryDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaTelemetryDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaTelemetryDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaTelemetryDetails.Merge(m, src)
}
func (m *SchemaTelemetryDetails) XXX_Size() int {
	return m.Size()
}
func (m *SchemaTelemetryDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaTelemetryDetails.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaTelemetryDetails proto.InternalMessageInfo

type SchemaTelemetryProgress struct {
}

func (m *SchemaTelemetryProgress) Reset()         { *m = SchemaTelemetryProgress{} }
func (m *SchemaTelemetryProgress) String() string { return proto.CompactTextString(m) }
func (*SchemaTelemetryProgress) ProtoMessage()    {}
func (*SchemaTelemetryProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{54}
}
func (m *SchemaTelemetryProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SchemaTelemetryProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SchemaTelemetryProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SchemaTelemetryProgress.Merge(m, src)
}
func (m *SchemaTelemetryProgress) XXX_Size() int {
	return m.Size()
}
func (m *SchemaTelemetryProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_SchemaTelemetryProgress.DiscardUnknown(m)
}

var xxx_messageInfo_SchemaTelemetryProgress proto.InternalMessageInfo

type PollJobsStatsDetails struct {
}

func (m *PollJobsStatsDetails) Reset()         { *m = PollJobsStatsDetails{} }
func (m *PollJobsStatsDetails) String() string { return proto.CompactTextString(m) }
func (*PollJobsStatsDetails) ProtoMessage()    {}
func (*PollJobsStatsDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{55}
}
func (m *PollJobsStatsDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *PollJobsStatsDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *PollJobsStatsDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_PollJobsStatsDetails.Merge(m, src)
}
func (m *PollJobsStatsDetails) XXX_Size() int {
	return m.Size()
}
func (m *PollJobsStatsDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_PollJobsStatsDetails.DiscardUnknown(m)
}

var xxx_messageInfo_PollJobsStatsDetails proto.InternalMessageInfo

type PollJobsStatsProgress struct {
}

func (m *PollJobsStatsProgress) Reset()         { *m = PollJobsStatsProgress{} }
func (m *PollJobsStatsProgress) String() string { return proto.CompactTextString(m) }
func (*PollJobsStatsProgress) ProtoMessage()    {}
func (*PollJobsStatsProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{56}
}
func (m *PollJobsStatsProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *PollJobsStatsProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *PollJobsStatsProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_PollJobsStatsProgress.Merge(m, src)
}
func (m *PollJobsStatsProgress) XXX_Size() int {
	return m.Size()
}
func (m *PollJobsStatsProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_PollJobsStatsProgress.DiscardUnknown(m)
}

var xxx_messageInfo_PollJobsStatsProgress proto.InternalMessageInfo

type AutoConfigRunnerDetails struct {
}

func (m *AutoConfigRunnerDetails) Reset()         { *m = AutoConfigRunnerDetails{} }
func (m *AutoConfigRunnerDetails) String() string { return proto.CompactTextString(m) }
func (*AutoConfigRunnerDetails) ProtoMessage()    {}
func (*AutoConfigRunnerDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{57}
}
func (m *AutoConfigRunnerDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoConfigRunnerDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoConfigRunnerDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoConfigRunnerDetails.Merge(m, src)
}
func (m *AutoConfigRunnerDetails) XXX_Size() int {
	return m.Size()
}
func (m *AutoConfigRunnerDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoConfigRunnerDetails.DiscardUnknown(m)
}

var xxx_messageInfo_AutoConfigRunnerDetails proto.InternalMessageInfo

type AutoConfigRunnerProgress struct {
}

func (m *AutoConfigRunnerProgress) Reset()         { *m = AutoConfigRunnerProgress{} }
func (m *AutoConfigRunnerProgress) String() string { return proto.CompactTextString(m) }
func (*AutoConfigRunnerProgress) ProtoMessage()    {}
func (*AutoConfigRunnerProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{58}
}
func (m *AutoConfigRunnerProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoConfigRunnerProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoConfigRunnerProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoConfigRunnerProgress.Merge(m, src)
}
func (m *AutoConfigRunnerProgress) XXX_Size() int {
	return m.Size()
}
func (m *AutoConfigRunnerProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoConfigRunnerProgress.DiscardUnknown(m)
}

var xxx_messageInfo_AutoConfigRunnerProgress proto.InternalMessageInfo

type AutoConfigEnvRunnerDetails struct {
}

func (m *AutoConfigEnvRunnerDetails) Reset()         { *m = AutoConfigEnvRunnerDetails{} }
func (m *AutoConfigEnvRunnerDetails) String() string { return proto.CompactTextString(m) }
func (*AutoConfigEnvRunnerDetails) ProtoMessage()    {}
func (*AutoConfigEnvRunnerDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{59}
}
func (m *AutoConfigEnvRunnerDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoConfigEnvRunnerDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoConfigEnvRunnerDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoConfigEnvRunnerDetails.Merge(m, src)
}
func (m *AutoConfigEnvRunnerDetails) XXX_Size() int {
	return m.Size()
}
func (m *AutoConfigEnvRunnerDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoConfigEnvRunnerDetails.DiscardUnknown(m)
}

var xxx_messageInfo_AutoConfigEnvRunnerDetails proto.InternalMessageInfo

type AutoConfigEnvRunnerProgress struct {
}

func (m *AutoConfigEnvRunnerProgress) Reset()         { *m = AutoConfigEnvRunnerProgress{} }
func (m *AutoConfigEnvRunnerProgress) String() string { return proto.CompactTextString(m) }
func (*AutoConfigEnvRunnerProgress) ProtoMessage()    {}
func (*AutoConfigEnvRunnerProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{60}
}
func (m *AutoConfigEnvRunnerProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoConfigEnvRunnerProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoConfigEnvRunnerProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoConfigEnvRunnerProgress.Merge(m, src)
}
func (m *AutoConfigEnvRunnerProgress) XXX_Size() int {
	return m.Size()
}
func (m *AutoConfigEnvRunnerProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoConfigEnvRunnerProgress.DiscardUnknown(m)
}

var xxx_messageInfo_AutoConfigEnvRunnerProgress proto.InternalMessageInfo

type AutoConfigTaskDetails struct {
}

func (m *AutoConfigTaskDetails) Reset()         { *m = AutoConfigTaskDetails{} }
func (m *AutoConfigTaskDetails) String() string { return proto.CompactTextString(m) }
func (*AutoConfigTaskDetails) ProtoMessage()    {}
func (*AutoConfigTaskDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{61}
}
func (m *AutoConfigTaskDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoConfigTaskDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoConfigTaskDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoConfigTaskDetails.Merge(m, src)
}
func (m *AutoConfigTaskDetails) XXX_Size() int {
	return m.Size()
}
func (m *AutoConfigTaskDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoConfigTaskDetails.DiscardUnknown(m)
}

var xxx_messageInfo_AutoConfigTaskDetails proto.InternalMessageInfo

type AutoConfigTaskProgress struct {
}

func (m *AutoConfigTaskProgress) Reset()         { *m = AutoConfigTaskProgress{} }
func (m *AutoConfigTaskProgress) String() string { return proto.CompactTextString(m) }
func (*AutoConfigTaskProgress) ProtoMessage()    {}
func (*AutoConfigTaskProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{62}
}
func (m *AutoConfigTaskProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoConfigTaskProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoConfigTaskProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoConfigTaskProgress.Merge(m, src)
}
func (m *AutoConfigTaskProgress) XXX_Size() int {
	return m.Size()
}
func (m *AutoConfigTaskProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoConfigTaskProgress.DiscardUnknown(m)
}

var xxx_messageInfo_AutoConfigTaskProgress proto.InternalMessageInfo

type AutoUpdateSQLActivityDetails struct {
}

func (m *AutoUpdateSQLActivityDetails) Reset()         { *m = AutoUpdateSQLActivityDetails{} }
func (m *AutoUpdateSQLActivityDetails) String() string { return proto.CompactTextString(m) }
func (*AutoUpdateSQLActivityDetails) ProtoMessage()    {}
func (*AutoUpdateSQLActivityDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{63}
}
func (m *AutoUpdateSQLActivityDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoUpdateSQLActivityDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoUpdateSQLActivityDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoUpdateSQLActivityDetails.Merge(m, src)
}
func (m *AutoUpdateSQLActivityDetails) XXX_Size() int {
	return m.Size()
}
func (m *AutoUpdateSQLActivityDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoUpdateSQLActivityDetails.DiscardUnknown(m)
}

var xxx_messageInfo_AutoUpdateSQLActivityDetails proto.InternalMessageInfo

type AutoUpdateSQLActivityProgress struct {
}

func (m *AutoUpdateSQLActivityProgress) Reset()         { *m = AutoUpdateSQLActivityProgress{} }
func (m *AutoUpdateSQLActivityProgress) String() string { return proto.CompactTextString(m) }
func (*AutoUpdateSQLActivityProgress) ProtoMessage()    {}
func (*AutoUpdateSQLActivityProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{64}
}
func (m *AutoUpdateSQLActivityProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AutoUpdateSQLActivityProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *AutoUpdateSQLActivityProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AutoUpdateSQLActivityProgress.Merge(m, src)
}
func (m *AutoUpdateSQLActivityProgress) XXX_Size() int {
	return m.Size()
}
func (m *AutoUpdateSQLActivityProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_AutoUpdateSQLActivityProgress.DiscardUnknown(m)
}

var xxx_messageInfo_AutoUpdateSQLActivityProgress proto.InternalMessageInfo

type MVCCStatisticsJobDetails struct {
}

func (m *MVCCStatisticsJobDetails) Reset()         { *m = MVCCStatisticsJobDetails{} }
func (m *MVCCStatisticsJobDetails) String() string { return proto.CompactTextString(m) }
func (*MVCCStatisticsJobDetails) ProtoMessage()    {}
func (*MVCCStatisticsJobDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{65}
}
func (m *MVCCStatisticsJobDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *MVCCStatisticsJobDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *MVCCStatisticsJobDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MVCCStatisticsJobDetails.Merge(m, src)
}
func (m *MVCCStatisticsJobDetails) XXX_Size() int {
	return m.Size()
}
func (m *MVCCStatisticsJobDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_MVCCStatisticsJobDetails.DiscardUnknown(m)
}

var xxx_messageInfo_MVCCStatisticsJobDetails proto.InternalMessageInfo

type MVCCStatisticsJobProgress struct {
}

func (m *MVCCStatisticsJobProgress) Reset()         { *m = MVCCStatisticsJobProgress{} }
func (m *MVCCStatisticsJobProgress) String() string { return proto.CompactTextString(m) }
func (*MVCCStatisticsJobProgress) ProtoMessage()    {}
func (*MVCCStatisticsJobProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{66}
}
func (m *MVCCStatisticsJobProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *MVCCStatisticsJobProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *MVCCStatisticsJobProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MVCCStatisticsJobProgress.Merge(m, src)
}
func (m *MVCCStatisticsJobProgress) XXX_Size() int {
	return m.Size()
}
func (m *MVCCStatisticsJobProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_MVCCStatisticsJobProgress.DiscardUnknown(m)
}

var xxx_messageInfo_MVCCStatisticsJobProgress proto.InternalMessageInfo

type StandbyReadTSPollerDetails struct {
}

func (m *StandbyReadTSPollerDetails) Reset()         { *m = StandbyReadTSPollerDetails{} }
func (m *StandbyReadTSPollerDetails) String() string { return proto.CompactTextString(m) }
func (*StandbyReadTSPollerDetails) ProtoMessage()    {}
func (*StandbyReadTSPollerDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{67}
}
func (m *StandbyReadTSPollerDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *StandbyReadTSPollerDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *StandbyReadTSPollerDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_StandbyReadTSPollerDetails.Merge(m, src)
}
func (m *StandbyReadTSPollerDetails) XXX_Size() int {
	return m.Size()
}
func (m *StandbyReadTSPollerDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_StandbyReadTSPollerDetails.DiscardUnknown(m)
}

var xxx_messageInfo_StandbyReadTSPollerDetails proto.InternalMessageInfo

type StandbyReadTSPollerProgress struct {
}

func (m *StandbyReadTSPollerProgress) Reset()         { *m = StandbyReadTSPollerProgress{} }
func (m *StandbyReadTSPollerProgress) String() string { return proto.CompactTextString(m) }
func (*StandbyReadTSPollerProgress) ProtoMessage()    {}
func (*StandbyReadTSPollerProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{68}
}
func (m *StandbyReadTSPollerProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *StandbyReadTSPollerProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *StandbyReadTSPollerProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_StandbyReadTSPollerProgress.Merge(m, src)
}
func (m *StandbyReadTSPollerProgress) XXX_Size() int {
	return m.Size()
}
func (m *StandbyReadTSPollerProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_StandbyReadTSPollerProgress.DiscardUnknown(m)
}

var xxx_messageInfo_StandbyReadTSPollerProgress proto.InternalMessageInfo

type HotRangesLoggerDetails struct {
}

func (m *HotRangesLoggerDetails) Reset()         { *m = HotRangesLoggerDetails{} }
func (m *HotRangesLoggerDetails) String() string { return proto.CompactTextString(m) }
func (*HotRangesLoggerDetails) ProtoMessage()    {}
func (*HotRangesLoggerDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{69}
}
func (m *HotRangesLoggerDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *HotRangesLoggerDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *HotRangesLoggerDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_HotRangesLoggerDetails.Merge(m, src)
}
func (m *HotRangesLoggerDetails) XXX_Size() int {
	return m.Size()
}
func (m *HotRangesLoggerDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_HotRangesLoggerDetails.DiscardUnknown(m)
}

var xxx_messageInfo_HotRangesLoggerDetails proto.InternalMessageInfo

type InspectDetails struct {
	// Checks is the list of individual checks this job will perform.
	Checks []*InspectDetails_Check `protobuf:"bytes,1,rep,name=checks,proto3" json:"checks,omitempty"`
	// AsOf specifies the timestamp at which the inspect checks should be performed.
	AsOf hlc.Timestamp `protobuf:"bytes,2,opt,name=as_of,json=asOf,proto3" json:"as_of"`
}

func (m *InspectDetails) Reset()         { *m = InspectDetails{} }
func (m *InspectDetails) String() string { return proto.CompactTextString(m) }
func (*InspectDetails) ProtoMessage()    {}
func (*InspectDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{70}
}
func (m *InspectDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *InspectDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *InspectDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_InspectDetails.Merge(m, src)
}
func (m *InspectDetails) XXX_Size() int {
	return m.Size()
}
func (m *InspectDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_InspectDetails.DiscardUnknown(m)
}

var xxx_messageInfo_InspectDetails proto.InternalMessageInfo

// Check represents a single validation task to perform as part of an INSPECT
// job. Each check targets a specific table or index and is associated with a
// validation type.
type InspectDetails_Check struct {
	// Type is the kind of validation to perform.
	Type InspectDetails_Check_InspectCheckType `protobuf:"varint,1,opt,name=type,proto3,enum=cockroach.sql.jobs.jobspb.InspectDetails_Check_InspectCheckType" json:"type,omitempty"`
	// TableID identifies the table this check applies to.
	TableID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,2,opt,name=table_id,json=tableId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"table_id,omitempty"`
	// IndexID identifies the specific index to check, if applicable. Only
	// relevant for check types that operate at the index level. Should be unset
	// or ignored for table-level checks.
	IndexID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID `protobuf:"varint,3,opt,name=index_id,json=indexId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.IndexID" json:"index_id,omitempty"`
}

func (m *InspectDetails_Check) Reset()         { *m = InspectDetails_Check{} }
func (m *InspectDetails_Check) String() string { return proto.CompactTextString(m) }
func (*InspectDetails_Check) ProtoMessage()    {}
func (*InspectDetails_Check) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{70, 0}
}
func (m *InspectDetails_Check) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *InspectDetails_Check) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *InspectDetails_Check) XXX_Merge(src proto.Message) {
	xxx_messageInfo_InspectDetails_Check.Merge(m, src)
}
func (m *InspectDetails_Check) XXX_Size() int {
	return m.Size()
}
func (m *InspectDetails_Check) XXX_DiscardUnknown() {
	xxx_messageInfo_InspectDetails_Check.DiscardUnknown(m)
}

var xxx_messageInfo_InspectDetails_Check proto.InternalMessageInfo

type UpdateTableMetadataCacheDetails struct {
}

func (m *UpdateTableMetadataCacheDetails) Reset()         { *m = UpdateTableMetadataCacheDetails{} }
func (m *UpdateTableMetadataCacheDetails) String() string { return proto.CompactTextString(m) }
func (*UpdateTableMetadataCacheDetails) ProtoMessage()    {}
func (*UpdateTableMetadataCacheDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{71}
}
func (m *UpdateTableMetadataCacheDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *UpdateTableMetadataCacheDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *UpdateTableMetadataCacheDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_UpdateTableMetadataCacheDetails.Merge(m, src)
}
func (m *UpdateTableMetadataCacheDetails) XXX_Size() int {
	return m.Size()
}
func (m *UpdateTableMetadataCacheDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_UpdateTableMetadataCacheDetails.DiscardUnknown(m)
}

var xxx_messageInfo_UpdateTableMetadataCacheDetails proto.InternalMessageInfo

type UpdateTableMetadataCacheProgress struct {
	// The time at which the job last started a run.
	LastStartTime *time.Time `protobuf:"bytes,1,opt,name=last_start_time,json=lastStartTime,proto3,stdtime" json:"last_start_time,omitempty"`
	// The time at which the job last completed a run.
	LastCompletedTime *time.Time                              `protobuf:"bytes,2,opt,name=last_completed_time,json=lastCompletedTime,proto3,stdtime" json:"last_completed_time,omitempty"`
	Status            UpdateTableMetadataCacheProgress_Status `protobuf:"varint,3,opt,name=status,proto3,enum=cockroach.sql.jobs.jobspb.UpdateTableMetadataCacheProgress_Status" json:"status,omitempty"`
}

func (m *UpdateTableMetadataCacheProgress) Reset()         { *m = UpdateTableMetadataCacheProgress{} }
func (m *UpdateTableMetadataCacheProgress) String() string { return proto.CompactTextString(m) }
func (*UpdateTableMetadataCacheProgress) ProtoMessage()    {}
func (*UpdateTableMetadataCacheProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{72}
}
func (m *UpdateTableMetadataCacheProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *UpdateTableMetadataCacheProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *UpdateTableMetadataCacheProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_UpdateTableMetadataCacheProgress.Merge(m, src)
}
func (m *UpdateTableMetadataCacheProgress) XXX_Size() int {
	return m.Size()
}
func (m *UpdateTableMetadataCacheProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_UpdateTableMetadataCacheProgress.DiscardUnknown(m)
}

var xxx_messageInfo_UpdateTableMetadataCacheProgress proto.InternalMessageInfo

type ImportRollbackDetails struct {
	// TableID is the descriptor ID of table that should be rolled back.
	//
	// TODO(ssd): We could consider having this job process multiple
	// tables.
	TableID github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,1,opt,name=table_id,json=tableId,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"table_id,omitempty"`
}

func (m *ImportRollbackDetails) Reset()         { *m = ImportRollbackDetails{} }
func (m *ImportRollbackDetails) String() string { return proto.CompactTextString(m) }
func (*ImportRollbackDetails) ProtoMessage()    {}
func (*ImportRollbackDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{73}
}
func (m *ImportRollbackDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ImportRollbackDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ImportRollbackDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ImportRollbackDetails.Merge(m, src)
}
func (m *ImportRollbackDetails) XXX_Size() int {
	return m.Size()
}
func (m *ImportRollbackDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_ImportRollbackDetails.DiscardUnknown(m)
}

var xxx_messageInfo_ImportRollbackDetails proto.InternalMessageInfo

type SqlActivityFlushDetails struct {
}

func (m *SqlActivityFlushDetails) Reset()         { *m = SqlActivityFlushDetails{} }
func (m *SqlActivityFlushDetails) String() string { return proto.CompactTextString(m) }
func (*SqlActivityFlushDetails) ProtoMessage()    {}
func (*SqlActivityFlushDetails) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{74}
}
func (m *SqlActivityFlushDetails) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SqlActivityFlushDetails) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SqlActivityFlushDetails) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SqlActivityFlushDetails.Merge(m, src)
}
func (m *SqlActivityFlushDetails) XXX_Size() int {
	return m.Size()
}
func (m *SqlActivityFlushDetails) XXX_DiscardUnknown() {
	xxx_messageInfo_SqlActivityFlushDetails.DiscardUnknown(m)
}

var xxx_messageInfo_SqlActivityFlushDetails proto.InternalMessageInfo

type SqlActivityFlushProgress struct {
}

func (m *SqlActivityFlushProgress) Reset()         { *m = SqlActivityFlushProgress{} }
func (m *SqlActivityFlushProgress) String() string { return proto.CompactTextString(m) }
func (*SqlActivityFlushProgress) ProtoMessage()    {}
func (*SqlActivityFlushProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{75}
}
func (m *SqlActivityFlushProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *SqlActivityFlushProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *SqlActivityFlushProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SqlActivityFlushProgress.Merge(m, src)
}
func (m *SqlActivityFlushProgress) XXX_Size() int {
	return m.Size()
}
func (m *SqlActivityFlushProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_SqlActivityFlushProgress.DiscardUnknown(m)
}

var xxx_messageInfo_SqlActivityFlushProgress proto.InternalMessageInfo

type HotRangesLoggerProgress struct {
}

func (m *HotRangesLoggerProgress) Reset()         { *m = HotRangesLoggerProgress{} }
func (m *HotRangesLoggerProgress) String() string { return proto.CompactTextString(m) }
func (*HotRangesLoggerProgress) ProtoMessage()    {}
func (*HotRangesLoggerProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{76}
}
func (m *HotRangesLoggerProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *HotRangesLoggerProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *HotRangesLoggerProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_HotRangesLoggerProgress.Merge(m, src)
}
func (m *HotRangesLoggerProgress) XXX_Size() int {
	return m.Size()
}
func (m *HotRangesLoggerProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_HotRangesLoggerProgress.DiscardUnknown(m)
}

var xxx_messageInfo_HotRangesLoggerProgress proto.InternalMessageInfo

type InspectProgress struct {
}

func (m *InspectProgress) Reset()         { *m = InspectProgress{} }
func (m *InspectProgress) String() string { return proto.CompactTextString(m) }
func (*InspectProgress) ProtoMessage()    {}
func (*InspectProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{77}
}
func (m *InspectProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *InspectProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *InspectProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_InspectProgress.Merge(m, src)
}
func (m *InspectProgress) XXX_Size() int {
	return m.Size()
}
func (m *InspectProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_InspectProgress.DiscardUnknown(m)
}

var xxx_messageInfo_InspectProgress proto.InternalMessageInfo

type ImportRollbackProgress struct {
}

func (m *ImportRollbackProgress) Reset()         { *m = ImportRollbackProgress{} }
func (m *ImportRollbackProgress) String() string { return proto.CompactTextString(m) }
func (*ImportRollbackProgress) ProtoMessage()    {}
func (*ImportRollbackProgress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{78}
}
func (m *ImportRollbackProgress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ImportRollbackProgress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *ImportRollbackProgress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ImportRollbackProgress.Merge(m, src)
}
func (m *ImportRollbackProgress) XXX_Size() int {
	return m.Size()
}
func (m *ImportRollbackProgress) XXX_DiscardUnknown() {
	xxx_messageInfo_ImportRollbackProgress.DiscardUnknown(m)
}

var xxx_messageInfo_ImportRollbackProgress proto.InternalMessageInfo

type Payload struct {
	Description string `protobuf:"bytes,1,opt,name=description,proto3" json:"description,omitempty"`
	// If empty, the description is assumed to be the statement.
	Statement     []string                                                                `protobuf:"bytes,16,rep,name=statement,proto3" json:"statement,omitempty"`
	UsernameProto github_com_cockroachdb_cockroach_pkg_security_username.SQLUsernameProto `protobuf:"bytes,2,opt,name=username_proto,json=usernameProto,proto3,casttype=github.com/cockroachdb/cockroach/pkg/security/username.SQLUsernameProto" json:"username_proto,omitempty"`
	// For consistency with the SQL timestamp type, which has microsecond
	// precision, we avoid the timestamp.Timestamp WKT, which has nanosecond
	// precision, and use microsecond integers directly.
	StartedMicros  int64                                                        `protobuf:"varint,3,opt,name=started_micros,json=startedMicros,proto3" json:"started_micros,omitempty"`
	FinishedMicros int64                                                        `protobuf:"varint,4,opt,name=finished_micros,json=finishedMicros,proto3" json:"finished_micros,omitempty"`
	DescriptorIDs  []github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID `protobuf:"varint,6,rep,packed,name=descriptor_ids,json=descriptorIds,proto3,casttype=github.com/cockroachdb/cockroach/pkg/sql/catalog/descpb.ID" json:"descriptor_ids,omitempty"`
	// TODO (lucy): Deprecate the string error field and move to using the encoded
	// errors everywhere.
	Error         string                   `protobuf:"bytes,8,opt,name=error,proto3" json:"error,omitempty"`
	ResumeErrors  []*errorspb.EncodedError `protobuf:"bytes,17,rep,name=resume_errors,json=resumeErrors,proto3" json:"resume_errors,omitempty"`
	CleanupErrors []*errorspb.EncodedError `protobuf:"bytes,18,rep,name=cleanup_errors,json=cleanupErrors,proto3" json:"cleanup_errors,omitempty"`
	// FinalResumeError is set when an error occurs that requires the job to be
	// reverted. The error is recorded so it can be handled while reverting, if
	// needed.
	FinalResumeError *errorspb.EncodedError `protobuf:"bytes,19,opt,name=final_resume_error,json=finalResumeError,proto3" json:"final_resume_error,omitempty"`
	// Noncancelable is used to denote when a job cannot be canceled. This field
	// will not be respected in mixed version clusters where some nodes have
	// a version < 20.1, so it can only be used in cases where all nodes having
	// versions >= 20.1 is guaranteed.
	Noncancelable bool `protobuf:"varint,20,opt,name=noncancelable,proto3" json:"noncancelable,omitempty"`
	// Types that are valid to be assigned to Details:
	//	*Payload_Backup
	//	*Payload_Restore
	//	*Payload_SchemaChange
	//	*Payload_Import
	//	*Payload_Changefeed
	//	*Payload_CreateStats
	//	*Payload_SchemaChangeGC
	//	*Payload_TypeSchemaChange
	//	*Payload_StreamIngestion
	//	*Payload_NewSchemaChange
	//	*Payload_Migration
	//	*Payload_AutoSpanConfigReconciliation
	//	*Payload_AutoSQLStatsCompaction
	//	*Payload_StreamReplication
	//	*Payload_RowLevelTTL
	//	*Payload_SchemaTelemetry
	//	*Payload_KeyVisualizerDetails
	//	*Payload_PollJobsStats
	//	*Payload_AutoConfigRunner
	//	*Payload_AutoConfigEnvRunner
	//	*Payload_AutoConfigTask
	//	*Payload_AutoUpdateSqlActivities
	//	*Payload_MvccStatisticsDetails
	//	*Payload_ImportRollbackDetails
	//	*Payload_HistoryRetentionDetails
	//	*Payload_LogicalReplicationDetails
	//	*Payload_UpdateTableMetadataCacheDetails
	//	*Payload_StandbyReadTsPollerDetails
	//	*Payload_SqlActivityFlushDetails
	//	*Payload_HotRangesLoggerDetails
	//	*Payload_InspectDetails
	Details isPayload_Details `protobuf_oneof:"details"`
	// PauseReason is used to describe the reason that the job is currently paused
	// or has been requested to be paused.
	PauseReason string `protobuf:"bytes,28,opt,name=pause_reason,json=pauseReason,proto3" json:"pause_reason,omitempty"`
	// CreationClusterID is populated at creation with the ClusterID, in case a
	// job resuming later, needs to use this information, e.g. to determine if it
	// has been restored into a different cluster, which might mean it should
	// terminate, pause or update some other state.
	CreationClusterID github_com_cockroachdb_cockroach_pkg_util_uuid.UUID `protobuf:"bytes,35,opt,name=creation_cluster_id,json=creationClusterId,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/uuid.UUID" json:"creation_cluster_id"`
	// CreationClusterVersion is populated at creation time with the then-active
	// cluster version, in case a job resuming later needs to use this information
	// to migrate or update the job.
	CreationClusterVersion roachpb.Version `protobuf:"bytes,36,opt,name=creation_cluster_version,json=creationClusterVersion,proto3" json:"creation_cluster_version"`
	// If a job lays protected timestamp records, this optional field
	// specifies how old such record could get before this job is canceled.
	MaximumPTSAge time.Duration `protobuf:"varint,40,opt,name=maximum_pts_age,json=maximumPtsAge,proto3,casttype=time.Duration" json:"maximum_pts_age,omitempty"`
}

func (m *Payload) Reset()         { *m = Payload{} }
func (m *Payload) String() string { return proto.CompactTextString(m) }
func (*Payload) ProtoMessage()    {}
func (*Payload) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{79}
}
func (m *Payload) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *Payload) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *Payload) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Payload.Merge(m, src)
}
func (m *Payload) XXX_Size() int {
	return m.Size()
}
func (m *Payload) XXX_DiscardUnknown() {
	xxx_messageInfo_Payload.DiscardUnknown(m)
}

var xxx_messageInfo_Payload proto.InternalMessageInfo

type isPayload_Details interface {
	isPayload_Details()
	MarshalTo([]byte) (int, error)
	Size() int
}

type Payload_Backup struct {
	Backup *BackupDetails `protobuf:"bytes,10,opt,name=backup,proto3,oneof" json:"backup,omitempty"`
}
type Payload_Restore struct {
	Restore *RestoreDetails `protobuf:"bytes,11,opt,name=restore,proto3,oneof" json:"restore,omitempty"`
}
type Payload_SchemaChange struct {
	SchemaChange *SchemaChangeDetails `protobuf:"bytes,12,opt,name=schemaChange,proto3,oneof" json:"schemaChange,omitempty"`
}
type Payload_Import struct {
	Import *ImportDetails `protobuf:"bytes,13,opt,name=import,proto3,oneof" json:"import,omitempty"`
}
type Payload_Changefeed struct {
	Changefeed *ChangefeedDetails `protobuf:"bytes,14,opt,name=changefeed,proto3,oneof" json:"changefeed,omitempty"`
}
type Payload_CreateStats struct {
	CreateStats *CreateStatsDetails `protobuf:"bytes,15,opt,name=createStats,proto3,oneof" json:"createStats,omitempty"`
}
type Payload_SchemaChangeGC struct {
	SchemaChangeGC *SchemaChangeGCDetails `protobuf:"bytes,21,opt,name=schemaChangeGC,proto3,oneof" json:"schemaChangeGC,omitempty"`
}
type Payload_TypeSchemaChange struct {
	TypeSchemaChange *TypeSchemaChangeDetails `protobuf:"bytes,22,opt,name=typeSchemaChange,proto3,oneof" json:"typeSchemaChange,omitempty"`
}
type Payload_StreamIngestion struct {
	StreamIngestion *StreamIngestionDetails `protobuf:"bytes,23,opt,name=streamIngestion,proto3,oneof" json:"streamIngestion,omitempty"`
}
type Payload_NewSchemaChange struct {
	NewSchemaChange *NewSchemaChangeDetails `protobuf:"bytes,24,opt,name=newSchemaChange,proto3,oneof" json:"newSchemaChange,omitempty"`
}
type Payload_Migration struct {
	Migration *MigrationDetails `protobuf:"bytes,25,opt,name=migration,proto3,oneof" json:"migration,omitempty"`
}
type Payload_AutoSpanConfigReconciliation struct {
	AutoSpanConfigReconciliation *AutoSpanConfigReconciliationDetails `protobuf:"bytes,27,opt,name=autoSpanConfigReconciliation,proto3,oneof" json:"autoSpanConfigReconciliation,omitempty"`
}
type Payload_AutoSQLStatsCompaction struct {
	AutoSQLStatsCompaction *AutoSQLStatsCompactionDetails `protobuf:"bytes,30,opt,name=autoSQLStatsCompaction,proto3,oneof" json:"autoSQLStatsCompaction,omitempty"`
}
type Payload_StreamReplication struct {
	StreamReplication *StreamReplicationDetails `protobuf:"bytes,33,opt,name=streamReplication,proto3,oneof" json:"streamReplication,omitempty"`
}
type Payload_RowLevelTTL struct {
	RowLevelTTL *RowLevelTTLDetails `protobuf:"bytes,34,opt,name=row_level_ttl,json=rowLevelTtl,proto3,oneof" json:"row_level_ttl,omitempty"`
}
type Payload_SchemaTelemetry struct {
	SchemaTelemetry *SchemaTelemetryDetails `protobuf:"bytes,37,opt,name=schema_telemetry,json=schemaTelemetry,proto3,oneof" json:"schema_telemetry,omitempty"`
}
type Payload_KeyVisualizerDetails struct {
	KeyVisualizerDetails *KeyVisualizerDetails `protobuf:"bytes,38,opt,name=keyVisualizerDetails,proto3,oneof" json:"keyVisualizerDetails,omitempty"`
}
type Payload_PollJobsStats struct {
	PollJobsStats *PollJobsStatsDetails `protobuf:"bytes,39,opt,name=poll_jobs_stats,json=pollJobsStats,proto3,oneof" json:"poll_jobs_stats,omitempty"`
}
type Payload_AutoConfigRunner struct {
	AutoConfigRunner *AutoConfigRunnerDetails `protobuf:"bytes,41,opt,name=auto_config_runner,json=autoConfigRunner,proto3,oneof" json:"auto_config_runner,omitempty"`
}
type Payload_AutoConfigEnvRunner struct {
	AutoConfigEnvRunner *AutoConfigEnvRunnerDetails `protobuf:"bytes,42,opt,name=auto_config_env_runner,json=autoConfigEnvRunner,proto3,oneof" json:"auto_config_env_runner,omitempty"`
}
type Payload_AutoConfigTask struct {
	AutoConfigTask *AutoConfigTaskDetails `protobuf:"bytes,43,opt,name=auto_config_task,json=autoConfigTask,proto3,oneof" json:"auto_config_task,omitempty"`
}
type Payload_AutoUpdateSqlActivities struct {
	AutoUpdateSqlActivities *AutoUpdateSQLActivityDetails `protobuf:"bytes,44,opt,name=auto_update_sql_activities,json=autoUpdateSqlActivities,proto3,oneof" json:"auto_update_sql_activities,omitempty"`
}
type Payload_MvccStatisticsDetails struct {
	MvccStatisticsDetails *MVCCStatisticsJobDetails `protobuf:"bytes,45,opt,name=mvcc_statistics_details,json=mvccStatisticsDetails,proto3,oneof" json:"mvcc_statistics_details,omitempty"`
}
type Payload_ImportRollbackDetails struct {
	ImportRollbackDetails *ImportRollbackDetails `protobuf:"bytes,46,opt,name=import_rollback_details,json=importRollbackDetails,proto3,oneof" json:"import_rollback_details,omitempty"`
}
type Payload_HistoryRetentionDetails struct {
	HistoryRetentionDetails *HistoryRetentionDetails `protobuf:"bytes,47,opt,name=history_retention_details,json=historyRetentionDetails,proto3,oneof" json:"history_retention_details,omitempty"`
}
type Payload_LogicalReplicationDetails struct {
	LogicalReplicationDetails *LogicalReplicationDetails `protobuf:"bytes,48,opt,name=logical_replication_details,json=logicalReplicationDetails,proto3,oneof" json:"logical_replication_details,omitempty"`
}
type Payload_UpdateTableMetadataCacheDetails struct {
	UpdateTableMetadataCacheDetails *UpdateTableMetadataCacheDetails `protobuf:"bytes,49,opt,name=update_table_metadata_cache_details,json=updateTableMetadataCacheDetails,proto3,oneof" json:"update_table_metadata_cache_details,omitempty"`
}
type Payload_StandbyReadTsPollerDetails struct {
	StandbyReadTsPollerDetails *StandbyReadTSPollerDetails `protobuf:"bytes,50,opt,name=standby_read_ts_poller_details,json=standbyReadTsPollerDetails,proto3,oneof" json:"standby_read_ts_poller_details,omitempty"`
}
type Payload_SqlActivityFlushDetails struct {
	SqlActivityFlushDetails *SqlActivityFlushDetails `protobuf:"bytes,51,opt,name=sql_activity_flush_details,json=sqlActivityFlushDetails,proto3,oneof" json:"sql_activity_flush_details,omitempty"`
}
type Payload_HotRangesLoggerDetails struct {
	HotRangesLoggerDetails *HotRangesLoggerDetails `protobuf:"bytes,52,opt,name=hot_ranges_logger_details,json=hotRangesLoggerDetails,proto3,oneof" json:"hot_ranges_logger_details,omitempty"`
}
type Payload_InspectDetails struct {
	InspectDetails *InspectDetails `protobuf:"bytes,53,opt,name=inspect_details,json=inspectDetails,proto3,oneof" json:"inspect_details,omitempty"`
}

func (*Payload_Backup) isPayload_Details()                          {}
func (*Payload_Restore) isPayload_Details()                         {}
func (*Payload_SchemaChange) isPayload_Details()                    {}
func (*Payload_Import) isPayload_Details()                          {}
func (*Payload_Changefeed) isPayload_Details()                      {}
func (*Payload_CreateStats) isPayload_Details()                     {}
func (*Payload_SchemaChangeGC) isPayload_Details()                  {}
func (*Payload_TypeSchemaChange) isPayload_Details()                {}
func (*Payload_StreamIngestion) isPayload_Details()                 {}
func (*Payload_NewSchemaChange) isPayload_Details()                 {}
func (*Payload_Migration) isPayload_Details()                       {}
func (*Payload_AutoSpanConfigReconciliation) isPayload_Details()    {}
func (*Payload_AutoSQLStatsCompaction) isPayload_Details()          {}
func (*Payload_StreamReplication) isPayload_Details()               {}
func (*Payload_RowLevelTTL) isPayload_Details()                     {}
func (*Payload_SchemaTelemetry) isPayload_Details()                 {}
func (*Payload_KeyVisualizerDetails) isPayload_Details()            {}
func (*Payload_PollJobsStats) isPayload_Details()                   {}
func (*Payload_AutoConfigRunner) isPayload_Details()                {}
func (*Payload_AutoConfigEnvRunner) isPayload_Details()             {}
func (*Payload_AutoConfigTask) isPayload_Details()                  {}
func (*Payload_AutoUpdateSqlActivities) isPayload_Details()         {}
func (*Payload_MvccStatisticsDetails) isPayload_Details()           {}
func (*Payload_ImportRollbackDetails) isPayload_Details()           {}
func (*Payload_HistoryRetentionDetails) isPayload_Details()         {}
func (*Payload_LogicalReplicationDetails) isPayload_Details()       {}
func (*Payload_UpdateTableMetadataCacheDetails) isPayload_Details() {}
func (*Payload_StandbyReadTsPollerDetails) isPayload_Details()      {}
func (*Payload_SqlActivityFlushDetails) isPayload_Details()         {}
func (*Payload_HotRangesLoggerDetails) isPayload_Details()          {}
func (*Payload_InspectDetails) isPayload_Details()                  {}

func (m *Payload) GetDetails() isPayload_Details {
	if m != nil {
		return m.Details
	}
	return nil
}

func (m *Payload) GetBackup() *BackupDetails {
	if x, ok := m.GetDetails().(*Payload_Backup); ok {
		return x.Backup
	}
	return nil
}

func (m *Payload) GetRestore() *RestoreDetails {
	if x, ok := m.GetDetails().(*Payload_Restore); ok {
		return x.Restore
	}
	return nil
}

func (m *Payload) GetSchemaChange() *SchemaChangeDetails {
	if x, ok := m.GetDetails().(*Payload_SchemaChange); ok {
		return x.SchemaChange
	}
	return nil
}

func (m *Payload) GetImport() *ImportDetails {
	if x, ok := m.GetDetails().(*Payload_Import); ok {
		return x.Import
	}
	return nil
}

func (m *Payload) GetChangefeed() *ChangefeedDetails {
	if x, ok := m.GetDetails().(*Payload_Changefeed); ok {
		return x.Changefeed
	}
	return nil
}

func (m *Payload) GetCreateStats() *CreateStatsDetails {
	if x, ok := m.GetDetails().(*Payload_CreateStats); ok {
		return x.CreateStats
	}
	return nil
}

func (m *Payload) GetSchemaChangeGC() *SchemaChangeGCDetails {
	if x, ok := m.GetDetails().(*Payload_SchemaChangeGC); ok {
		return x.SchemaChangeGC
	}
	return nil
}

func (m *Payload) GetTypeSchemaChange() *TypeSchemaChangeDetails {
	if x, ok := m.GetDetails().(*Payload_TypeSchemaChange); ok {
		return x.TypeSchemaChange
	}
	return nil
}

func (m *Payload) GetStreamIngestion() *StreamIngestionDetails {
	if x, ok := m.GetDetails().(*Payload_StreamIngestion); ok {
		return x.StreamIngestion
	}
	return nil
}

func (m *Payload) GetNewSchemaChange() *NewSchemaChangeDetails {
	if x, ok := m.GetDetails().(*Payload_NewSchemaChange); ok {
		return x.NewSchemaChange
	}
	return nil
}

func (m *Payload) GetMigration() *MigrationDetails {
	if x, ok := m.GetDetails().(*Payload_Migration); ok {
		return x.Migration
	}
	return nil
}

func (m *Payload) GetAutoSpanConfigReconciliation() *AutoSpanConfigReconciliationDetails {
	if x, ok := m.GetDetails().(*Payload_AutoSpanConfigReconciliation); ok {
		return x.AutoSpanConfigReconciliation
	}
	return nil
}

func (m *Payload) GetAutoSQLStatsCompaction() *AutoSQLStatsCompactionDetails {
	if x, ok := m.GetDetails().(*Payload_AutoSQLStatsCompaction); ok {
		return x.AutoSQLStatsCompaction
	}
	return nil
}

func (m *Payload) GetStreamReplication() *StreamReplicationDetails {
	if x, ok := m.GetDetails().(*Payload_StreamReplication); ok {
		return x.StreamReplication
	}
	return nil
}

func (m *Payload) GetRowLevelTTL() *RowLevelTTLDetails {
	if x, ok := m.GetDetails().(*Payload_RowLevelTTL); ok {
		return x.RowLevelTTL
	}
	return nil
}

func (m *Payload) GetSchemaTelemetry() *SchemaTelemetryDetails {
	if x, ok := m.GetDetails().(*Payload_SchemaTelemetry); ok {
		return x.SchemaTelemetry
	}
	return nil
}

func (m *Payload) GetKeyVisualizerDetails() *KeyVisualizerDetails {
	if x, ok := m.GetDetails().(*Payload_KeyVisualizerDetails); ok {
		return x.KeyVisualizerDetails
	}
	return nil
}

func (m *Payload) GetPollJobsStats() *PollJobsStatsDetails {
	if x, ok := m.GetDetails().(*Payload_PollJobsStats); ok {
		return x.PollJobsStats
	}
	return nil
}

func (m *Payload) GetAutoConfigRunner() *AutoConfigRunnerDetails {
	if x, ok := m.GetDetails().(*Payload_AutoConfigRunner); ok {
		return x.AutoConfigRunner
	}
	return nil
}

func (m *Payload) GetAutoConfigEnvRunner() *AutoConfigEnvRunnerDetails {
	if x, ok := m.GetDetails().(*Payload_AutoConfigEnvRunner); ok {
		return x.AutoConfigEnvRunner
	}
	return nil
}

func (m *Payload) GetAutoConfigTask() *AutoConfigTaskDetails {
	if x, ok := m.GetDetails().(*Payload_AutoConfigTask); ok {
		return x.AutoConfigTask
	}
	return nil
}

func (m *Payload) GetAutoUpdateSqlActivities() *AutoUpdateSQLActivityDetails {
	if x, ok := m.GetDetails().(*Payload_AutoUpdateSqlActivities); ok {
		return x.AutoUpdateSqlActivities
	}
	return nil
}

func (m *Payload) GetMvccStatisticsDetails() *MVCCStatisticsJobDetails {
	if x, ok := m.GetDetails().(*Payload_MvccStatisticsDetails); ok {
		return x.MvccStatisticsDetails
	}
	return nil
}

func (m *Payload) GetImportRollbackDetails() *ImportRollbackDetails {
	if x, ok := m.GetDetails().(*Payload_ImportRollbackDetails); ok {
		return x.ImportRollbackDetails
	}
	return nil
}

func (m *Payload) GetHistoryRetentionDetails() *HistoryRetentionDetails {
	if x, ok := m.GetDetails().(*Payload_HistoryRetentionDetails); ok {
		return x.HistoryRetentionDetails
	}
	return nil
}

func (m *Payload) GetLogicalReplicationDetails() *LogicalReplicationDetails {
	if x, ok := m.GetDetails().(*Payload_LogicalReplicationDetails); ok {
		return x.LogicalReplicationDetails
	}
	return nil
}

func (m *Payload) GetUpdateTableMetadataCacheDetails() *UpdateTableMetadataCacheDetails {
	if x, ok := m.GetDetails().(*Payload_UpdateTableMetadataCacheDetails); ok {
		return x.UpdateTableMetadataCacheDetails
	}
	return nil
}

func (m *Payload) GetStandbyReadTsPollerDetails() *StandbyReadTSPollerDetails {
	if x, ok := m.GetDetails().(*Payload_StandbyReadTsPollerDetails); ok {
		return x.StandbyReadTsPollerDetails
	}
	return nil
}

func (m *Payload) GetSqlActivityFlushDetails() *SqlActivityFlushDetails {
	if x, ok := m.GetDetails().(*Payload_SqlActivityFlushDetails); ok {
		return x.SqlActivityFlushDetails
	}
	return nil
}

func (m *Payload) GetHotRangesLoggerDetails() *HotRangesLoggerDetails {
	if x, ok := m.GetDetails().(*Payload_HotRangesLoggerDetails); ok {
		return x.HotRangesLoggerDetails
	}
	return nil
}

func (m *Payload) GetInspectDetails() *InspectDetails {
	if x, ok := m.GetDetails().(*Payload_InspectDetails); ok {
		return x.InspectDetails
	}
	return nil
}

// XXX_OneofWrappers is for the internal use of the proto package.
func (*Payload) XXX_OneofWrappers() []interface{} {
	return []interface{}{
		(*Payload_Backup)(nil),
		(*Payload_Restore)(nil),
		(*Payload_SchemaChange)(nil),
		(*Payload_Import)(nil),
		(*Payload_Changefeed)(nil),
		(*Payload_CreateStats)(nil),
		(*Payload_SchemaChangeGC)(nil),
		(*Payload_TypeSchemaChange)(nil),
		(*Payload_StreamIngestion)(nil),
		(*Payload_NewSchemaChange)(nil),
		(*Payload_Migration)(nil),
		(*Payload_AutoSpanConfigReconciliation)(nil),
		(*Payload_AutoSQLStatsCompaction)(nil),
		(*Payload_StreamReplication)(nil),
		(*Payload_RowLevelTTL)(nil),
		(*Payload_SchemaTelemetry)(nil),
		(*Payload_KeyVisualizerDetails)(nil),
		(*Payload_PollJobsStats)(nil),
		(*Payload_AutoConfigRunner)(nil),
		(*Payload_AutoConfigEnvRunner)(nil),
		(*Payload_AutoConfigTask)(nil),
		(*Payload_AutoUpdateSqlActivities)(nil),
		(*Payload_MvccStatisticsDetails)(nil),
		(*Payload_ImportRollbackDetails)(nil),
		(*Payload_HistoryRetentionDetails)(nil),
		(*Payload_LogicalReplicationDetails)(nil),
		(*Payload_UpdateTableMetadataCacheDetails)(nil),
		(*Payload_StandbyReadTsPollerDetails)(nil),
		(*Payload_SqlActivityFlushDetails)(nil),
		(*Payload_HotRangesLoggerDetails)(nil),
		(*Payload_InspectDetails)(nil),
	}
}

type Progress struct {
	// Types that are valid to be assigned to Progress:
	//	*Progress_FractionCompleted
	//	*Progress_HighWater
	Progress       isProgress_Progress `protobuf_oneof:"progress"`
	ModifiedMicros int64               `protobuf:"varint,2,opt,name=modified_micros,json=modifiedMicros,proto3" json:"modified_micros,omitempty"`
	// StatusMessage contains the human readible status of a job (e.g. "running
	// initial scan"), which is distinct from the state of a job (e.g. PAUSED).
	// The status of a job is also stored in the system.job_status table.
	// TODO(150233): Should use redactable type.
	StatusMessage string `protobuf:"bytes,4,opt,name=status_message,json=statusMessage,proto3" json:"status_message,omitempty"`
	//                ------ COMPLIANCE NOTE ------
	// If you're updating this `Progress` proto, consider its impact on compliance.
	// Currently, we include this data unredacted in debug zip bundles as part of the
	// dump of `system.jobs`. The current assumption is that none of these details
	// protos contain PII aside from Key spans.
	//
	// If you need to add a new details proto that will include PII beyond just key
	// spans, `system.jobs.progress` will need to be redacted or excluded from debug
	// zip to maintain compliance. Exclusion can be configured in
	// `zip_table_registry.go`.
	//
	// If you're unsure, reach out to the compliance team for help.
	//
	// Types that are valid to be assigned to Details:
	//	*Progress_Backup
	//	*Progress_Restore
	//	*Progress_SchemaChange
	//	*Progress_Import
	//	*Progress_Changefeed
	//	*Progress_CreateStats
	//	*Progress_SchemaChangeGC
	//	*Progress_TypeSchemaChange
	//	*Progress_StreamIngest
	//	*Progress_NewSchemaChange
	//	*Progress_Migration
	//	*Progress_AutoSpanConfigReconciliation
	//	*Progress_AutoSQLStatsCompaction
	//	*Progress_StreamReplication
	//	*Progress_RowLevelTTL
	//	*Progress_SchemaTelemetry
	//	*Progress_KeyVisualizerProgress
	//	*Progress_PollJobsStats
	//	*Progress_AutoConfigRunner
	//	*Progress_AutoConfigEnvRunner
	//	*Progress_AutoConfigTask
	//	*Progress_UpdateSqlActivity
	//	*Progress_MvccStatisticsProgress
	//	*Progress_ImportRollbackProgress
	//	*Progress_HistoryRetentionProgress
	//	*Progress_LogicalReplication
	//	*Progress_TableMetadataCache
	//	*Progress_StandbyReadTsPoller
	//	*Progress_SqlActivityFlush
	//	*Progress_HotRangesLogger
	//	*Progress_Inspect
	Details isProgress_Details                                                  `protobuf_oneof:"details"`
	TraceID github_com_cockroachdb_cockroach_pkg_util_tracing_tracingpb.TraceID `protobuf:"varint,21,opt,name=trace_id,json=traceId,proto3,customtype=github.com/cockroachdb/cockroach/pkg/util/tracing/tracingpb.TraceID" json:"trace_id"`
}

func (m *Progress) Reset()         { *m = Progress{} }
func (m *Progress) String() string { return proto.CompactTextString(m) }
func (*Progress) ProtoMessage()    {}
func (*Progress) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{80}
}
func (m *Progress) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *Progress) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *Progress) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Progress.Merge(m, src)
}
func (m *Progress) XXX_Size() int {
	return m.Size()
}
func (m *Progress) XXX_DiscardUnknown() {
	xxx_messageInfo_Progress.DiscardUnknown(m)
}

var xxx_messageInfo_Progress proto.InternalMessageInfo

type isProgress_Progress interface {
	isProgress_Progress()
	MarshalTo([]byte) (int, error)
	Size() int
}
type isProgress_Details interface {
	isProgress_Details()
	MarshalTo([]byte) (int, error)
	Size() int
}

type Progress_FractionCompleted struct {
	FractionCompleted float32 `protobuf:"fixed32,1,opt,name=fraction_completed,json=fractionCompleted,proto3,oneof" json:"fraction_completed,omitempty"`
}
type Progress_HighWater struct {
	HighWater *hlc.Timestamp `protobuf:"bytes,3,opt,name=high_water,json=highWater,proto3,oneof" json:"high_water,omitempty"`
}
type Progress_Backup struct {
	Backup *BackupProgress `protobuf:"bytes,10,opt,name=backup,proto3,oneof" json:"backup,omitempty"`
}
type Progress_Restore struct {
	Restore *RestoreProgress `protobuf:"bytes,11,opt,name=restore,proto3,oneof" json:"restore,omitempty"`
}
type Progress_SchemaChange struct {
	SchemaChange *SchemaChangeProgress `protobuf:"bytes,12,opt,name=schemaChange,proto3,oneof" json:"schemaChange,omitempty"`
}
type Progress_Import struct {
	Import *ImportProgress `protobuf:"bytes,13,opt,name=import,proto3,oneof" json:"import,omitempty"`
}
type Progress_Changefeed struct {
	Changefeed *ChangefeedProgress `protobuf:"bytes,14,opt,name=changefeed,proto3,oneof" json:"changefeed,omitempty"`
}
type Progress_CreateStats struct {
	CreateStats *CreateStatsProgress `protobuf:"bytes,15,opt,name=createStats,proto3,oneof" json:"createStats,omitempty"`
}
type Progress_SchemaChangeGC struct {
	SchemaChangeGC *SchemaChangeGCProgress `protobuf:"bytes,16,opt,name=schemaChangeGC,proto3,oneof" json:"schemaChangeGC,omitempty"`
}
type Progress_TypeSchemaChange struct {
	TypeSchemaChange *TypeSchemaChangeProgress `protobuf:"bytes,17,opt,name=typeSchemaChange,proto3,oneof" json:"typeSchemaChange,omitempty"`
}
type Progress_StreamIngest struct {
	StreamIngest *StreamIngestionProgress `protobuf:"bytes,18,opt,name=streamIngest,proto3,oneof" json:"streamIngest,omitempty"`
}
type Progress_NewSchemaChange struct {
	NewSchemaChange *NewSchemaChangeProgress `protobuf:"bytes,19,opt,name=newSchemaChange,proto3,oneof" json:"newSchemaChange,omitempty"`
}
type Progress_Migration struct {
	Migration *MigrationProgress `protobuf:"bytes,20,opt,name=migration,proto3,oneof" json:"migration,omitempty"`
}
type Progress_AutoSpanConfigReconciliation struct {
	AutoSpanConfigReconciliation *AutoSpanConfigReconciliationProgress `protobuf:"bytes,22,opt,name=AutoSpanConfigReconciliation,proto3,oneof" json:"AutoSpanConfigReconciliation,omitempty"`
}
type Progress_AutoSQLStatsCompaction struct {
	AutoSQLStatsCompaction *AutoSQLStatsCompactionProgress `protobuf:"bytes,23,opt,name=autoSQLStatsCompaction,proto3,oneof" json:"autoSQLStatsCompaction,omitempty"`
}
type Progress_StreamReplication struct {
	StreamReplication *StreamReplicationProgress `protobuf:"bytes,24,opt,name=streamReplication,proto3,oneof" json:"streamReplication,omitempty"`
}
type Progress_RowLevelTTL struct {
	RowLevelTTL *RowLevelTTLProgress `protobuf:"bytes,25,opt,name=row_level_ttl,json=rowLevelTtl,proto3,oneof" json:"row_level_ttl,omitempty"`
}
type Progress_SchemaTelemetry struct {
	SchemaTelemetry *SchemaTelemetryProgress `protobuf:"bytes,26,opt,name=schema_telemetry,json=schemaTelemetry,proto3,oneof" json:"schema_telemetry,omitempty"`
}
type Progress_KeyVisualizerProgress struct {
	KeyVisualizerProgress *KeyVisualizerProgress `protobuf:"bytes,27,opt,name=keyVisualizerProgress,proto3,oneof" json:"keyVisualizerProgress,omitempty"`
}
type Progress_PollJobsStats struct {
	PollJobsStats *PollJobsStatsProgress `protobuf:"bytes,28,opt,name=pollJobsStats,proto3,oneof" json:"pollJobsStats,omitempty"`
}
type Progress_AutoConfigRunner struct {
	AutoConfigRunner *AutoConfigRunnerProgress `protobuf:"bytes,29,opt,name=auto_config_runner,json=autoConfigRunner,proto3,oneof" json:"auto_config_runner,omitempty"`
}
type Progress_AutoConfigEnvRunner struct {
	AutoConfigEnvRunner *AutoConfigEnvRunnerProgress `protobuf:"bytes,30,opt,name=auto_config_env_runner,json=autoConfigEnvRunner,proto3,oneof" json:"auto_config_env_runner,omitempty"`
}
type Progress_AutoConfigTask struct {
	AutoConfigTask *AutoConfigTaskProgress `protobuf:"bytes,31,opt,name=auto_config_task,json=autoConfigTask,proto3,oneof" json:"auto_config_task,omitempty"`
}
type Progress_UpdateSqlActivity struct {
	UpdateSqlActivity *AutoUpdateSQLActivityProgress `protobuf:"bytes,32,opt,name=update_sql_activity,json=updateSqlActivity,proto3,oneof" json:"update_sql_activity,omitempty"`
}
type Progress_MvccStatisticsProgress struct {
	MvccStatisticsProgress *MVCCStatisticsJobProgress `protobuf:"bytes,33,opt,name=mvcc_statistics_progress,json=mvccStatisticsProgress,proto3,oneof" json:"mvcc_statistics_progress,omitempty"`
}
type Progress_ImportRollbackProgress struct {
	ImportRollbackProgress *ImportRollbackProgress `protobuf:"bytes,34,opt,name=import_rollback_progress,json=importRollbackProgress,proto3,oneof" json:"import_rollback_progress,omitempty"`
}
type Progress_HistoryRetentionProgress struct {
	HistoryRetentionProgress *HistoryRetentionProgress `protobuf:"bytes,35,opt,name=HistoryRetentionProgress,proto3,oneof" json:"HistoryRetentionProgress,omitempty"`
}
type Progress_LogicalReplication struct {
	LogicalReplication *LogicalReplicationProgress `protobuf:"bytes,36,opt,name=LogicalReplication,proto3,oneof" json:"LogicalReplication,omitempty"`
}
type Progress_TableMetadataCache struct {
	TableMetadataCache *UpdateTableMetadataCacheProgress `protobuf:"bytes,37,opt,name=table_metadata_cache,json=tableMetadataCache,proto3,oneof" json:"table_metadata_cache,omitempty"`
}
type Progress_StandbyReadTsPoller struct {
	StandbyReadTsPoller *StandbyReadTSPollerProgress `protobuf:"bytes,38,opt,name=standby_read_ts_poller,json=standbyReadTsPoller,proto3,oneof" json:"standby_read_ts_poller,omitempty"`
}
type Progress_SqlActivityFlush struct {
	SqlActivityFlush *SqlActivityFlushProgress `protobuf:"bytes,39,opt,name=sql_activity_flush,json=sqlActivityFlush,proto3,oneof" json:"sql_activity_flush,omitempty"`
}
type Progress_HotRangesLogger struct {
	HotRangesLogger *HotRangesLoggerProgress `protobuf:"bytes,40,opt,name=hot_ranges_logger,json=hotRangesLogger,proto3,oneof" json:"hot_ranges_logger,omitempty"`
}
type Progress_Inspect struct {
	Inspect *InspectProgress `protobuf:"bytes,41,opt,name=inspect,proto3,oneof" json:"inspect,omitempty"`
}

func (*Progress_FractionCompleted) isProgress_Progress()           {}
func (*Progress_HighWater) isProgress_Progress()                   {}
func (*Progress_Backup) isProgress_Details()                       {}
func (*Progress_Restore) isProgress_Details()                      {}
func (*Progress_SchemaChange) isProgress_Details()                 {}
func (*Progress_Import) isProgress_Details()                       {}
func (*Progress_Changefeed) isProgress_Details()                   {}
func (*Progress_CreateStats) isProgress_Details()                  {}
func (*Progress_SchemaChangeGC) isProgress_Details()               {}
func (*Progress_TypeSchemaChange) isProgress_Details()             {}
func (*Progress_StreamIngest) isProgress_Details()                 {}
func (*Progress_NewSchemaChange) isProgress_Details()              {}
func (*Progress_Migration) isProgress_Details()                    {}
func (*Progress_AutoSpanConfigReconciliation) isProgress_Details() {}
func (*Progress_AutoSQLStatsCompaction) isProgress_Details()       {}
func (*Progress_StreamReplication) isProgress_Details()            {}
func (*Progress_RowLevelTTL) isProgress_Details()                  {}
func (*Progress_SchemaTelemetry) isProgress_Details()              {}
func (*Progress_KeyVisualizerProgress) isProgress_Details()        {}
func (*Progress_PollJobsStats) isProgress_Details()                {}
func (*Progress_AutoConfigRunner) isProgress_Details()             {}
func (*Progress_AutoConfigEnvRunner) isProgress_Details()          {}
func (*Progress_AutoConfigTask) isProgress_Details()               {}
func (*Progress_UpdateSqlActivity) isProgress_Details()            {}
func (*Progress_MvccStatisticsProgress) isProgress_Details()       {}
func (*Progress_ImportRollbackProgress) isProgress_Details()       {}
func (*Progress_HistoryRetentionProgress) isProgress_Details()     {}
func (*Progress_LogicalReplication) isProgress_Details()           {}
func (*Progress_TableMetadataCache) isProgress_Details()           {}
func (*Progress_StandbyReadTsPoller) isProgress_Details()          {}
func (*Progress_SqlActivityFlush) isProgress_Details()             {}
func (*Progress_HotRangesLogger) isProgress_Details()              {}
func (*Progress_Inspect) isProgress_Details()                      {}

func (m *Progress) GetProgress() isProgress_Progress {
	if m != nil {
		return m.Progress
	}
	return nil
}
func (m *Progress) GetDetails() isProgress_Details {
	if m != nil {
		return m.Details
	}
	return nil
}

func (m *Progress) GetFractionCompleted() float32 {
	if x, ok := m.GetProgress().(*Progress_FractionCompleted); ok {
		return x.FractionCompleted
	}
	return 0
}

func (m *Progress) GetHighWater() *hlc.Timestamp {
	if x, ok := m.GetProgress().(*Progress_HighWater); ok {
		return x.HighWater
	}
	return nil
}

func (m *Progress) GetBackup() *BackupProgress {
	if x, ok := m.GetDetails().(*Progress_Backup); ok {
		return x.Backup
	}
	return nil
}

func (m *Progress) GetRestore() *RestoreProgress {
	if x, ok := m.GetDetails().(*Progress_Restore); ok {
		return x.Restore
	}
	return nil
}

func (m *Progress) GetSchemaChange() *SchemaChangeProgress {
	if x, ok := m.GetDetails().(*Progress_SchemaChange); ok {
		return x.SchemaChange
	}
	return nil
}

func (m *Progress) GetImport() *ImportProgress {
	if x, ok := m.GetDetails().(*Progress_Import); ok {
		return x.Import
	}
	return nil
}

func (m *Progress) GetChangefeed() *ChangefeedProgress {
	if x, ok := m.GetDetails().(*Progress_Changefeed); ok {
		return x.Changefeed
	}
	return nil
}

func (m *Progress) GetCreateStats() *CreateStatsProgress {
	if x, ok := m.GetDetails().(*Progress_CreateStats); ok {
		return x.CreateStats
	}
	return nil
}

func (m *Progress) GetSchemaChangeGC() *SchemaChangeGCProgress {
	if x, ok := m.GetDetails().(*Progress_SchemaChangeGC); ok {
		return x.SchemaChangeGC
	}
	return nil
}

func (m *Progress) GetTypeSchemaChange() *TypeSchemaChangeProgress {
	if x, ok := m.GetDetails().(*Progress_TypeSchemaChange); ok {
		return x.TypeSchemaChange
	}
	return nil
}

func (m *Progress) GetStreamIngest() *StreamIngestionProgress {
	if x, ok := m.GetDetails().(*Progress_StreamIngest); ok {
		return x.StreamIngest
	}
	return nil
}

func (m *Progress) GetNewSchemaChange() *NewSchemaChangeProgress {
	if x, ok := m.GetDetails().(*Progress_NewSchemaChange); ok {
		return x.NewSchemaChange
	}
	return nil
}

func (m *Progress) GetMigration() *MigrationProgress {
	if x, ok := m.GetDetails().(*Progress_Migration); ok {
		return x.Migration
	}
	return nil
}

func (m *Progress) GetAutoSpanConfigReconciliation() *AutoSpanConfigReconciliationProgress {
	if x, ok := m.GetDetails().(*Progress_AutoSpanConfigReconciliation); ok {
		return x.AutoSpanConfigReconciliation
	}
	return nil
}

func (m *Progress) GetAutoSQLStatsCompaction() *AutoSQLStatsCompactionProgress {
	if x, ok := m.GetDetails().(*Progress_AutoSQLStatsCompaction); ok {
		return x.AutoSQLStatsCompaction
	}
	return nil
}

func (m *Progress) GetStreamReplication() *StreamReplicationProgress {
	if x, ok := m.GetDetails().(*Progress_StreamReplication); ok {
		return x.StreamReplication
	}
	return nil
}

func (m *Progress) GetRowLevelTTL() *RowLevelTTLProgress {
	if x, ok := m.GetDetails().(*Progress_RowLevelTTL); ok {
		return x.RowLevelTTL
	}
	return nil
}

func (m *Progress) GetSchemaTelemetry() *SchemaTelemetryProgress {
	if x, ok := m.GetDetails().(*Progress_SchemaTelemetry); ok {
		return x.SchemaTelemetry
	}
	return nil
}

func (m *Progress) GetKeyVisualizerProgress() *KeyVisualizerProgress {
	if x, ok := m.GetDetails().(*Progress_KeyVisualizerProgress); ok {
		return x.KeyVisualizerProgress
	}
	return nil
}

func (m *Progress) GetPollJobsStats() *PollJobsStatsProgress {
	if x, ok := m.GetDetails().(*Progress_PollJobsStats); ok {
		return x.PollJobsStats
	}
	return nil
}

func (m *Progress) GetAutoConfigRunner() *AutoConfigRunnerProgress {
	if x, ok := m.GetDetails().(*Progress_AutoConfigRunner); ok {
		return x.AutoConfigRunner
	}
	return nil
}

func (m *Progress) GetAutoConfigEnvRunner() *AutoConfigEnvRunnerProgress {
	if x, ok := m.GetDetails().(*Progress_AutoConfigEnvRunner); ok {
		return x.AutoConfigEnvRunner
	}
	return nil
}

func (m *Progress) GetAutoConfigTask() *AutoConfigTaskProgress {
	if x, ok := m.GetDetails().(*Progress_AutoConfigTask); ok {
		return x.AutoConfigTask
	}
	return nil
}

func (m *Progress) GetUpdateSqlActivity() *AutoUpdateSQLActivityProgress {
	if x, ok := m.GetDetails().(*Progress_UpdateSqlActivity); ok {
		return x.UpdateSqlActivity
	}
	return nil
}

func (m *Progress) GetMvccStatisticsProgress() *MVCCStatisticsJobProgress {
	if x, ok := m.GetDetails().(*Progress_MvccStatisticsProgress); ok {
		return x.MvccStatisticsProgress
	}
	return nil
}

func (m *Progress) GetImportRollbackProgress() *ImportRollbackProgress {
	if x, ok := m.GetDetails().(*Progress_ImportRollbackProgress); ok {
		return x.ImportRollbackProgress
	}
	return nil
}

func (m *Progress) GetHistoryRetentionProgress() *HistoryRetentionProgress {
	if x, ok := m.GetDetails().(*Progress_HistoryRetentionProgress); ok {
		return x.HistoryRetentionProgress
	}
	return nil
}

func (m *Progress) GetLogicalReplication() *LogicalReplicationProgress {
	if x, ok := m.GetDetails().(*Progress_LogicalReplication); ok {
		return x.LogicalReplication
	}
	return nil
}

func (m *Progress) GetTableMetadataCache() *UpdateTableMetadataCacheProgress {
	if x, ok := m.GetDetails().(*Progress_TableMetadataCache); ok {
		return x.TableMetadataCache
	}
	return nil
}

func (m *Progress) GetStandbyReadTsPoller() *StandbyReadTSPollerProgress {
	if x, ok := m.GetDetails().(*Progress_StandbyReadTsPoller); ok {
		return x.StandbyReadTsPoller
	}
	return nil
}

func (m *Progress) GetSqlActivityFlush() *SqlActivityFlushProgress {
	if x, ok := m.GetDetails().(*Progress_SqlActivityFlush); ok {
		return x.SqlActivityFlush
	}
	return nil
}

func (m *Progress) GetHotRangesLogger() *HotRangesLoggerProgress {
	if x, ok := m.GetDetails().(*Progress_HotRangesLogger); ok {
		return x.HotRangesLogger
	}
	return nil
}

func (m *Progress) GetInspect() *InspectProgress {
	if x, ok := m.GetDetails().(*Progress_Inspect); ok {
		return x.Inspect
	}
	return nil
}

// XXX_OneofWrappers is for the internal use of the proto package.
func (*Progress) XXX_OneofWrappers() []interface{} {
	return []interface{}{
		(*Progress_FractionCompleted)(nil),
		(*Progress_HighWater)(nil),
		(*Progress_Backup)(nil),
		(*Progress_Restore)(nil),
		(*Progress_SchemaChange)(nil),
		(*Progress_Import)(nil),
		(*Progress_Changefeed)(nil),
		(*Progress_CreateStats)(nil),
		(*Progress_SchemaChangeGC)(nil),
		(*Progress_TypeSchemaChange)(nil),
		(*Progress_StreamIngest)(nil),
		(*Progress_NewSchemaChange)(nil),
		(*Progress_Migration)(nil),
		(*Progress_AutoSpanConfigReconciliation)(nil),
		(*Progress_AutoSQLStatsCompaction)(nil),
		(*Progress_StreamReplication)(nil),
		(*Progress_RowLevelTTL)(nil),
		(*Progress_SchemaTelemetry)(nil),
		(*Progress_KeyVisualizerProgress)(nil),
		(*Progress_PollJobsStats)(nil),
		(*Progress_AutoConfigRunner)(nil),
		(*Progress_AutoConfigEnvRunner)(nil),
		(*Progress_AutoConfigTask)(nil),
		(*Progress_UpdateSqlActivity)(nil),
		(*Progress_MvccStatisticsProgress)(nil),
		(*Progress_ImportRollbackProgress)(nil),
		(*Progress_HistoryRetentionProgress)(nil),
		(*Progress_LogicalReplication)(nil),
		(*Progress_TableMetadataCache)(nil),
		(*Progress_StandbyReadTsPoller)(nil),
		(*Progress_SqlActivityFlush)(nil),
		(*Progress_HotRangesLogger)(nil),
		(*Progress_Inspect)(nil),
	}
}

type Job struct {
	Id JobID `protobuf:"varint,1,opt,name=id,proto3,customtype=JobID" json:"id"`
	// Keep progress first as it may be more relevant to see when looking at a
	// running job.
	Progress *Progress `protobuf:"bytes,2,opt,name=progress,proto3" json:"progress,omitempty"`
	Payload  *Payload  `protobuf:"bytes,3,opt,name=payload,proto3" json:"payload,omitempty"`
}

func (m *Job) Reset()         { *m = Job{} }
func (m *Job) String() string { return proto.CompactTextString(m) }
func (*Job) ProtoMessage()    {}
func (*Job) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{81}
}
func (m *Job) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *Job) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *Job) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Job.Merge(m, src)
}
func (m *Job) XXX_Size() int {
	return m.Size()
}
func (m *Job) XXX_DiscardUnknown() {
	xxx_messageInfo_Job.DiscardUnknown(m)
}

var xxx_messageInfo_Job proto.InternalMessageInfo

// RetriableExecutionFailure is used in Payload.RetriableExecutionFailureLog
// to store a history of executions which failed.
type RetriableExecutionFailure struct {
	// Status is the status of the job when this failure occurred.
	Status string `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
	// ExecutionStartMicros is the timestamp at which this execution occurred.
	ExecutionStartMicros int64 `protobuf:"varint,2,opt,name=execution_start_micros,json=executionStartMicros,proto3" json:"execution_start_micros,omitempty"`
	// ExecutionEndMicros is the timestamp at which this execution concluded.
	ExecutionEndMicros int64 `protobuf:"varint,3,opt,name=execution_end_micros,json=executionEndMicros,proto3" json:"execution_end_micros,omitempty"`
	// InstanceID is the instance which coordinated the execution.
	InstanceID github_com_cockroachdb_cockroach_pkg_base.SQLInstanceID `protobuf:"varint,4,opt,name=instance_id,json=instanceId,proto3,customtype=github.com/cockroachdb/cockroach/pkg/base.SQLInstanceID" json:"instance_id"`
	// Error stores the structured error which occurred. It might be nil if it
	// was too large. In that case, the TruncatedError will be populated.
	Error *errorspb.EncodedError `protobuf:"bytes,5,opt,name=error,proto3" json:"error,omitempty"`
	// TruncatedError is a fragment of a error message populated in the case
	// that the error was too large. While the structure may be lost, at least
	// some information will be preserved.
	TruncatedError string `protobuf:"bytes,6,opt,name=truncated_error,json=truncatedError,proto3" json:"truncated_error,omitempty"`
}

func (m *RetriableExecutionFailure) Reset()         { *m = RetriableExecutionFailure{} }
func (m *RetriableExecutionFailure) String() string { return proto.CompactTextString(m) }
func (*RetriableExecutionFailure) ProtoMessage()    {}
func (*RetriableExecutionFailure) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{82}
}
func (m *RetriableExecutionFailure) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *RetriableExecutionFailure) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *RetriableExecutionFailure) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RetriableExecutionFailure.Merge(m, src)
}
func (m *RetriableExecutionFailure) XXX_Size() int {
	return m.Size()
}
func (m *RetriableExecutionFailure) XXX_DiscardUnknown() {
	xxx_messageInfo_RetriableExecutionFailure.DiscardUnknown(m)
}

var xxx_messageInfo_RetriableExecutionFailure proto.InternalMessageInfo

// TraceData is used to capture the traces of a job when the resumer completes
// its execution.
type TraceData struct {
	CollectedSpans []tracingpb.RecordedSpan `protobuf:"bytes,1,rep,name=collected_spans,json=collectedSpans,proto3" json:"collected_spans"`
}

func (m *TraceData) Reset()         { *m = TraceData{} }
func (m *TraceData) String() string { return proto.CompactTextString(m) }
func (*TraceData) ProtoMessage()    {}
func (*TraceData) Descriptor() ([]byte, []int) {
	return fileDescriptor_6c315f3a2536c4ef, []int{83}
}
func (m *TraceData) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *TraceData) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	b = b[:cap(b)]
	n, err := m.MarshalToSizedBuffer(b)
	if err != nil {
		return nil, err
	}
	return b[:n], nil
}
func (m *TraceData) XXX_Merge(src proto.Message) {
	xxx_messageInfo_TraceData.Merge(m, src)
}
func (m *TraceData) XXX_Size() int {
	return m.Size()
}
func (m *TraceData) XXX_DiscardUnknown() {
	xxx_messageInfo_TraceData.DiscardUnknown(m)
}

var xxx_messageInfo_TraceData proto.InternalMessageInfo

func init() {
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.EncryptionMode", EncryptionMode_name, EncryptionMode_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.Status", Status_name, Status_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.Type", Type_name, Type_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.EncryptionInfo_Scheme", EncryptionInfo_Scheme_name, EncryptionInfo_Scheme_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.LogicalReplicationDetails_ApplyMode", LogicalReplicationDetails_ApplyMode_name, LogicalReplicationDetails_ApplyMode_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.LogicalReplicationDetails_Discard", LogicalReplicationDetails_Discard_name, LogicalReplicationDetails_Discard_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution", LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution_name, LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.StreamReplicationProgress_StreamIngestionStatus", StreamReplicationProgress_StreamIngestionStatus_name, StreamReplicationProgress_StreamIngestionStatus_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.SchedulePTSChainingRecord_PTSAction", SchedulePTSChainingRecord_PTSAction_name, SchedulePTSChainingRecord_PTSAction_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.SchemaChangeGCProgress_Status", SchemaChangeGCProgress_Status_name, SchemaChangeGCProgress_Status_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.ChangefeedTargetSpecification_TargetType", ChangefeedTargetSpecification_TargetType_name, ChangefeedTargetSpecification_TargetType_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.ResolvedSpan_BoundaryType", ResolvedSpan_BoundaryType_name, ResolvedSpan_BoundaryType_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.InspectDetails_Check_InspectCheckType", InspectDetails_Check_InspectCheckType_name, InspectDetails_Check_InspectCheckType_value)
	proto.RegisterEnum("cockroach.sql.jobs.jobspb.UpdateTableMetadataCacheProgress_Status", UpdateTableMetadataCacheProgress_Status_name, UpdateTableMetadataCacheProgress_Status_value)
	proto.RegisterType((*BackupEncryptionOptions)(nil), "cockroach.sql.jobs.jobspb.BackupEncryptionOptions")
	proto.RegisterType((*BackupEncryptionOptions_KMSInfo)(nil), "cockroach.sql.jobs.jobspb.BackupEncryptionOptions.KMSInfo")
	proto.RegisterType((*EncryptionInfo)(nil), "cockroach.sql.jobs.jobspb.EncryptionInfo")
	proto.RegisterMapType((map[string][]byte)(nil), "cockroach.sql.jobs.jobspb.EncryptionInfo.EncryptedDataKeyByKMSMasterKeyIDEntry")
	proto.RegisterType((*StreamIngestionDetails)(nil), "cockroach.sql.jobs.jobspb.StreamIngestionDetails")
	proto.RegisterType((*StreamIngestionCheckpoint)(nil), "cockroach.sql.jobs.jobspb.StreamIngestionCheckpoint")
	proto.RegisterType((*StreamIngestionProgress)(nil), "cockroach.sql.jobs.jobspb.StreamIngestionProgress")
	proto.RegisterType((*HistoryRetentionDetails)(nil), "cockroach.sql.jobs.jobspb.HistoryRetentionDetails")
	proto.RegisterType((*HistoryRetentionProgress)(nil), "cockroach.sql.jobs.jobspb.HistoryRetentionProgress")
	proto.RegisterType((*LogicalReplicationDetails)(nil), "cockroach.sql.jobs.jobspb.LogicalReplicationDetails")
	proto.RegisterType((*LogicalReplicationDetails_ReplicationPair)(nil), "cockroach.sql.jobs.jobspb.LogicalReplicationDetails.ReplicationPair")
	proto.RegisterType((*LogicalReplicationDetails_DefaultConflictResolution)(nil), "cockroach.sql.jobs.jobspb.LogicalReplicationDetails.DefaultConflictResolution")
	proto.RegisterType((*LogicalReplicationProgress)(nil), "cockroach.sql.jobs.jobspb.LogicalReplicationProgress")
	proto.RegisterType((*StreamReplicationDetails)(nil), "cockroach.sql.jobs.jobspb.StreamReplicationDetails")
	proto.RegisterType((*StreamReplicationProgress)(nil), "cockroach.sql.jobs.jobspb.StreamReplicationProgress")
	proto.RegisterType((*SchedulePTSChainingRecord)(nil), "cockroach.sql.jobs.jobspb.SchedulePTSChainingRecord")
	proto.RegisterType((*BackupDetails)(nil), "cockroach.sql.jobs.jobspb.BackupDetails")
	proto.RegisterMapType((map[string]string)(nil), "cockroach.sql.jobs.jobspb.BackupDetails.UrisByLocalityKvEntry")
	proto.RegisterType((*BackupDetails_Destination)(nil), "cockroach.sql.jobs.jobspb.BackupDetails.Destination")
	proto.RegisterType((*BackupProgress)(nil), "cockroach.sql.jobs.jobspb.BackupProgress")
	proto.RegisterType((*DescriptorRewrite)(nil), "cockroach.sql.jobs.jobspb.DescriptorRewrite")
	proto.RegisterType((*RestoreDetails)(nil), "cockroach.sql.jobs.jobspb.RestoreDetails")
	proto.RegisterMapType((map[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID]*RestoreDetails_DatabaseModifier)(nil), "cockroach.sql.jobs.jobspb.RestoreDetails.DatabaseModifiersEntry")
	proto.RegisterMapType((map[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID]*DescriptorRewrite)(nil), "cockroach.sql.jobs.jobspb.RestoreDetails.DescriptorRewritesEntry")
	proto.RegisterMapType((map[uint32]*catpb.AutoStatsSettings)(nil), "cockroach.sql.jobs.jobspb.RestoreDetails.PostDownloadTableAutoStatsSettingsEntry")
	proto.RegisterMapType((map[string]bool)(nil), "cockroach.sql.jobs.jobspb.RestoreDetails.SystemTablesMigratedEntry")
	proto.RegisterType((*RestoreDetails_BackupLocalityInfo)(nil), "cockroach.sql.jobs.jobspb.RestoreDetails.BackupLocalityInfo")
	proto.RegisterMapType((map[string]string)(nil), "cockroach.sql.jobs.jobspb.RestoreDetails.BackupLocalityInfo.UrisByOriginalLocalityKvEntry")
	proto.RegisterType((*RestoreDetails_DatabaseModifier)(nil), "cockroach.sql.jobs.jobspb.RestoreDetails.DatabaseModifier")
	proto.RegisterType((*RestoreProgress)(nil), "cockroach.sql.jobs.jobspb.RestoreProgress")
	proto.RegisterType((*RestoreProgress_FrontierEntry)(nil), "cockroach.sql.jobs.jobspb.RestoreProgress.FrontierEntry")
	proto.RegisterType((*ImportDetails)(nil), "cockroach.sql.jobs.jobspb.ImportDetails")
	proto.RegisterType((*ImportDetails_Table)(nil), "cockroach.sql.jobs.jobspb.ImportDetails.Table")
	proto.RegisterType((*ImportDetails_Type)(nil), "cockroach.sql.jobs.jobspb.ImportDetails.Type")
	proto.RegisterType((*SequenceValChunk)(nil), "cockroach.sql.jobs.jobspb.SequenceValChunk")
	proto.RegisterType((*SequenceDetails)(nil), "cockroach.sql.jobs.jobspb.SequenceDetails")
	proto.RegisterMapType((map[int32]*SequenceDetails_SequenceChunks)(nil), "cockroach.sql.jobs.jobspb.SequenceDetails.SeqIdToChunksEntry")
	proto.RegisterType((*SequenceDetails_SequenceChunks)(nil), "cockroach.sql.jobs.jobspb.SequenceDetails.SequenceChunks")
	proto.RegisterType((*ImportProgress)(nil), "cockroach.sql.jobs.jobspb.ImportProgress")
	proto.RegisterType((*TypeSchemaChangeDetails)(nil), "cockroach.sql.jobs.jobspb.TypeSchemaChangeDetails")
	proto.RegisterType((*TypeSchemaChangeProgress)(nil), "cockroach.sql.jobs.jobspb.TypeSchemaChangeProgress")
	proto.RegisterType((*NewSchemaChangeDetails)(nil), "cockroach.sql.jobs.jobspb.NewSchemaChangeDetails")
	proto.RegisterType((*BackfillProgress)(nil), "cockroach.sql.jobs.jobspb.BackfillProgress")
	proto.RegisterType((*MergeProgress)(nil), "cockroach.sql.jobs.jobspb.MergeProgress")
	proto.RegisterType((*MergeProgress_MergePair)(nil), "cockroach.sql.jobs.jobspb.MergeProgress.MergePair")
	proto.RegisterType((*NewSchemaChangeProgress)(nil), "cockroach.sql.jobs.jobspb.NewSchemaChangeProgress")
	proto.RegisterType((*AutoSpanConfigReconciliationDetails)(nil), "cockroach.sql.jobs.jobspb.AutoSpanConfigReconciliationDetails")
	proto.RegisterType((*AutoSpanConfigReconciliationProgress)(nil), "cockroach.sql.jobs.jobspb.AutoSpanConfigReconciliationProgress")
	proto.RegisterType((*KeyVisualizerDetails)(nil), "cockroach.sql.jobs.jobspb.KeyVisualizerDetails")
	proto.RegisterType((*KeyVisualizerProgress)(nil), "cockroach.sql.jobs.jobspb.KeyVisualizerProgress")
	proto.RegisterType((*ResumeSpanList)(nil), "cockroach.sql.jobs.jobspb.ResumeSpanList")
	proto.RegisterType((*DroppedTableDetails)(nil), "cockroach.sql.jobs.jobspb.DroppedTableDetails")
	proto.RegisterType((*SchemaChangeGCDetails)(nil), "cockroach.sql.jobs.jobspb.SchemaChangeGCDetails")
	proto.RegisterType((*SchemaChangeGCDetails_DroppedIndex)(nil), "cockroach.sql.jobs.jobspb.SchemaChangeGCDetails.DroppedIndex")
	proto.RegisterType((*SchemaChangeGCDetails_DroppedID)(nil), "cockroach.sql.jobs.jobspb.SchemaChangeGCDetails.DroppedID")
	proto.RegisterType((*SchemaChangeGCDetails_DroppedTenant)(nil), "cockroach.sql.jobs.jobspb.SchemaChangeGCDetails.DroppedTenant")
	proto.RegisterType((*SchemaChangeDetails)(nil), "cockroach.sql.jobs.jobspb.SchemaChangeDetails")
	proto.RegisterType((*SchemaChangeProgress)(nil), "cockroach.sql.jobs.jobspb.SchemaChangeProgress")
	proto.RegisterType((*SchemaChangeGCProgress)(nil), "cockroach.sql.jobs.jobspb.SchemaChangeGCProgress")
	proto.RegisterType((*SchemaChangeGCProgress_IndexProgress)(nil), "cockroach.sql.jobs.jobspb.SchemaChangeGCProgress.IndexProgress")
	proto.RegisterType((*SchemaChangeGCProgress_TableProgress)(nil), "cockroach.sql.jobs.jobspb.SchemaChangeGCProgress.TableProgress")
	proto.RegisterType((*SchemaChangeGCProgress_TenantProgress)(nil), "cockroach.sql.jobs.jobspb.SchemaChangeGCProgress.TenantProgress")
	proto.RegisterType((*ChangefeedTargetTable)(nil), "cockroach.sql.jobs.jobspb.ChangefeedTargetTable")
	proto.RegisterType((*ChangefeedTargetSpecification)(nil), "cockroach.sql.jobs.jobspb.ChangefeedTargetSpecification")
	proto.RegisterType((*ChangefeedDetails)(nil), "cockroach.sql.jobs.jobspb.ChangefeedDetails")
	proto.RegisterMapType((map[string]string)(nil), "cockroach.sql.jobs.jobspb.ChangefeedDetails.OptsEntry")
	proto.RegisterMapType((ChangefeedTargets)(nil), "cockroach.sql.jobs.jobspb.ChangefeedDetails.TablesEntry")
	proto.RegisterType((*ResolvedSpan)(nil), "cockroach.sql.jobs.jobspb.ResolvedSpan")
	proto.RegisterType((*ResolvedSpans)(nil), "cockroach.sql.jobs.jobspb.ResolvedSpans")
	proto.RegisterType((*ResolvedSpans_Stats)(nil), "cockroach.sql.jobs.jobspb.ResolvedSpans.Stats")
	proto.RegisterType((*TimestampSpansMap)(nil), "cockroach.sql.jobs.jobspb.TimestampSpansMap")
	proto.RegisterType((*TimestampSpansMap_Entry)(nil), "cockroach.sql.jobs.jobspb.TimestampSpansMap.Entry")
	proto.RegisterType((*ChangefeedProgress)(nil), "cockroach.sql.jobs.jobspb.ChangefeedProgress")
	proto.RegisterType((*CreateStatsDetails)(nil), "cockroach.sql.jobs.jobspb.CreateStatsDetails")
	proto.RegisterType((*CreateStatsDetails_ColStat)(nil), "cockroach.sql.jobs.jobspb.CreateStatsDetails.ColStat")
	proto.RegisterType((*CreateStatsProgress)(nil), "cockroach.sql.jobs.jobspb.CreateStatsProgress")
	proto.RegisterType((*MigrationDetails)(nil), "cockroach.sql.jobs.jobspb.MigrationDetails")
	proto.RegisterType((*MigrationProgress)(nil), "cockroach.sql.jobs.jobspb.MigrationProgress")
	proto.RegisterType((*AutoSQLStatsCompactionDetails)(nil), "cockroach.sql.jobs.jobspb.AutoSQLStatsCompactionDetails")
	proto.RegisterType((*AutoSQLStatsCompactionProgress)(nil), "cockroach.sql.jobs.jobspb.AutoSQLStatsCompactionProgress")
	proto.RegisterType((*RowLevelTTLDetails)(nil), "cockroach.sql.jobs.jobspb.RowLevelTTLDetails")
	proto.RegisterType((*RowLevelTTLProgress)(nil), "cockroach.sql.jobs.jobspb.RowLevelTTLProgress")
	proto.RegisterType((*RowLevelTTLProcessorProgress)(nil), "cockroach.sql.jobs.jobspb.RowLevelTTLProcessorProgress")
	proto.RegisterType((*SchemaTelemetryDetails)(nil), "cockroach.sql.jobs.jobspb.SchemaTelemetryDetails")
	proto.RegisterType((*SchemaTelemetryProgress)(nil), "cockroach.sql.jobs.jobspb.SchemaTelemetryProgress")
	proto.RegisterType((*PollJobsStatsDetails)(nil), "cockroach.sql.jobs.jobspb.PollJobsStatsDetails")
	proto.RegisterType((*PollJobsStatsProgress)(nil), "cockroach.sql.jobs.jobspb.PollJobsStatsProgress")
	proto.RegisterType((*AutoConfigRunnerDetails)(nil), "cockroach.sql.jobs.jobspb.AutoConfigRunnerDetails")
	proto.RegisterType((*AutoConfigRunnerProgress)(nil), "cockroach.sql.jobs.jobspb.AutoConfigRunnerProgress")
	proto.RegisterType((*AutoConfigEnvRunnerDetails)(nil), "cockroach.sql.jobs.jobspb.AutoConfigEnvRunnerDetails")
	proto.RegisterType((*AutoConfigEnvRunnerProgress)(nil), "cockroach.sql.jobs.jobspb.AutoConfigEnvRunnerProgress")
	proto.RegisterType((*AutoConfigTaskDetails)(nil), "cockroach.sql.jobs.jobspb.AutoConfigTaskDetails")
	proto.RegisterType((*AutoConfigTaskProgress)(nil), "cockroach.sql.jobs.jobspb.AutoConfigTaskProgress")
	proto.RegisterType((*AutoUpdateSQLActivityDetails)(nil), "cockroach.sql.jobs.jobspb.AutoUpdateSQLActivityDetails")
	proto.RegisterType((*AutoUpdateSQLActivityProgress)(nil), "cockroach.sql.jobs.jobspb.AutoUpdateSQLActivityProgress")
	proto.RegisterType((*MVCCStatisticsJobDetails)(nil), "cockroach.sql.jobs.jobspb.MVCCStatisticsJobDetails")
	proto.RegisterType((*MVCCStatisticsJobProgress)(nil), "cockroach.sql.jobs.jobspb.MVCCStatisticsJobProgress")
	proto.RegisterType((*StandbyReadTSPollerDetails)(nil), "cockroach.sql.jobs.jobspb.StandbyReadTSPollerDetails")
	proto.RegisterType((*StandbyReadTSPollerProgress)(nil), "cockroach.sql.jobs.jobspb.StandbyReadTSPollerProgress")
	proto.RegisterType((*HotRangesLoggerDetails)(nil), "cockroach.sql.jobs.jobspb.HotRangesLoggerDetails")
	proto.RegisterType((*InspectDetails)(nil), "cockroach.sql.jobs.jobspb.InspectDetails")
	proto.RegisterType((*InspectDetails_Check)(nil), "cockroach.sql.jobs.jobspb.InspectDetails.Check")
	proto.RegisterType((*UpdateTableMetadataCacheDetails)(nil), "cockroach.sql.jobs.jobspb.UpdateTableMetadataCacheDetails")
	proto.RegisterType((*UpdateTableMetadataCacheProgress)(nil), "cockroach.sql.jobs.jobspb.UpdateTableMetadataCacheProgress")
	proto.RegisterType((*ImportRollbackDetails)(nil), "cockroach.sql.jobs.jobspb.ImportRollbackDetails")
	proto.RegisterType((*SqlActivityFlushDetails)(nil), "cockroach.sql.jobs.jobspb.SqlActivityFlushDetails")
	proto.RegisterType((*SqlActivityFlushProgress)(nil), "cockroach.sql.jobs.jobspb.SqlActivityFlushProgress")
	proto.RegisterType((*HotRangesLoggerProgress)(nil), "cockroach.sql.jobs.jobspb.HotRangesLoggerProgress")
	proto.RegisterType((*InspectProgress)(nil), "cockroach.sql.jobs.jobspb.InspectProgress")
	proto.RegisterType((*ImportRollbackProgress)(nil), "cockroach.sql.jobs.jobspb.ImportRollbackProgress")
	proto.RegisterType((*Payload)(nil), "cockroach.sql.jobs.jobspb.Payload")
	proto.RegisterType((*Progress)(nil), "cockroach.sql.jobs.jobspb.Progress")
	proto.RegisterType((*Job)(nil), "cockroach.sql.jobs.jobspb.Job")
	proto.RegisterType((*RetriableExecutionFailure)(nil), "cockroach.sql.jobs.jobspb.RetriableExecutionFailure")
	proto.RegisterType((*TraceData)(nil), "cockroach.sql.jobs.jobspb.TraceData")
}

func init() { proto.RegisterFile("jobs/jobspb/jobs.proto", fileDescriptor_6c315f3a2536c4ef) }

var fileDescriptor_6c315f3a2536c4ef = []byte{
	// 10734 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xcc, 0xbd, 0x59, 0x6c, 0x23, 0x59,
	0x96, 0x1e, 0x2c, 0x52, 0x94, 0x44, 0x1e, 0x89, 0x54, 0xf0, 0x6a, 0xa3, 0x98, 0x0b, 0x55, 0xac,
	0x2d, 0xb3, 0x16, 0xaa, 0x3a, 0x6b, 0xed, 0x9a, 0xae, 0x85, 0x5b, 0xa6, 0xa8, 0x94, 0x28, 0x65,
	0x90, 0xca, 0xac, 0xac, 0x9e, 0xea, 0xe8, 0x10, 0xe3, 0x4a, 0x8a, 0x52, 0x30, 0x82, 0x19, 0x11,
	0x94, 0x52, 0x3d, 0xff, 0xcc, 0xdf, 0x18, 0xbb, 0x01, 0x4f, 0xbe, 0x78, 0x1a, 0x68, 0x1b, 0x1e,
	0x78, 0xd2, 0x1e, 0x78, 0xba, 0x0d, 0xdb, 0xb0, 0x61, 0x78, 0x60, 0xc0, 0x7e, 0xb4, 0x9f, 0xdc,
	0x63, 0xd8, 0x40, 0x3f, 0x0e, 0xfa, 0x41, 0x63, 0xab, 0x01, 0x63, 0x1e, 0x0c, 0xc3, 0x8f, 0x46,
	0x75, 0x3f, 0x18, 0x77, 0x0b, 0x46, 0x70, 0x11, 0x29, 0x65, 0x56, 0x97, 0x5f, 0x32, 0x15, 0x77,
	0x39, 0x77, 0x3b, 0xf7, 0xdc, 0xf3, 0x9d, 0x7b, 0xee, 0x21, 0x2c, 0x7e, 0x69, 0xed, 0x3a, 0xab,
	0xe4, 0x9f, 0xd6, 0x2e, 0xfd, 0x2f, 0xd7, 0xb2, 0x2d, 0xd7, 0x42, 0xcb, 0x0d, 0xab, 0x71, 0x68,
	0x5b, 0x6a, 0xe3, 0x20, 0xe7, 0x3c, 0x32, 0x72, 0x34, 0x87, 0x95, 0x4a, 0x2f, 0x60, 0xdb, 0xb6,
	0x6c, 0x52, 0x9e, 0xfd, 0xc1, 0x6a, 0xa4, 0xe7, 0xf7, 0xad, 0x7d, 0x8b, 0xfe, 0xb9, 0x4a, 0xfe,
	0xe2, 0xa9, 0xc9, 0xc3, 0xa3, 0xd5, 0xc3, 0xa3, 0xd6, 0xee, 0xaa, 0xda, 0xd2, 0x79, 0x12, 0xa2,
	0x64, 0x5b, 0xbb, 0xab, 0x9a, 0xea, 0xaa, 0x3c, 0x6d, 0x51, 0xa4, 0x35, 0xb1, 0xab, 0xfa, 0xd2,
	0x53, 0x22, 0x5d, 0xb7, 0xde, 0xdc, 0xb3, 0xec, 0xa6, 0xea, 0x8a, 0xe6, 0x5e, 0x74, 0x1e, 0x19,
	0xab, 0x0d, 0xd5, 0x55, 0x0d, 0x6b, 0x7f, 0x55, 0xc3, 0x4e, 0xa3, 0xb5, 0xbb, 0xea, 0xb8, 0x76,
	0xbb, 0xe1, 0xb6, 0x6d, 0xac, 0xf1, 0x42, 0x19, 0x7f, 0xa1, 0x86, 0xea, 0xb6, 0x76, 0xc5, 0x97,
	0x28, 0xd0, 0x6c, 0x1b, 0xae, 0xee, 0x62, 0x53, 0x35, 0xdd, 0xd5, 0xa6, 0xab, 0x9b, 0x7b, 0x16,
	0x69, 0xcc, 0xdc, 0x13, 0xfd, 0x7f, 0x89, 0x50, 0x70, 0xb0, 0xe3, 0xe8, 0x96, 0x49, 0xfa, 0x45,
	0x5a, 0x61, 0x5f, 0x8a, 0xbf, 0x9b, 0x6d, 0x57, 0x37, 0x56, 0x0f, 0x8c, 0xc6, 0xaa, 0xab, 0x37,
	0xb1, 0xe3, 0xaa, 0xcd, 0x96, 0xa8, 0xdf, 0x30, 0xda, 0x8e, 0x8b, 0xed, 0x23, 0x6c, 0x93, 0x4a,
	0xab, 0xfc, 0x53, 0xe1, 0xdf, 0xa2, 0x1b, 0xfb, 0x96, 0xb5, 0x6f, 0xe0, 0x55, 0xfa, 0xb5, 0xdb,
	0xde, 0xeb, 0x21, 0xf3, 0x1a, 0x6d, 0xc0, 0xb5, 0xd5, 0x86, 0x6e, 0xee, 0x8b, 0xff, 0x5b, 0xbb,
	0xab, 0x36, 0x6e, 0x58, 0xb6, 0x86, 0x35, 0xc5, 0x69, 0xa9, 0x82, 0xd8, 0xbb, 0xfe, 0x41, 0xe3,
	0xc7, 0x2e, 0xb6, 0x4d, 0xd5, 0xe8, 0xfe, 0x26, 0xab, 0xc7, 0xff, 0x64, 0xd5, 0xb2, 0xff, 0x2b,
	0x0c, 0x4b, 0x05, 0xb5, 0x71, 0xd8, 0x6e, 0x95, 0xcd, 0x86, 0x7d, 0xd2, 0x72, 0x75, 0xcb, 0xdc,
	0xa2, 0xff, 0x3a, 0x48, 0x82, 0xf1, 0x43, 0x7c, 0x92, 0x0a, 0xad, 0x84, 0x6e, 0xcc, 0xc8, 0xe4,
	0x4f, 0xf4, 0x11, 0x44, 0x9a, 0x96, 0x86, 0x53, 0xe1, 0x95, 0xd0, 0x8d, 0xc4, 0xad, 0x9b, 0xb9,
	0x81, 0xec, 0x92, 0xeb, 0x50, 0xdb, 0xb4, 0x34, 0x2c, 0xd3, 0x6a, 0x68, 0x17, 0xa2, 0x87, 0x4d,
	0x47, 0x21, 0x13, 0x9d, 0x1a, 0x5f, 0x09, 0xdd, 0x98, 0xbe, 0xf5, 0xe1, 0x39, 0x24, 0x06, 0x74,
	0x2b, 0x77, 0x77, 0xb3, 0x56, 0x31, 0xf7, 0xac, 0xc2, 0xf4, 0xd9, 0x69, 0x66, 0x8a, 0x7f, 0xc8,
	0x53, 0x87, 0x4d, 0x87, 0xfc, 0x81, 0x5e, 0x86, 0x84, 0xad, 0x1e, 0x2b, 0x2d, 0xd5, 0x71, 0x5a,
	0x07, 0xb6, 0xea, 0xe0, 0x54, 0x64, 0x25, 0x74, 0x23, 0x26, 0xc7, 0x6d, 0xf5, 0x78, 0xdb, 0x4b,
	0x44, 0x2b, 0x30, 0x43, 0x8a, 0x91, 0xee, 0xb4, 0x6d, 0xdd, 0x49, 0x4d, 0xac, 0x8c, 0xdf, 0x88,
	0xc9, 0x60, 0xab, 0xc7, 0x77, 0x9b, 0xce, 0x8e, 0xad, 0x3b, 0xe9, 0x2d, 0x10, 0xc4, 0xc9, 0x44,
	0xb4, 0x6d, 0x9d, 0x4e, 0x44, 0x4c, 0x26, 0x7f, 0xa2, 0x37, 0x00, 0x61, 0xd6, 0x31, 0xac, 0x51,
	0x96, 0x50, 0xc8, 0x4c, 0x85, 0xe9, 0x4c, 0x49, 0x5e, 0x4e, 0x49, 0x75, 0xd5, 0xbb, 0xf8, 0xe4,
	0xc3, 0xc8, 0xdf, 0xfc, 0x59, 0x26, 0xc4, 0xfe, 0xcd, 0xfe, 0x70, 0x1c, 0x12, 0x9d, 0x31, 0x51,
	0xf2, 0x6b, 0x30, 0xe9, 0x34, 0x0e, 0x70, 0x13, 0xd3, 0x16, 0x12, 0xb7, 0xde, 0x1a, 0x69, 0x5e,
	0x49, 0xd5, 0x5c, 0x8d, 0xd6, 0x93, 0x79, 0x7d, 0x84, 0x20, 0xe2, 0xa8, 0x86, 0xcb, 0x3b, 0x42,
	0xff, 0x46, 0xff, 0x30, 0x04, 0x2b, 0xdd, 0x3d, 0x2a, 0x9c, 0xdc, 0xdd, 0xac, 0x6d, 0xaa, 0x84,
	0x27, 0xef, 0xe2, 0x93, 0x4a, 0x29, 0x35, 0xbe, 0x32, 0x7e, 0x63, 0xfa, 0xd6, 0xd6, 0xe8, 0x0d,
	0x97, 0x87, 0x50, 0x2c, 0x9b, 0xae, 0x7d, 0x22, 0x0f, 0x6d, 0x38, 0x5d, 0x83, 0x97, 0x47, 0x22,
	0xe5, 0x67, 0xc6, 0x18, 0x63, 0xc6, 0x79, 0x98, 0x38, 0x52, 0x8d, 0x36, 0xe6, 0xa3, 0x65, 0x1f,
	0x1f, 0x86, 0x3f, 0x08, 0x65, 0x97, 0x60, 0x92, 0x4d, 0x0c, 0x8a, 0x43, 0x2c, 0x5f, 0xae, 0xdd,
	0x7a, 0xf7, 0xbd, 0x3b, 0xc5, 0x4d, 0x69, 0x8c, 0x2f, 0xc1, 0x9f, 0x44, 0x61, 0xb1, 0xe6, 0xda,
	0x58, 0x6d, 0x56, 0xcc, 0x7d, 0xec, 0x90, 0x31, 0x95, 0xb0, 0xab, 0xea, 0x86, 0x83, 0xde, 0x85,
	0x25, 0xc7, 0x6a, 0xdb, 0x0d, 0xac, 0x88, 0x2d, 0xdb, 0xb0, 0x4c, 0x53, 0xe9, 0xac, 0xfe, 0x3c,
	0xcb, 0x2e, 0xb2, 0xdc, 0xa2, 0x65, 0x9a, 0x3b, 0xb6, 0x8e, 0x6e, 0x42, 0xcc, 0xa1, 0x04, 0x15,
	0x5d, 0xa3, 0xfc, 0x16, 0x29, 0xcc, 0x9c, 0x9d, 0x66, 0xa2, 0xbc, 0x95, 0x92, 0x1c, 0x65, 0xd9,
	0x15, 0x0d, 0x7d, 0x0b, 0x22, 0x64, 0xd7, 0xd2, 0x4e, 0x4f, 0xdf, 0x5a, 0xf2, 0xcd, 0x38, 0x17,
	0x7a, 0xb9, 0x5a, 0x4b, 0x35, 0x0b, 0x91, 0x9f, 0x9f, 0x66, 0xc6, 0x64, 0x5a, 0x14, 0x19, 0xb0,
	0xa0, 0x91, 0x6e, 0x9a, 0x2a, 0xe9, 0xaa, 0xc2, 0xe4, 0x16, 0x69, 0x69, 0x8a, 0xd2, 0xb8, 0xd2,
	0x87, 0x46, 0x9d, 0x96, 0xa9, 0x94, 0x0a, 0x57, 0x08, 0x9d, 0xb3, 0xd3, 0xcc, 0x5c, 0xa9, 0x43,
	0x41, 0x64, 0xca, 0x73, 0x5a, 0x4f, 0xa2, 0x86, 0x9a, 0x80, 0xf8, 0x14, 0xf0, 0x86, 0x4c, 0xb5,
	0x89, 0x53, 0x51, 0x32, 0xfa, 0xc2, 0x27, 0x84, 0xda, 0x2f, 0x4f, 0x33, 0xef, 0xef, 0xeb, 0xee,
	0x41, 0x7b, 0x37, 0xd7, 0xb0, 0x9a, 0xab, 0x5e, 0xe3, 0xda, 0x6e, 0xe7, 0xef, 0xd5, 0xd6, 0xe1,
	0xfe, 0x6a, 0xb0, 0x33, 0x55, 0xb5, 0x89, 0x65, 0x89, 0x91, 0xee, 0xa4, 0xa0, 0x7f, 0x10, 0x82,
	0x6b, 0x44, 0x14, 0xe1, 0x06, 0xd9, 0x4a, 0x9e, 0x04, 0x54, 0x98, 0x8c, 0x23, 0xa3, 0x04, 0xb2,
	0xbc, 0x85, 0x9d, 0x5f, 0x9e, 0x66, 0xde, 0x1e, 0xa9, 0x59, 0x2a, 0x34, 0xdb, 0x6d, 0x5d, 0xcb,
	0xed, 0xec, 0x54, 0x4a, 0x67, 0xa7, 0x99, 0xf4, 0xb6, 0xa0, 0x5f, 0x17, 0xe4, 0x65, 0x4a, 0xbd,
	0x52, 0x92, 0xd3, 0xad, 0x41, 0x79, 0x1a, 0xba, 0x07, 0x4b, 0x36, 0x6e, 0x19, 0x7a, 0x83, 0xcf,
	0xbb, 0x6b, 0x28, 0x0e, 0x6e, 0x58, 0xa6, 0xe6, 0xa4, 0xa6, 0x57, 0x42, 0x37, 0x26, 0x0a, 0xcb,
	0x67, 0xa7, 0x99, 0x05, 0xb9, 0x53, 0xa4, 0x5e, 0xdf, 0xa8, 0xb1, 0x02, 0xf2, 0x82, 0xaf, 0x66,
	0xdd, 0x35, 0x78, 0x32, 0x7a, 0x08, 0x8b, 0x7e, 0x92, 0x8e, 0xab, 0xda, 0x2e, 0x1d, 0x74, 0x6a,
	0x86, 0xae, 0xe5, 0x35, 0xdf, 0x5a, 0x92, 0x71, 0xe4, 0x0e, 0x8c, 0x46, 0xce, 0xeb, 0x19, 0xe7,
	0x8a, 0x79, 0x1f, 0x89, 0x1a, 0xa1, 0x40, 0x0a, 0xa0, 0x2f, 0x40, 0x0a, 0xae, 0x9b, 0xae, 0xa5,
	0xe2, 0xc3, 0x19, 0x64, 0x91, 0x33, 0x48, 0xa2, 0xe6, 0x5b, 0x99, 0x4a, 0x49, 0x4e, 0xf8, 0x57,
	0xaa, 0xa2, 0xa1, 0x1f, 0x40, 0xb2, 0x6b, 0x67, 0xe8, 0x5a, 0x2a, 0x41, 0x97, 0xa6, 0xca, 0xb9,
	0xe2, 0x92, 0xcb, 0x33, 0x5b, 0xf3, 0x6f, 0xa9, 0x4a, 0x49, 0x9e, 0x0d, 0xec, 0xb1, 0x8a, 0x86,
	0x1e, 0x40, 0xc2, 0xc6, 0xaa, 0xe6, 0x1b, 0xd8, 0xec, 0xf0, 0x81, 0xcd, 0xf3, 0x81, 0xcd, 0xc8,
	0x58, 0xd5, 0xbc, 0x61, 0xcd, 0xd8, 0x9d, 0x2f, 0x6d, 0x3d, 0x12, 0x8d, 0x49, 0xb0, 0x1e, 0x89,
	0x4e, 0x48, 0x93, 0xeb, 0x91, 0xe8, 0xa4, 0x34, 0x95, 0x7d, 0x04, 0xcb, 0x5d, 0xa2, 0xa1, 0x78,
	0x80, 0x1b, 0x87, 0x2d, 0x4b, 0x37, 0x5d, 0x54, 0x27, 0xfd, 0x70, 0x2c, 0xe3, 0x88, 0x1f, 0xbd,
	0x4e, 0x2a, 0x44, 0xe5, 0xe6, 0xab, 0xe7, 0xc8, 0x4d, 0x99, 0x57, 0xf0, 0xed, 0xea, 0xb8, 0xed,
	0x4b, 0x73, 0xb2, 0x7f, 0x34, 0x09, 0x4b, 0x5d, 0x6d, 0x6e, 0xdb, 0xd6, 0xbe, 0x8d, 0x1d, 0x07,
	0xdd, 0x86, 0x99, 0x46, 0xdb, 0xb5, 0x8e, 0xb0, 0xcd, 0xb8, 0x24, 0x34, 0x3a, 0x97, 0x4c, 0xf3,
	0x8a, 0x94, 0x39, 0x36, 0x60, 0x56, 0x30, 0x0d, 0xdf, 0x65, 0x5c, 0x78, 0x8c, 0x44, 0x2a, 0xd1,
	0xa9, 0x4b, 0xa9, 0xad, 0x01, 0xea, 0xe2, 0x62, 0xb7, 0xed, 0xa4, 0x26, 0x57, 0x42, 0x37, 0xe2,
	0x85, 0x65, 0xce, 0x0c, 0x49, 0x39, 0xc0, 0xa4, 0x6e, 0xdb, 0x91, 0x93, 0x76, 0x77, 0x12, 0xfa,
	0x1c, 0xa0, 0xe1, 0xcd, 0x2f, 0x95, 0x9c, 0xd3, 0xb7, 0xde, 0x39, 0x67, 0x36, 0x07, 0xae, 0x0d,
	0xef, 0xa9, 0x8f, 0x1a, 0xca, 0xc1, 0x5c, 0x4b, 0xb5, 0x5d, 0x9d, 0xf6, 0x51, 0x88, 0x71, 0x71,
	0xd2, 0x27, 0xbd, 0x2c, 0x2e, 0xc3, 0x1d, 0xb4, 0x43, 0xb6, 0x7b, 0x53, 0xd5, 0x4d, 0xdd, 0xdc,
	0x57, 0xc4, 0xac, 0xb3, 0x65, 0x8e, 0xd2, 0x65, 0x1e, 0x22, 0xac, 0x17, 0xbc, 0xda, 0x45, 0x56,
	0x99, 0x2e, 0x2f, 0x7a, 0x07, 0x16, 0x75, 0x53, 0x77, 0x75, 0xd5, 0x50, 0x9c, 0x96, 0xa1, 0xbb,
	0x4a, 0xc3, 0x6a, 0xb6, 0x0c, 0xec, 0xe2, 0x54, 0x6c, 0x25, 0x74, 0x23, 0x2a, 0xcf, 0xf3, 0xdc,
	0x1a, 0xc9, 0x2c, 0xf2, 0x3c, 0xf4, 0x1e, 0x2c, 0x89, 0x5a, 0x36, 0x3e, 0xc2, 0xb6, 0xab, 0xd8,
	0xf8, 0x51, 0x5b, 0xb7, 0x31, 0x93, 0x87, 0x51, 0x79, 0x81, 0x67, 0xcb, 0x34, 0x57, 0xe6, 0x99,
	0x68, 0x0b, 0x92, 0x5d, 0xf5, 0x5c, 0x8b, 0x4a, 0xab, 0x11, 0x97, 0x7a, 0x36, 0x40, 0xb6, 0x6e,
	0xa1, 0xef, 0x43, 0xba, 0x8b, 0x73, 0x14, 0xd5, 0x15, 0xd3, 0x73, 0x11, 0xa9, 0xb5, 0x14, 0x64,
	0xa2, 0xbc, 0xcb, 0x67, 0x69, 0x3d, 0x12, 0x0d, 0x4b, 0xe3, 0xeb, 0x91, 0xe8, 0xb8, 0x14, 0xc9,
	0xfe, 0x9f, 0x10, 0x2c, 0xad, 0xe9, 0x8e, 0x6b, 0xd9, 0x27, 0x32, 0x76, 0xb1, 0xe9, 0x3f, 0x9b,
	0xff, 0x74, 0xe8, 0x49, 0x41, 0x35, 0xd5, 0xc2, 0xc3, 0x67, 0x13, 0x47, 0x97, 0x3d, 0x2d, 0x3e,
	0x86, 0x24, 0x7e, 0xdc, 0xd2, 0x6d, 0xb6, 0x27, 0x8e, 0x75, 0x53, 0xb3, 0x8e, 0x29, 0x47, 0x8f,
	0x17, 0x92, 0x5f, 0x9d, 0x66, 0xe2, 0xa4, 0xc3, 0xb9, 0x52, 0x9b, 0xe5, 0xcb, 0x52, 0xa7, 0xec,
	0x03, 0x5a, 0x34, 0xdb, 0x82, 0x54, 0xf7, 0xc8, 0x3d, 0x31, 0x50, 0x87, 0x39, 0x43, 0x75, 0x5c,
	0xe5, 0x00, 0xab, 0xb6, 0xbb, 0x8b, 0x55, 0xd7, 0x2f, 0x0d, 0xd2, 0x39, 0x86, 0x23, 0x72, 0x02,
	0x47, 0xf8, 0xa6, 0x3e, 0x4a, 0xe6, 0xe2, 0x8f, 0xff, 0x3a, 0x13, 0x92, 0x93, 0x84, 0xc0, 0x9a,
	0xa8, 0x4f, 0x4a, 0x64, 0x7f, 0x92, 0x80, 0xe5, 0x0d, 0x6b, 0x5f, 0x6f, 0x90, 0xe5, 0xf6, 0x76,
	0xe6, 0x33, 0xaa, 0x42, 0x19, 0x98, 0x76, 0xd5, 0x5d, 0x03, 0x53, 0xb5, 0xc1, 0x49, 0x85, 0x99,
	0x5e, 0x4d, 0x93, 0xc8, 0x79, 0xef, 0xa0, 0x63, 0xf0, 0xcb, 0x01, 0xa5, 0xa5, 0xea, 0xb6, 0xc3,
	0xf5, 0xcf, 0xd2, 0x39, 0x3b, 0x7f, 0x60, 0x47, 0x73, 0xbe, 0xa4, 0x6d, 0x55, 0xb7, 0x39, 0xbb,
	0x49, 0x76, 0x30, 0xd9, 0xb9, 0x88, 0x92, 0x36, 0xf8, 0x98, 0x9e, 0x78, 0xd6, 0x63, 0xba, 0xef,
	0x39, 0x3a, 0xf9, 0xdb, 0x39, 0x47, 0x7f, 0x12, 0x82, 0x2b, 0x1a, 0xde, 0x53, 0xdb, 0x06, 0x91,
	0x42, 0xe6, 0x9e, 0xa1, 0x37, 0x88, 0x5c, 0x71, 0x2c, 0xa3, 0x4d, 0x3a, 0xc9, 0x8f, 0x84, 0xea,
	0xa5, 0x56, 0xa1, 0xc4, 0xe8, 0x16, 0x39, 0x59, 0xd9, 0xa3, 0xca, 0x67, 0x63, 0x59, 0x1b, 0x54,
	0x00, 0xc9, 0x1c, 0x55, 0xc6, 0x28, 0xfa, 0xf9, 0xf8, 0x52, 0xcd, 0xe7, 0x5b, 0x2d, 0xe3, 0xc4,
	0x07, 0x35, 0x5f, 0x84, 0x78, 0x13, 0xbb, 0xb6, 0xde, 0x70, 0x14, 0x43, 0xdd, 0xc5, 0x06, 0x95,
	0x9a, 0x31, 0x79, 0x86, 0x27, 0x6e, 0x90, 0x34, 0x74, 0x1f, 0xa6, 0x34, 0xdd, 0x69, 0xa8, 0xb6,
	0x46, 0x45, 0x64, 0xe2, 0xd6, 0x77, 0x2e, 0x37, 0x74, 0x46, 0x43, 0x16, 0xc4, 0xd0, 0x0b, 0x30,
	0xd3, 0xb0, 0xb1, 0xea, 0x62, 0x85, 0xf2, 0x3d, 0x95, 0x92, 0x51, 0x79, 0x9a, 0xa5, 0xd5, 0x49,
	0x12, 0xfa, 0x5b, 0x21, 0x58, 0xd6, 0xe9, 0x31, 0x86, 0x35, 0x45, 0x60, 0x72, 0x85, 0xe3, 0x75,
	0xae, 0xb7, 0xe5, 0xbb, 0x7a, 0x23, 0x8c, 0x18, 0x5d, 0xe8, 0x3e, 0xd7, 0x41, 0xf7, 0xb9, 0x32,
	0xff, 0xb3, 0xc8, 0xb2, 0x84, 0xe8, 0x15, 0x2d, 0x75, 0x65, 0x93, 0xb3, 0x89, 0x9e, 0x12, 0x0e,
	0x56, 0xf8, 0xd6, 0x68, 0x58, 0xcd, 0xa6, 0x6a, 0x32, 0xcd, 0x2e, 0x46, 0x58, 0x98, 0xe6, 0xb2,
	0x2d, 0x52, 0x64, 0x79, 0x64, 0x23, 0xb5, 0x54, 0x1b, 0x77, 0x34, 0xb1, 0x71, 0xb6, 0x91, 0xb6,
	0x69, 0x22, 0xd9, 0x48, 0x2c, 0xbb, 0xa2, 0xa1, 0x14, 0x4c, 0x09, 0x8a, 0x12, 0xa5, 0x28, 0x3e,
	0xd1, 0x6b, 0x90, 0x74, 0x0e, 0xf5, 0x96, 0x42, 0x91, 0xab, 0xaa, 0xd0, 0x73, 0x3b, 0x95, 0xa4,
	0x13, 0x35, 0x4b, 0x32, 0x28, 0x80, 0x53, 0xe9, 0x01, 0x9f, 0xfe, 0x4f, 0x21, 0x98, 0xed, 0xda,
	0xe5, 0xe8, 0x13, 0x48, 0x3a, 0x76, 0x43, 0xd1, 0xb0, 0xd3, 0xb0, 0xf5, 0x96, 0x6b, 0xd9, 0xe2,
	0x00, 0x98, 0x28, 0xcc, 0xd1, 0xcd, 0x60, 0x37, 0x4a, 0x5e, 0x1e, 0xdd, 0x0c, 0x81, 0x04, 0x8d,
	0x10, 0xd0, 0x1c, 0xb7, 0x8b, 0x40, 0xb8, 0x43, 0xa0, 0xe4, 0xb8, 0x41, 0x02, 0x5a, 0x20, 0x41,
	0x43, 0xb7, 0x60, 0x7a, 0xaf, 0x6d, 0x36, 0xa8, 0x84, 0xd0, 0x35, 0x6a, 0xd0, 0x98, 0x28, 0x24,
	0xcf, 0x4e, 0x33, 0xf1, 0x92, 0xe3, 0xde, 0xe6, 0x39, 0x95, 0x92, 0x0c, 0xa2, 0x54, 0x45, 0x4b,
	0xff, 0x49, 0x18, 0x96, 0x07, 0xee, 0x14, 0xf4, 0x4f, 0x42, 0x90, 0xea, 0xb3, 0x2f, 0x15, 0xf7,
	0xa4, 0x25, 0x6c, 0x03, 0x07, 0xcf, 0x77, 0x73, 0x0e, 0xce, 0x91, 0x17, 0x1b, 0x3d, 0x69, 0xf5,
	0x93, 0x16, 0x26, 0x02, 0xde, 0x3f, 0x6c, 0x3a, 0x63, 0xfe, 0x31, 0x66, 0xdf, 0x3b, 0x6f, 0x88,
	0x53, 0x30, 0xbe, 0xf1, 0xe0, 0x81, 0x34, 0x46, 0xfe, 0x28, 0x6d, 0xdc, 0x93, 0x42, 0xe4, 0x8f,
	0x9d, 0xd2, 0x6d, 0x29, 0x9c, 0xbd, 0x09, 0x31, 0x6f, 0x17, 0x13, 0xe0, 0x5e, 0x69, 0x36, 0xb1,
	0xa6, 0xab, 0x2e, 0x96, 0xc6, 0xc8, 0xe7, 0x7d, 0xd5, 0xd0, 0x35, 0xa2, 0x3d, 0x48, 0xa1, 0xec,
	0x0e, 0x4c, 0xf1, 0x4d, 0x87, 0x10, 0x24, 0xf8, 0x9f, 0x55, 0xcb, 0x3d, 0xd0, 0xcd, 0x7d, 0x69,
	0x0c, 0x65, 0xe0, 0x0a, 0x4f, 0x2b, 0x96, 0x8a, 0x95, 0x7d, 0xd3, 0xb2, 0xb1, 0x56, 0xaf, 0x6f,
	0x94, 0x30, 0x51, 0xad, 0x1c, 0x29, 0x84, 0x16, 0x20, 0xc9, 0x0b, 0xe4, 0x0d, 0x43, 0x24, 0x87,
	0xd7, 0x23, 0xd1, 0xa8, 0x14, 0xcb, 0xfe, 0x26, 0x0c, 0xe9, 0xde, 0xa9, 0xf4, 0xce, 0xe2, 0x3e,
	0xaa, 0xf4, 0xc4, 0xe5, 0x55, 0xe9, 0xa0, 0x02, 0x3c, 0xf9, 0xdb, 0x50, 0x80, 0xa3, 0x83, 0x14,
	0xe0, 0xb7, 0x60, 0xbe, 0xd5, 0xde, 0x35, 0x74, 0xe7, 0x00, 0x6b, 0x8a, 0x89, 0x8f, 0x99, 0xf4,
	0x72, 0xb8, 0x9e, 0x8a, 0xbc, 0xbc, 0x2a, 0x3e, 0xa6, 0x42, 0x8c, 0xea, 0xb6, 0xf4, 0x6c, 0xc4,
	0x9a, 0x12, 0x94, 0x23, 0x5c, 0x49, 0x9d, 0xe7, 0xb9, 0xb2, 0x5f, 0x8c, 0xac, 0x47, 0xa2, 0x21,
	0x3a, 0xd9, 0x9e, 0xda, 0xb7, 0x1e, 0x89, 0x46, 0xa4, 0x89, 0xf5, 0x48, 0x74, 0x4a, 0x8a, 0x66,
	0x7f, 0x36, 0x0e, 0x29, 0x56, 0xb0, 0x8f, 0x52, 0xf2, 0x36, 0x4c, 0xf8, 0x81, 0xd7, 0x10, 0x8d,
	0x9c, 0x95, 0x1d, 0x41, 0x71, 0x0c, 0x7f, 0x93, 0x8a, 0xe3, 0x3a, 0xc4, 0x3a, 0xc0, 0x76, 0x7c,
	0x38, 0xb0, 0x95, 0x38, 0xb0, 0x8d, 0x7a, 0xa0, 0x36, 0xea, 0x0a, 0x94, 0xfe, 0x8c, 0x4a, 0x28,
	0x11, 0xed, 0x4c, 0x7b, 0xd3, 0x35, 0x86, 0x94, 0xe2, 0x4c, 0xb4, 0xd3, 0xf5, 0xae, 0x94, 0x1c,
	0x39, 0x4a, 0xb3, 0x2b, 0x9a, 0x93, 0xfd, 0xcb, 0xb0, 0x80, 0xca, 0xfd, 0x76, 0x49, 0x09, 0xa0,
	0x43, 0xfc, 0x42, 0x8a, 0xaa, 0xaf, 0x1e, 0xfa, 0xc3, 0x10, 0x2c, 0x09, 0x9d, 0x4d, 0xb0, 0xbc,
	0x80, 0x9b, 0xcc, 0x06, 0xbd, 0x3e, 0x74, 0xaf, 0xf4, 0xe9, 0x5d, 0xf7, 0x2e, 0xe2, 0xf8, 0x74,
	0xc1, 0xe9, 0x97, 0x9c, 0x55, 0x61, 0xa1, 0x6f, 0x79, 0x24, 0xc1, 0x4c, 0x75, 0xab, 0xae, 0xdc,
	0xae, 0x54, 0x2b, 0xb5, 0xb5, 0x72, 0x49, 0x1a, 0x43, 0xcb, 0xb0, 0x20, 0xbe, 0x94, 0xda, 0x4e,
	0xb1, 0x58, 0xae, 0xd5, 0x6e, 0xef, 0x6c, 0x6c, 0x3c, 0x94, 0x42, 0xe8, 0x0a, 0x2c, 0x79, 0x59,
	0x3b, 0xd5, 0x40, 0x66, 0x38, 0xfb, 0xaf, 0xc8, 0x5c, 0x36, 0x0e, 0xb0, 0xd6, 0x36, 0xf0, 0x76,
	0xbd, 0x56, 0x3c, 0x60, 0x38, 0x92, 0xb1, 0x08, 0xfa, 0x71, 0x08, 0xd2, 0x83, 0xf9, 0x97, 0xa3,
	0x9e, 0xda, 0xe5, 0x19, 0x37, 0x35, 0x88, 0x71, 0xe5, 0xd4, 0x20, 0xb6, 0x45, 0xf7, 0x61, 0x52,
	0xa5, 0x02, 0x9f, 0xaf, 0xc3, 0x79, 0x5a, 0xdb, 0xc0, 0x91, 0xe5, 0xb6, 0xeb, 0xb5, 0x3c, 0xa5,
	0x22, 0x73, 0x6a, 0xd9, 0x97, 0x20, 0xe6, 0x25, 0x22, 0x80, 0xc9, 0x9d, 0xed, 0x52, 0xbe, 0x5e,
	0x96, 0xc6, 0xd0, 0x34, 0x4c, 0xc9, 0xe5, 0x8d, 0x72, 0xbe, 0x56, 0x96, 0x42, 0xd9, 0x9f, 0x4a,
	0x10, 0x67, 0xd7, 0x03, 0x42, 0x30, 0x14, 0x00, 0x7c, 0x5a, 0xfa, 0x05, 0xcc, 0x24, 0x31, 0xc7,
	0x53, 0xcd, 0x3f, 0x86, 0x28, 0x36, 0xb9, 0x48, 0x0f, 0x8f, 0x4e, 0x61, 0x0a, 0x9b, 0x4c, 0x96,
	0x2f, 0xb3, 0x6b, 0x82, 0x71, 0x6a, 0x2a, 0x9d, 0x3a, 0x3b, 0xcd, 0x8c, 0xef, 0xc8, 0x15, 0x76,
	0x5f, 0xf0, 0xbb, 0x30, 0xed, 0xb3, 0xb5, 0x72, 0x40, 0xfe, 0xce, 0xd0, 0xcb, 0x8f, 0xce, 0xf9,
	0xed, 0xd5, 0x15, 0xd6, 0x1d, 0x1f, 0x39, 0xa2, 0x4c, 0xce, 0x11, 0xd1, 0xae, 0xec, 0x9e, 0x28,
	0x86, 0xd5, 0x50, 0x0d, 0xdd, 0x3d, 0x51, 0x0e, 0x8f, 0xe8, 0x06, 0x9e, 0x3e, 0x77, 0x69, 0x82,
	0xcd, 0x90, 0x53, 0xa0, 0x70, 0xb2, 0xc1, 0x29, 0xdc, 0x3d, 0xa2, 0x96, 0xf7, 0xc2, 0xfc, 0xd9,
	0x69, 0x46, 0xda, 0x91, 0x2b, 0xfe, 0xac, 0xfb, 0xb2, 0xd4, 0xee, 0x2a, 0x8c, 0xbe, 0x03, 0x69,
	0x0d, 0xb7, 0x6c, 0xcc, 0x0e, 0xc6, 0x5d, 0x4a, 0x59, 0x69, 0xaa, 0xa6, 0xbe, 0x87, 0x1d, 0x66,
	0xdb, 0x99, 0x91, 0x53, 0x9d, 0x12, 0xac, 0xe9, 0x4d, 0x9e, 0x8f, 0x54, 0xef, 0x46, 0x85, 0xec,
	0x71, 0x8b, 0xdd, 0xf5, 0xf0, 0x03, 0xf1, 0xd6, 0xc5, 0x6f, 0x89, 0xe4, 0x24, 0xee, 0xb9, 0xcf,
	0x92, 0x61, 0xd6, 0xd7, 0x04, 0xbd, 0x85, 0x8a, 0x51, 0xfa, 0x37, 0x47, 0xbe, 0xf7, 0x90, 0x13,
	0x38, 0x78, 0x77, 0x33, 0x64, 0x6f, 0x4e, 0x7d, 0x13, 0x7b, 0xf3, 0x03, 0x48, 0x34, 0x2c, 0xc3,
	0xc0, 0x4c, 0x47, 0xdb, 0x91, 0x2b, 0xdc, 0x7a, 0x4f, 0x75, 0xd3, 0xa2, 0x97, 0x43, 0x98, 0x33,
	0xde, 0xf0, 0x7f, 0xa2, 0x8f, 0x60, 0xda, 0xe1, 0x9b, 0x95, 0x1c, 0x46, 0x33, 0xf4, 0xe0, 0xb8,
	0x7a, 0x76, 0x9a, 0x01, 0xb1, 0x87, 0x2b, 0xa5, 0xaf, 0x02, 0x5f, 0x32, 0x88, 0x0a, 0x0c, 0x5f,
	0x5e, 0xf5, 0xea, 0xb7, 0x5c, 0x47, 0x69, 0xf0, 0xed, 0x2e, 0xa6, 0x03, 0x86, 0xeb, 0x37, 0x83,
	0x64, 0x45, 0xe1, 0xda, 0xd9, 0x69, 0x66, 0xb0, 0x90, 0x94, 0x97, 0x45, 0xc3, 0xdb, 0xae, 0xd3,
	0x25, 0x3f, 0x6f, 0x82, 0x64, 0xe3, 0x23, 0x9d, 0x5e, 0xdf, 0x1e, 0x30, 0x13, 0x0b, 0x45, 0x58,
	0x51, 0x79, 0x56, 0xa4, 0x73, 0xcb, 0x0b, 0x41, 0x6e, 0x7b, 0x6d, 0xc3, 0x10, 0xd8, 0x9c, 0xa2,
	0x9b, 0xa8, 0x3c, 0x4d, 0xd2, 0x38, 0x8c, 0x46, 0xf7, 0x60, 0xce, 0x69, 0xe1, 0x86, 0xbe, 0xa7,
	0x37, 0x3a, 0x06, 0x69, 0x27, 0x35, 0x47, 0xf7, 0xda, 0xb9, 0x07, 0x37, 0xdb, 0xb9, 0x49, 0x51,
	0x5b, 0x58, 0xa1, 0x09, 0x63, 0x4a, 0x9e, 0x5d, 0xd9, 0x55, 0xed, 0x7d, 0xec, 0x3a, 0xa9, 0x24,
	0xa5, 0xf7, 0x42, 0xd7, 0x54, 0x39, 0x8f, 0x8c, 0x5d, 0xd5, 0xc1, 0xb9, 0x0e, 0x10, 0x11, 0x76,
	0x3b, 0x41, 0xa0, 0xce, 0xea, 0x23, 0x1b, 0x16, 0x3c, 0x9a, 0xc2, 0xe2, 0xa8, 0x68, 0xbb, 0x4e,
	0x0a, 0xd1, 0x53, 0xfd, 0xe3, 0xaf, 0x4e, 0x33, 0x1f, 0x8e, 0xc4, 0x92, 0xbd, 0x37, 0xee, 0xb9,
	0x4a, 0x49, 0x9e, 0x13, 0xc4, 0x85, 0xc5, 0xb2, 0xb4, 0xeb, 0xa0, 0x3a, 0x24, 0x6d, 0xfc, 0xa8,
	0xcd, 0x40, 0xad, 0x18, 0xc8, 0xfc, 0xc5, 0x06, 0x22, 0x79, 0x14, 0xc4, 0x48, 0xd2, 0x10, 0xd5,
	0xb0, 0xab, 0x92, 0xe5, 0x4d, 0x2d, 0xd0, 0xf5, 0xf0, 0xbe, 0xd1, 0x4b, 0x90, 0x50, 0x1d, 0xc5,
	0xda, 0x53, 0x74, 0xd3, 0xc5, 0xf6, 0x91, 0x6a, 0xa4, 0x16, 0x09, 0xcf, 0xca, 0x33, 0xaa, 0xb3,
	0xb5, 0x57, 0xe1, 0x69, 0x84, 0x01, 0xd4, 0x56, 0xc7, 0x9c, 0x43, 0x2f, 0xb4, 0x96, 0x28, 0x1c,
	0x9d, 0xf5, 0xa5, 0xd3, 0xeb, 0xa8, 0x6d, 0x40, 0xf8, 0x31, 0x6e, 0x30, 0xdc, 0x25, 0x64, 0x69,
	0x2a, 0x35, 0x50, 0x2b, 0x13, 0xf2, 0x4f, 0x2c, 0xae, 0x57, 0x59, 0x64, 0xa0, 0x3c, 0x5c, 0xd3,
	0xcd, 0x86, 0xd1, 0xd6, 0xb0, 0xa2, 0x1a, 0xe2, 0x06, 0x49, 0xb5, 0x4f, 0x38, 0xf3, 0x38, 0xa9,
	0x65, 0x3a, 0xa6, 0x34, 0x2f, 0x94, 0x37, 0xf8, 0x65, 0x91, 0x6a, 0x9f, 0x30, 0x0e, 0x71, 0xd0,
	0x5d, 0xc8, 0xb6, 0x5b, 0x04, 0xfb, 0x38, 0x9e, 0xd1, 0xa8, 0x69, 0x99, 0xba, 0x6b, 0xd9, 0x64,
	0x6f, 0x71, 0x93, 0x46, 0x2a, 0x4d, 0xe9, 0x64, 0x78, 0x49, 0xce, 0xae, 0x9b, 0x5e, 0xb9, 0x4d,
	0x56, 0x8c, 0x43, 0xf2, 0x96, 0xda, 0x70, 0x53, 0x57, 0x68, 0x0d, 0xf1, 0x99, 0xfe, 0x03, 0x98,
	0xf6, 0x1d, 0x34, 0x28, 0x01, 0x61, 0xd7, 0xa2, 0x8a, 0x76, 0x4c, 0x0e, 0xbb, 0x16, 0x5a, 0x84,
	0x49, 0xa7, 0xbd, 0xab, 0xe9, 0x36, 0x3d, 0x1c, 0x63, 0x32, 0xff, 0x42, 0xab, 0x30, 0xa7, 0x9b,
	0x0d, 0x1b, 0x37, 0xb1, 0xe9, 0xaa, 0x86, 0x42, 0x36, 0x92, 0xba, 0x8f, 0xa9, 0x49, 0x2f, 0x26,
	0x23, 0x5f, 0x56, 0x8d, 0xe5, 0x10, 0x42, 0xf8, 0xb1, 0xee, 0xb8, 0x0e, 0x3d, 0x14, 0xa2, 0x32,
	0xff, 0x4a, 0x17, 0x61, 0xa1, 0xef, 0x09, 0x34, 0xec, 0xee, 0x37, 0xe6, 0xbb, 0xfb, 0x5d, 0x8f,
	0x44, 0x13, 0xd2, 0xec, 0x7a, 0x24, 0x2a, 0x49, 0xc9, 0xac, 0x04, 0x09, 0x76, 0x3c, 0x08, 0xc5,
	0x2f, 0xfb, 0x8f, 0xc6, 0x21, 0xd9, 0x61, 0x39, 0x19, 0x1f, 0xdb, 0xba, 0x8b, 0x51, 0x1d, 0xc2,
	0xdc, 0x78, 0x10, 0x2f, 0x10, 0xa1, 0x1b, 0xa6, 0x52, 0xee, 0x59, 0xb6, 0x47, 0x58, 0xd7, 0xd0,
	0xbe, 0xdf, 0x4c, 0x12, 0xa6, 0xc4, 0xd7, 0xfd, 0x66, 0x92, 0x67, 0x6c, 0xa2, 0x63, 0x64, 0xf9,
	0x01, 0x48, 0xbc, 0x21, 0x6e, 0x4c, 0xd1, 0x35, 0x0a, 0x49, 0xe3, 0x85, 0xed, 0xb3, 0xd3, 0x4c,
	0x82, 0xb5, 0xc7, 0xec, 0x29, 0xcf, 0xdc, 0x6a, 0xa2, 0xe5, 0xa7, 0xa6, 0x51, 0x73, 0xaf, 0xa5,
	0xd0, 0x05, 0xd4, 0xcd, 0x7d, 0xaa, 0xfb, 0x44, 0x65, 0x70, 0xad, 0x32, 0x4f, 0x41, 0x6f, 0xc2,
	0x34, 0x81, 0x92, 0xda, 0x2e, 0xdb, 0x76, 0xd4, 0x19, 0xa3, 0x10, 0x3f, 0x3b, 0xcd, 0xc4, 0xaa,
	0xf8, 0xb8, 0x54, 0xa0, 0xb7, 0xc2, 0x31, 0x13, 0x1f, 0x97, 0x76, 0xc9, 0x9f, 0xd9, 0xa7, 0x57,
	0x20, 0x21, 0x63, 0xc2, 0x43, 0x58, 0xa8, 0x76, 0x7e, 0xb5, 0x2c, 0x72, 0x09, 0xb5, 0xec, 0x2f,
	0x42, 0x30, 0xe7, 0xb3, 0xf2, 0xd8, 0x6c, 0xd1, 0x99, 0x69, 0xba, 0xd7, 0xc8, 0xd6, 0x75, 0x77,
	0xe7, 0xeb, 0x48, 0xae, 0x87, 0x71, 0x1c, 0xa6, 0x20, 0x7d, 0xfc, 0x87, 0x7f, 0xfd, 0x4c, 0x73,
	0x8a, 0xb4, 0x1e, 0xc2, 0xe8, 0x2a, 0x44, 0x28, 0x58, 0xa7, 0xbb, 0xa8, 0x10, 0x3d, 0x3b, 0xcd,
	0x44, 0x88, 0x0a, 0x26, 0xd3, 0x54, 0xe4, 0xc2, 0x3c, 0xd7, 0xaf, 0x3c, 0x75, 0x8f, 0xaa, 0x33,
	0x53, 0x74, 0x48, 0xdf, 0x19, 0x7d, 0x48, 0x6c, 0x7b, 0x88, 0xfd, 0x46, 0xdd, 0x6a, 0xd8, 0xec,
	0xa1, 0xdd, 0x9e, 0x1c, 0xb4, 0x0d, 0x09, 0x4d, 0x75, 0x55, 0x22, 0xb7, 0xa9, 0xd9, 0xcc, 0x49,
	0x49, 0xb4, 0xbd, 0x9b, 0x83, 0x64, 0x3b, 0x2f, 0xec, 0x9b, 0xb7, 0xb8, 0xe6, 0x4b, 0x73, 0xd0,
	0x1d, 0x71, 0x59, 0xc0, 0xc8, 0x31, 0x7d, 0xf5, 0x95, 0x01, 0xe4, 0x28, 0x06, 0xf5, 0xd1, 0x62,
	0x97, 0x0a, 0x8c, 0x50, 0x09, 0xc0, 0x3d, 0x69, 0x09, 0x3a, 0x09, 0x4a, 0xe7, 0xe5, 0x41, 0x74,
	0x4e, 0x5a, 0x7e, 0x32, 0x31, 0x97, 0x7f, 0x3b, 0x68, 0x1d, 0x66, 0xf8, 0x0e, 0x62, 0x74, 0x66,
	0xfb, 0xde, 0xee, 0x0a, 0x3a, 0x6c, 0x0f, 0xf8, 0x28, 0x4d, 0x3b, 0x5e, 0x8a, 0x43, 0x26, 0xcb,
	0x33, 0x93, 0x31, 0x6a, 0x57, 0xce, 0x9d, 0x2c, 0x61, 0x30, 0xf4, 0x4f, 0xd6, 0x9e, 0x2f, 0x8d,
	0xf4, 0x6e, 0x4a, 0x1c, 0x19, 0x0b, 0x94, 0xd4, 0x6b, 0x3e, 0x52, 0x3e, 0x8f, 0x36, 0xa1, 0x70,
	0x98, 0x7b, 0xd6, 0x03, 0xdd, 0x3d, 0xd8, 0x71, 0xd4, 0x7d, 0x2c, 0xf6, 0x04, 0x27, 0x80, 0x56,
	0x61, 0xda, 0x3a, 0xc2, 0xb6, 0xad, 0x6b, 0x44, 0x29, 0xa0, 0x6a, 0x76, 0xac, 0x90, 0x20, 0x8a,
	0xde, 0x16, 0x4f, 0x2e, 0x15, 0x64, 0x10, 0x45, 0x4a, 0xbb, 0xe8, 0x75, 0x48, 0xb6, 0x6c, 0x4c,
	0x36, 0xbf, 0xa7, 0x4d, 0x68, 0x54, 0xad, 0x8c, 0xca, 0x12, 0xcf, 0x10, 0x9a, 0x80, 0x86, 0x5e,
	0x86, 0x04, 0x01, 0xe9, 0x8e, 0xa2, 0x9b, 0x0e, 0xb6, 0x49, 0x49, 0x66, 0x42, 0x8a, 0xd3, 0xd4,
	0x0a, 0x4f, 0x44, 0x27, 0xb0, 0xe8, 0x9c, 0x38, 0x2e, 0x6e, 0x72, 0x43, 0x93, 0xd2, 0xd4, 0xf7,
	0x6d, 0x02, 0x0d, 0xb8, 0xf2, 0x53, 0x1c, 0x9d, 0x8f, 0x6b, 0x94, 0x0e, 0xb3, 0x4a, 0x6d, 0x72,
	0x2a, 0xcc, 0x05, 0x69, 0xde, 0xe9, 0x93, 0x85, 0xde, 0xa6, 0x2e, 0x35, 0x7c, 0xa2, 0x1d, 0xc5,
	0x33, 0x6d, 0x09, 0xbb, 0x95, 0x2f, 0x73, 0x5b, 0xe4, 0xa1, 0x93, 0x80, 0x1c, 0x69, 0x90, 0xd9,
	0x21, 0x07, 0x1d, 0xf3, 0x05, 0x59, 0xfb, 0xea, 0x34, 0x53, 0x1a, 0x59, 0x08, 0x38, 0xb8, 0xb9,
	0xea, 0xda, 0xd8, 0xaf, 0xff, 0x14, 0x39, 0x3d, 0xbf, 0x38, 0x10, 0x69, 0x48, 0x06, 0xe8, 0x00,
	0x0f, 0x7e, 0xeb, 0x7a, 0x19, 0x54, 0xe4, 0xa3, 0x82, 0xfe, 0x75, 0x08, 0x90, 0xb7, 0x9f, 0x9b,
	0x96, 0xa6, 0xef, 0xe9, 0xd8, 0x16, 0x8a, 0xec, 0xa7, 0x17, 0x10, 0x8b, 0x9c, 0xc6, 0xa6, 0x20,
	0xf1, 0x7c, 0xa4, 0x62, 0x52, 0xeb, 0xa6, 0x8b, 0xde, 0x82, 0x79, 0x9b, 0xb5, 0xad, 0x70, 0xc6,
	0x69, 0x3b, 0xa4, 0xcb, 0x8b, 0xcc, 0x40, 0xc9, 0xf3, 0x18, 0x2f, 0xec, 0x90, 0x1c, 0x54, 0x85,
	0x85, 0x96, 0x8d, 0x85, 0xcc, 0xf7, 0x39, 0x90, 0x2c, 0x0d, 0xb5, 0xb3, 0xc9, 0xa8, 0x65, 0x63,
	0x2e, 0x8f, 0x3d, 0x2f, 0x98, 0x0c, 0xf0, 0x4d, 0xae, 0x58, 0xa6, 0x71, 0xc2, 0x55, 0x37, 0x60,
	0x49, 0x5b, 0xa6, 0x71, 0x82, 0xae, 0x03, 0xdc, 0xc7, 0xb6, 0xbe, 0x77, 0x42, 0x66, 0x85, 0xab,
	0x64, 0xbe, 0x94, 0x61, 0x78, 0xf1, 0xea, 0x37, 0x81, 0x17, 0xdf, 0x82, 0xb9, 0xda, 0xa1, 0x2e,
	0x64, 0xbd, 0x8e, 0x1d, 0x6a, 0x55, 0x4e, 0x5d, 0xa3, 0x9d, 0xef, 0x97, 0x35, 0x40, 0x4b, 0xbe,
	0xfe, 0x0c, 0x5a, 0xf2, 0x2a, 0xcc, 0xe1, 0xc7, 0x2d, 0x6c, 0xeb, 0x5c, 0x8b, 0xb4, 0x4c, 0x43,
	0x37, 0x71, 0x2a, 0xc3, 0x56, 0xd6, 0x9f, 0xb5, 0x45, 0x73, 0x50, 0x09, 0x12, 0x9a, 0x75, 0x6c,
	0x1a, 0x96, 0x2a, 0x7c, 0x71, 0x56, 0x46, 0x31, 0x09, 0xc7, 0x45, 0x25, 0xe6, 0x9c, 0xf1, 0x12,
	0xc4, 0x65, 0xdc, 0xb4, 0x8e, 0xb0, 0x8c, 0xf7, 0xa9, 0xc1, 0xe1, 0x05, 0x26, 0xa8, 0x02, 0x89,
	0x68, 0x13, 0x5e, 0x6c, 0x9b, 0x8e, 0xba, 0x47, 0x18, 0x89, 0xb1, 0x9f, 0x6e, 0x52, 0xa5, 0xd9,
	0xd5, 0xc9, 0xe1, 0xc5, 0xbd, 0x7a, 0x53, 0x59, 0x5a, 0x77, 0x85, 0x15, 0xe5, 0x9b, 0xa4, 0xe2,
	0x2b, 0x78, 0x9f, 0x95, 0x43, 0xff, 0x34, 0x04, 0xaf, 0xb6, 0x2c, 0xc7, 0x55, 0xbc, 0x01, 0xb0,
	0x43, 0x50, 0x6d, 0xbb, 0x96, 0xc2, 0x04, 0xa7, 0x83, 0x5d, 0xa2, 0x3d, 0x39, 0xa9, 0x17, 0xe9,
	0xa0, 0xee, 0x8d, 0xbe, 0x1b, 0xb7, 0x2d, 0xc7, 0x2d, 0x71, 0xba, 0x54, 0xe8, 0xe5, 0xdb, 0xae,
	0x55, 0x23, 0x44, 0x6b, 0x9c, 0x26, 0x93, 0x8b, 0xd9, 0xd6, 0xd0, 0x82, 0x04, 0x0d, 0x7b, 0x5d,
	0xfc, 0xd2, 0xda, 0x4d, 0xbd, 0xc4, 0xd0, 0xb0, 0x48, 0x5b, 0xb7, 0xe8, 0xb9, 0x10, 0x58, 0xb7,
	0x86, 0xd5, 0x3a, 0x49, 0xbd, 0xcc, 0xce, 0x05, 0x7f, 0x46, 0xd1, 0x6a, 0x9d, 0xa4, 0xff, 0x34,
	0x0c, 0xa8, 0x57, 0xe3, 0x40, 0xff, 0x3e, 0x04, 0x57, 0x85, 0xf9, 0xca, 0xb2, 0xf5, 0x7d, 0xdd,
	0x54, 0x8d, 0x80, 0x1d, 0x8b, 0x19, 0xfb, 0x3f, 0x7f, 0x16, 0xb5, 0x86, 0xdb, 0xb6, 0xb6, 0x38,
	0xf9, 0x6e, 0x1b, 0xd7, 0x55, 0xb2, 0x75, 0x98, 0x8d, 0xab, 0xa7, 0xc8, 0x7d, 0x39, 0xd5, 0x1e,
	0x50, 0x39, 0x7d, 0x17, 0xae, 0x9d, 0x4b, 0xf8, 0x22, 0xd0, 0x25, 0xed, 0xc0, 0xd2, 0x00, 0x15,
	0xd3, 0x4f, 0x26, 0xce, 0xc8, 0x14, 0xfc, 0x64, 0xa6, 0x6f, 0xbd, 0x71, 0xce, 0xe4, 0xf4, 0x10,
	0xf5, 0x37, 0x7a, 0x07, 0x96, 0x07, 0x1e, 0x9e, 0xc3, 0x7a, 0x1f, 0xf5, 0x13, 0xfa, 0x0f, 0x21,
	0x90, 0xba, 0x8f, 0x02, 0xb4, 0x05, 0x12, 0x7e, 0xec, 0xda, 0xaa, 0xe2, 0xd3, 0xce, 0x42, 0x17,
	0xd1, 0xce, 0x12, 0xb4, 0x7a, 0xdd, 0x53, 0xd1, 0xbe, 0x0b, 0x71, 0x9b, 0xee, 0x4a, 0xea, 0xc0,
	0xa0, 0xef, 0xf3, 0xe1, 0xbf, 0x37, 0xb2, 0x0a, 0x9a, 0x63, 0x9b, 0xba, 0x48, 0x6b, 0xcb, 0x33,
	0xb6, 0xef, 0x2b, 0xfd, 0xc3, 0x10, 0x2c, 0xf6, 0x3f, 0xcd, 0xfa, 0x2c, 0xc0, 0x76, 0x70, 0x01,
	0x3e, 0xbc, 0xfc, 0x81, 0xe9, 0x9f, 0xc5, 0x1f, 0x85, 0xe0, 0xd5, 0x11, 0xb7, 0x70, 0x9f, 0x3e,
	0x95, 0x82, 0x7d, 0xca, 0x0d, 0x70, 0x20, 0xa0, 0x6f, 0x22, 0x72, 0x3d, 0x54, 0x83, 0x30, 0x9a,
	0xdd, 0xd1, 0xc5, 0xa5, 0xc4, 0x7a, 0x24, 0x8a, 0xa4, 0xb9, 0xf5, 0x48, 0x34, 0x25, 0x2d, 0x67,
	0x7f, 0x11, 0x86, 0x59, 0x3e, 0x1c, 0xef, 0xae, 0xe7, 0x1a, 0xc0, 0x81, 0xbe, 0x7f, 0xa0, 0x1c,
	0xab, 0x2e, 0xb6, 0xf9, 0x73, 0x81, 0x18, 0x49, 0x79, 0x40, 0x12, 0xd0, 0xf7, 0x02, 0x57, 0x9c,
	0x0c, 0x75, 0x7d, 0x30, 0x7c, 0xb6, 0xbc, 0xcb, 0x9a, 0xdb, 0xb6, 0x65, 0xba, 0x3a, 0xb6, 0xd9,
	0x4e, 0xed, 0xbd, 0xe6, 0x7c, 0x0f, 0x96, 0x5c, 0x8b, 0xc8, 0x1e, 0x4f, 0x56, 0x79, 0xae, 0x72,
	0x04, 0x8e, 0x46, 0xe4, 0x05, 0x9a, 0x2d, 0x66, 0x54, 0xb8, 0xca, 0x91, 0xa9, 0x8e, 0x07, 0x68,
	0x7b, 0xbe, 0xd9, 0xa1, 0xd1, 0x7d, 0xb3, 0xf3, 0x10, 0xf3, 0x0e, 0xf1, 0x8b, 0x5c, 0x1a, 0x74,
	0x6a, 0x65, 0x7f, 0x3d, 0x05, 0xf1, 0x4a, 0xb3, 0x65, 0xd9, 0xae, 0x40, 0xbc, 0x1b, 0x30, 0xc9,
	0xaf, 0x5e, 0xd9, 0x5e, 0xc9, 0x9d, 0x33, 0x5b, 0x81, 0x9a, 0x0c, 0x23, 0xf1, 0x26, 0x38, 0x0d,
	0x54, 0x81, 0x09, 0xb2, 0xfb, 0x9c, 0x54, 0x9a, 0x12, 0x7b, 0x73, 0x74, 0x62, 0x27, 0x2d, 0x41,
	0x8b, 0x51, 0xf0, 0x50, 0x69, 0xb8, 0x2f, 0x2a, 0xfd, 0x08, 0x26, 0xd9, 0x6b, 0x1d, 0x7e, 0x8b,
	0x99, 0xe9, 0x33, 0x81, 0x95, 0xad, 0xdb, 0xba, 0x81, 0x6f, 0xd3, 0x62, 0xa2, 0x9f, 0xac, 0x12,
	0x4a, 0x43, 0xf4, 0x58, 0x35, 0x0c, 0xef, 0x46, 0x7d, 0x5c, 0xf6, 0xbe, 0x83, 0xb6, 0x94, 0xc9,
	0xaf, 0xd1, 0x96, 0x72, 0x13, 0xa4, 0x6e, 0x9c, 0xc3, 0xdd, 0x77, 0x66, 0xbb, 0x60, 0x0e, 0x29,
	0xca, 0x71, 0x4b, 0x07, 0x3e, 0x70, 0xb3, 0x32, 0x4b, 0xef, 0x20, 0x87, 0xdf, 0x87, 0x25, 0x4f,
	0xd3, 0x6e, 0xd9, 0x7a, 0x53, 0xb5, 0x4f, 0x14, 0x26, 0x79, 0xa8, 0x0d, 0x2e, 0x56, 0x28, 0x7f,
	0x75, 0x9a, 0xc9, 0x5f, 0x78, 0x00, 0x6c, 0x1f, 0x33, 0x81, 0x46, 0x0d, 0x29, 0x0b, 0xa2, 0x95,
	0x6d, 0xd6, 0x08, 0xcb, 0x4a, 0xff, 0x24, 0x0c, 0x13, 0xcc, 0xed, 0xe8, 0x43, 0x88, 0x90, 0x51,
	0x73, 0x0e, 0x1f, 0x15, 0x69, 0xd3, 0x3a, 0x08, 0x41, 0x84, 0x9a, 0x70, 0x10, 0x3d, 0x0d, 0xe8,
	0xdf, 0x68, 0x09, 0xa6, 0x1c, 0xfc, 0x48, 0x39, 0x52, 0x8d, 0xd4, 0x1c, 0x5d, 0xb2, 0x49, 0x07,
	0x3f, 0xba, 0xaf, 0x1a, 0xe8, 0x0a, 0xc4, 0x8e, 0x55, 0x47, 0xc1, 0xcd, 0x96, 0x7b, 0xc2, 0xf5,
	0xf3, 0xe8, 0xb1, 0xea, 0x94, 0xc9, 0x37, 0xf3, 0x11, 0xb4, 0xf7, 0xb1, 0xab, 0x34, 0x2c, 0x83,
	0xa1, 0x59, 0xea, 0x23, 0x48, 0x92, 0x8a, 0x96, 0xe1, 0xf4, 0xf5, 0x0d, 0xf0, 0x7c, 0xb4, 0x99,
	0x9f, 0x00, 0x73, 0xd6, 0xf0, 0x3c, 0xb8, 0x41, 0x9a, 0x5e, 0x8f, 0x44, 0xa7, 0xa5, 0x99, 0xf5,
	0x48, 0x74, 0x46, 0x8a, 0x7b, 0x92, 0x8b, 0x19, 0x03, 0x67, 0x25, 0x89, 0x99, 0x04, 0xd7, 0x23,
	0xd1, 0xa4, 0x84, 0xd6, 0x23, 0xd1, 0x79, 0x69, 0x21, 0x9d, 0x87, 0x08, 0xf5, 0x68, 0xf9, 0x76,
	0x60, 0x52, 0x46, 0x3c, 0x98, 0x68, 0x15, 0xbf, 0xe3, 0xc2, 0x39, 0x1d, 0x62, 0x9d, 0x58, 0x94,
	0x96, 0xd6, 0x23, 0xd1, 0x25, 0x29, 0xc5, 0x44, 0xe9, 0x7a, 0x24, 0xba, 0x2c, 0xa5, 0xb3, 0x7f,
	0x11, 0x02, 0xa9, 0x86, 0x1f, 0xb5, 0xb1, 0xd9, 0xc0, 0xf7, 0x55, 0xa3, 0x78, 0xd0, 0x36, 0x0f,
	0xd1, 0x2b, 0x30, 0xdb, 0x20, 0x7f, 0x70, 0xcf, 0x43, 0x32, 0xbd, 0x21, 0x3a, 0xbd, 0x71, 0x9a,
	0x4c, 0xbd, 0x09, 0xc9, 0x2c, 0x5f, 0x23, 0xa2, 0x95, 0x96, 0xd3, 0x7f, 0xc0, 0x84, 0xfe, 0xb8,
	0x1c, 0x63, 0x45, 0xf4, 0x1f, 0xe0, 0x6e, 0x32, 0xb6, 0x75, 0x4c, 0x77, 0x66, 0x80, 0x8c, 0x6c,
	0x1d, 0xa3, 0x55, 0x98, 0x37, 0xf1, 0x63, 0x57, 0xe9, 0x2e, 0x4c, 0x1d, 0x07, 0xe4, 0x24, 0xc9,
	0x2b, 0xfa, 0x2b, 0x64, 0xff, 0x6b, 0x18, 0x66, 0x45, 0xa7, 0x85, 0xd0, 0xda, 0x03, 0x89, 0xb0,
	0x82, 0xae, 0x29, 0xae, 0xc5, 0x28, 0x09, 0xf1, 0xf5, 0xd1, 0x79, 0xf7, 0x3d, 0x41, 0x2a, 0xe4,
	0xbb, 0xa2, 0xd5, 0x2d, 0xda, 0x1c, 0xd7, 0x54, 0xe3, 0x8e, 0x3f, 0x2d, 0xbd, 0x03, 0x09, 0x51,
	0x89, 0xa5, 0xa0, 0x22, 0x4c, 0x06, 0xda, 0x7b, 0x7d, 0x84, 0xf6, 0xc4, 0x54, 0xcb, 0xbc, 0x6a,
	0xfa, 0xf7, 0x00, 0xf5, 0xb6, 0xed, 0x3f, 0x62, 0x27, 0xd8, 0x11, 0xbb, 0x15, 0x3c, 0x62, 0xbf,
	0x7d, 0xb1, 0xb1, 0xf9, 0xba, 0xed, 0x7f, 0xb0, 0xf4, 0xa3, 0x71, 0x48, 0x30, 0xd9, 0xeb, 0x1d,
	0xaa, 0xaf, 0x43, 0xd2, 0x51, 0x9b, 0x2d, 0x43, 0x37, 0xf7, 0x95, 0x16, 0x4f, 0xa4, 0xe3, 0x0b,
	0xcb, 0x92, 0xc8, 0xf0, 0x0a, 0xbf, 0x48, 0xb4, 0x22, 0x55, 0xeb, 0x14, 0x0c, 0xd3, 0x82, 0xf4,
	0xb1, 0x83, 0x57, 0xe8, 0x65, 0x48, 0x30, 0x14, 0xec, 0x95, 0x1a, 0xa7, 0xa5, 0xe2, 0x34, 0xd5,
	0x2b, 0x56, 0x80, 0x38, 0x39, 0xd9, 0x3a, 0xa5, 0x22, 0xa3, 0xe0, 0xaa, 0x19, 0x52, 0xc7, 0xaf,
	0x11, 0xd8, 0xd8, 0x69, 0x37, 0xb1, 0xd2, 0xb2, 0x98, 0x59, 0x6f, 0x5c, 0x8e, 0xb1, 0x94, 0x6d,
	0xcb, 0x41, 0x3b, 0x94, 0x55, 0xe8, 0x5c, 0x28, 0x1a, 0x9b, 0x9c, 0xd4, 0x64, 0x8f, 0x49, 0x6b,
	0xc8, 0x74, 0xca, 0xb3, 0x4e, 0x17, 0x07, 0x7e, 0x0a, 0x53, 0x4e, 0xbb, 0x49, 0xe4, 0x1e, 0xf7,
	0x64, 0x5d, 0xe9, 0xd3, 0xe7, 0x42, 0xdb, 0x38, 0xdc, 0x6a, 0xd5, 0x58, 0x39, 0x61, 0x16, 0xe3,
	0xd5, 0xb2, 0xff, 0x26, 0x04, 0x4b, 0x64, 0x9f, 0x0b, 0xe7, 0x43, 0xd5, 0xdc, 0xf7, 0xa8, 0xab,
	0x30, 0x45, 0x95, 0x58, 0xef, 0xa6, 0x60, 0xed, 0xec, 0x34, 0x33, 0x49, 0x4a, 0x3f, 0xf3, 0xf1,
	0x33, 0x49, 0x08, 0x57, 0xa8, 0x55, 0xca, 0xb5, 0x55, 0xd3, 0xa1, 0x6e, 0x59, 0xec, 0x6a, 0xa7,
	0xb9, 0x8b, 0x6d, 0xb6, 0x9c, 0x33, 0xf2, 0x7c, 0x20, 0x73, 0x93, 0xe5, 0x65, 0xd3, 0x90, 0xea,
	0xee, 0xb2, 0x77, 0xdd, 0xf1, 0xeb, 0x30, 0x2c, 0x56, 0xf1, 0x71, 0xbf, 0xe1, 0x7c, 0x0f, 0x92,
	0xbb, 0x6a, 0xe3, 0x70, 0x4f, 0x37, 0x8c, 0xee, 0xa5, 0x7e, 0x7d, 0x88, 0x61, 0x89, 0xd4, 0x11,
	0x4d, 0x88, 0x5b, 0xbb, 0xdd, 0xae, 0x74, 0xb4, 0x03, 0x89, 0x26, 0xb6, 0xf7, 0x7d, 0xdc, 0xc6,
	0x56, 0xf8, 0xc6, 0x39, 0xc4, 0x37, 0x49, 0x85, 0x2e, 0xca, 0xf1, 0xa6, 0x3f, 0xf1, 0xff, 0xc5,
	0xfb, 0xf6, 0xbe, 0xfe, 0x6c, 0x13, 0xd2, 0x64, 0xf6, 0x37, 0xe3, 0x20, 0x75, 0xcf, 0x17, 0x7a,
	0xe8, 0xbb, 0x6b, 0xaa, 0x9c, 0x9d, 0x66, 0xa6, 0xb8, 0x6b, 0xd5, 0x73, 0xb8, 0x70, 0xfa, 0xff,
	0x80, 0x7b, 0x7c, 0x2b, 0xba, 0xa9, 0xe1, 0xc7, 0x9d, 0x6b, 0xa7, 0xfa, 0xd9, 0x69, 0x26, 0xce,
	0xbc, 0xc3, 0x2b, 0x24, 0x87, 0xb6, 0xf6, 0xc9, 0xa5, 0x5b, 0x63, 0x24, 0xe4, 0xb8, 0xe3, 0xa3,
	0xa8, 0xa1, 0x13, 0x48, 0x68, 0xd8, 0x71, 0xbd, 0xb6, 0x99, 0x78, 0x89, 0x17, 0x6a, 0x67, 0xa7,
	0x99, 0x99, 0x12, 0x76, 0x5c, 0x5e, 0xcf, 0x79, 0x1e, 0x6d, 0xcf, 0x68, 0x1e, 0x41, 0x8d, 0xba,
	0x64, 0x72, 0xfb, 0x9e, 0xa7, 0x8a, 0x5f, 0xe0, 0xa2, 0x88, 0x49, 0x45, 0x2f, 0x15, 0xdd, 0x86,
	0x59, 0xcf, 0xc4, 0xcd, 0x4d, 0x4b, 0x13, 0xa3, 0x88, 0xc0, 0x84, 0x57, 0x8b, 0xbd, 0xeb, 0xfa,
	0x71, 0x04, 0xe2, 0x01, 0x8e, 0xfe, 0x3a, 0xd7, 0xfe, 0x21, 0x4c, 0xf3, 0xed, 0x46, 0xdf, 0x53,
	0x30, 0x94, 0x75, 0x6b, 0xd4, 0xbd, 0xc6, 0xbf, 0x3a, 0xaf, 0x27, 0xa0, 0x29, 0x12, 0x9c, 0xf4,
	0x5f, 0x86, 0x21, 0xe6, 0xe5, 0x7f, 0xc3, 0x4c, 0x76, 0x04, 0xf1, 0x00, 0x93, 0x51, 0x7d, 0x26,
	0x5e, 0x90, 0xcf, 0x4e, 0x33, 0xd3, 0x3e, 0x1e, 0x7b, 0x1e, 0x2d, 0x4f, 0xfb, 0x58, 0xac, 0x1f,
	0x4f, 0x44, 0x2e, 0xc3, 0x13, 0x19, 0x58, 0xea, 0x92, 0xc7, 0x62, 0x09, 0x98, 0x14, 0xc9, 0xbe,
	0x0c, 0x2f, 0x52, 0x5c, 0xde, 0x52, 0x85, 0x89, 0x02, 0x37, 0x2c, 0xb3, 0xa1, 0x1b, 0xba, 0xdf,
	0x0f, 0x36, 0x7b, 0x08, 0x2f, 0x9d, 0x57, 0xcc, 0xe3, 0xb8, 0x62, 0x00, 0x7b, 0x5f, 0xc0, 0x2d,
	0xce, 0x57, 0x2d, 0xbb, 0x08, 0xf3, 0x77, 0xf1, 0xc9, 0x7d, 0xdd, 0x69, 0xab, 0x86, 0xfe, 0x03,
	0x6c, 0x8b, 0x4e, 0x2c, 0xc1, 0x42, 0x20, 0xdd, 0x3b, 0x76, 0x64, 0x7a, 0x87, 0xdb, 0x6e, 0x62,
	0xd2, 0xbf, 0x0d, 0xdd, 0x71, 0xd1, 0xa7, 0x30, 0xc3, 0x15, 0x82, 0x0b, 0xb8, 0xef, 0x4e, 0xdb,
	0x1e, 0x11, 0x27, 0xfb, 0x6f, 0x43, 0x30, 0x57, 0xb2, 0xad, 0x56, 0x0b, 0x6b, 0x1c, 0x9e, 0xb0,
	0x73, 0x4c, 0xa0, 0x92, 0x90, 0x0f, 0x95, 0x54, 0x21, 0x5c, 0x29, 0x71, 0xb6, 0x7c, 0x56, 0x47,
	0x97, 0x70, 0xa5, 0x84, 0xbe, 0x0d, 0x93, 0xdc, 0xe9, 0x74, 0x9c, 0x3a, 0x3b, 0xbe, 0x70, 0xae,
	0xd3, 0x29, 0xf5, 0x25, 0xe5, 0x15, 0xb2, 0xbf, 0x99, 0x80, 0x05, 0xff, 0x72, 0xdf, 0x29, 0x8a,
	0x8e, 0x7f, 0x01, 0x53, 0x94, 0x8b, 0xf1, 0x48, 0x6a, 0x72, 0x3f, 0x12, 0x39, 0x3e, 0x1f, 0x94,
	0x49, 0x85, 0x2a, 0xc3, 0x69, 0xa2, 0xcf, 0x3c, 0x1b, 0x02, 0x93, 0x05, 0x1f, 0x5e, 0x9a, 0x7a,
	0xa9, 0xcb, 0x9e, 0x10, 0xc0, 0xe2, 0x14, 0x4f, 0x7c, 0x4d, 0x58, 0xfc, 0x3e, 0x4c, 0xb2, 0x0b,
	0x1b, 0xee, 0x06, 0xf8, 0xf1, 0x65, 0x87, 0xc0, 0xae, 0x6f, 0x64, 0x4e, 0x2d, 0xfd, 0xf7, 0x43,
	0x30, 0xe3, 0x9f, 0x3a, 0xa4, 0x43, 0xd4, 0x13, 0x28, 0x14, 0x67, 0x15, 0xaa, 0x44, 0x3a, 0x3f,
	0x47, 0x61, 0xc2, 0x96, 0xa5, 0xa2, 0x11, 0x5c, 0xac, 0xd9, 0x56, 0xab, 0xe3, 0x64, 0x3a, 0x2e,
	0x47, 0x49, 0x02, 0xd9, 0x7f, 0xe9, 0x3f, 0x80, 0x98, 0x37, 0xe9, 0x3e, 0xa7, 0x94, 0xf1, 0xe7,
	0xe8, 0x94, 0x72, 0x6e, 0xfb, 0x25, 0x88, 0x07, 0x66, 0x0c, 0x2d, 0x7a, 0x7d, 0x88, 0x14, 0x26,
	0x59, 0x1f, 0x86, 0x52, 0xf1, 0x03, 0xf6, 0xec, 0xaf, 0x63, 0x30, 0xd7, 0x4f, 0xfb, 0x7c, 0x48,
	0x3d, 0xde, 0x84, 0x3c, 0x50, 0x0c, 0xdd, 0x11, 0x96, 0xc1, 0x9b, 0xe7, 0x5b, 0x06, 0x7d, 0x42,
	0xa5, 0xf3, 0xa2, 0x22, 0x20, 0x6a, 0xbe, 0x0b, 0x09, 0x8d, 0x0d, 0x42, 0xbc, 0x5f, 0x18, 0x1f,
	0x6a, 0x44, 0xeb, 0x23, 0x58, 0xbc, 0xfb, 0x22, 0x5f, 0x96, 0x83, 0x1a, 0x10, 0xf7, 0x88, 0x53,
	0x9b, 0x5a, 0xf4, 0xb9, 0x78, 0xd3, 0xcd, 0x88, 0x56, 0xa8, 0x95, 0x6d, 0x1f, 0x66, 0x45, 0x23,
	0xec, 0x66, 0xd1, 0x49, 0xc5, 0x9e, 0x4b, 0x33, 0x62, 0x62, 0xd8, 0x8a, 0x38, 0xd4, 0x6f, 0x58,
	0xb4, 0xe4, 0xd9, 0xa7, 0xf8, 0xe3, 0x48, 0xa6, 0xb8, 0x25, 0xf9, 0xcc, 0x08, 0x93, 0xf5, 0x33,
	0xf3, 0x60, 0x52, 0xeb, 0x22, 0xa8, 0xa1, 0x43, 0x10, 0x89, 0x8a, 0x70, 0x78, 0x70, 0x52, 0x33,
	0xcf, 0x65, 0xc0, 0x12, 0x27, 0x2c, 0x9c, 0x2b, 0x28, 0x8a, 0x23, 0xd9, 0x1d, 0x17, 0x29, 0x8a,
	0xe2, 0x4a, 0xd8, 0x69, 0x3c, 0x3b, 0x8a, 0x23, 0x7f, 0x56, 0x34, 0xf4, 0xa3, 0x10, 0x24, 0xd9,
	0x85, 0x5e, 0xb3, 0xed, 0xaa, 0xe2, 0x9d, 0x14, 0x33, 0x5a, 0x3e, 0x3c, 0x3b, 0xcd, 0xcc, 0x52,
	0x5e, 0xda, 0xe4, 0x79, 0xb4, 0xd9, 0xc2, 0x65, 0x9b, 0xed, 0x50, 0xe1, 0x46, 0x47, 0x2f, 0x41,
	0x43, 0x77, 0x21, 0xc1, 0x2c, 0xab, 0xde, 0x05, 0xe5, 0x14, 0xed, 0xc3, 0x4b, 0x5f, 0x9d, 0x66,
	0x56, 0xfa, 0x6c, 0x4a, 0x66, 0x94, 0xe5, 0x97, 0x94, 0x72, 0x7c, 0xcf, 0xff, 0xd9, 0x4f, 0xc5,
	0x86, 0xcb, 0xab, 0xd8, 0x43, 0x50, 0xdc, 0xf4, 0x37, 0x71, 0x0b, 0x7e, 0x17, 0x66, 0xfc, 0x31,
	0x9e, 0xf8, 0x1b, 0xcc, 0x6e, 0xb8, 0x1a, 0x08, 0x0a, 0x95, 0xab, 0xb1, 0x2f, 0xc2, 0xcc, 0xf2,
	0xb4, 0xd3, 0xf9, 0xe0, 0xca, 0xdc, 0x22, 0xcc, 0xf7, 0x85, 0xe5, 0x3f, 0x9d, 0x82, 0xc5, 0xe0,
	0x81, 0xe5, 0x29, 0x6c, 0x4a, 0xb7, 0x56, 0xf0, 0xc9, 0xc8, 0x87, 0x9e, 0xa7, 0xcc, 0xd3, 0x43,
	0xa7, 0x0b, 0x46, 0x7b, 0x7a, 0xc1, 0x17, 0x5d, 0x7a, 0xc1, 0x25, 0xe8, 0x53, 0xfe, 0xed, 0xa2,
	0x2f, 0x94, 0x83, 0xcf, 0xbc, 0x33, 0x9b, 0xdd, 0x01, 0x7c, 0x7a, 0x09, 0xf2, 0xb4, 0xbe, 0xf8,
	0x14, 0xa7, 0x36, 0xca, 0xc1, 0x9c, 0x4d, 0x4a, 0x3a, 0x4a, 0xdb, 0x64, 0x81, 0x14, 0x34, 0xcb,
	0xc4, 0xdc, 0x85, 0x34, 0xc9, 0xb2, 0x76, 0x58, 0x4e, 0xc9, 0x32, 0x71, 0xfa, 0xbf, 0x84, 0x20,
	0x1e, 0x98, 0x89, 0xdf, 0xe6, 0x31, 0xbf, 0xed, 0x69, 0x8c, 0xec, 0x79, 0xcc, 0x07, 0x17, 0x9f,
	0x86, 0xa0, 0x22, 0x99, 0xfe, 0x77, 0x21, 0x88, 0x07, 0x26, 0xfe, 0x6b, 0x52, 0x10, 0x9e, 0x7f,
	0xcf, 0x77, 0x21, 0x11, 0x5c, 0x52, 0x5f, 0x1b, 0xa1, 0xe7, 0xd3, 0x46, 0xb6, 0x06, 0x93, 0xfc,
	0x51, 0xd6, 0x02, 0x24, 0x1f, 0xe4, 0x2b, 0xf5, 0x4a, 0xf5, 0x8e, 0x72, 0x7b, 0x4b, 0x56, 0x8a,
	0x1b, 0xe5, 0xbc, 0x2c, 0x8d, 0xa1, 0x19, 0x88, 0xd2, 0x3f, 0x2b, 0xd5, 0x3b, 0x52, 0x08, 0x4d,
	0xc3, 0x14, 0xfd, 0x2a, 0x97, 0xa4, 0x30, 0x5a, 0x82, 0x39, 0x7f, 0x8d, 0xcd, 0xfb, 0xc5, 0xa2,
	0x72, 0xa7, 0x28, 0x8d, 0x67, 0xef, 0xc0, 0x02, 0x6b, 0x77, 0x0f, 0x0b, 0x6f, 0x74, 0x76, 0x8b,
	0x92, 0x83, 0x39, 0xd2, 0x2e, 0x75, 0x6b, 0x66, 0x21, 0x31, 0x7c, 0x10, 0x24, 0xe9, 0x65, 0x11,
	0x09, 0x43, 0x9d, 0x5a, 0x7f, 0x3c, 0x0e, 0xd7, 0xba, 0x29, 0xd5, 0xf8, 0x2b, 0x00, 0xe6, 0x6b,
	0xfd, 0x00, 0x22, 0xbe, 0x47, 0xbe, 0xe7, 0x39, 0xbe, 0x9d, 0x4b, 0x27, 0xc7, 0x7b, 0x79, 0xd2,
	0xc2, 0x32, 0x25, 0x88, 0x9a, 0x14, 0x30, 0x77, 0xbd, 0x70, 0x7e, 0x9e, 0xa7, 0xde, 0x8c, 0xe6,
	0x7f, 0x13, 0x9d, 0x81, 0xe9, 0x3d, 0xb5, 0xa9, 0x1b, 0x27, 0x6c, 0x46, 0xe8, 0x53, 0x28, 0x19,
	0x58, 0x12, 0xf5, 0xaf, 0x1f, 0x30, 0x75, 0x91, 0x41, 0x53, 0xf7, 0x00, 0xa0, 0x33, 0x26, 0xb2,
	0x54, 0xdb, 0x72, 0x65, 0x33, 0x2f, 0x3f, 0x54, 0x6e, 0xe7, 0x37, 0x2b, 0x1b, 0x0f, 0x95, 0xad,
	0xea, 0xc6, 0x43, 0x69, 0x0c, 0xcd, 0xc2, 0x74, 0x39, 0x5f, 0x5c, 0xe3, 0xa9, 0x52, 0x08, 0x25,
	0x21, 0x5e, 0xdc, 0xda, 0xd8, 0xd9, 0xac, 0x8a, 0xa4, 0x30, 0x61, 0x81, 0x52, 0xbe, 0x9e, 0x2f,
	0xe4, 0x6b, 0x65, 0x69, 0x3c, 0xfb, 0xcb, 0x49, 0x48, 0x76, 0xe6, 0x52, 0xe8, 0xa5, 0xff, 0x3c,
	0xe4, 0x89, 0xc7, 0xc9, 0xa1, 0x17, 0xd5, 0x3d, 0xd5, 0x99, 0x64, 0xe4, 0xfe, 0x6f, 0x0f, 0x88,
	0x5c, 0xfc, 0xea, 0x34, 0x93, 0xec, 0x5e, 0x31, 0xe7, 0x19, 0x1d, 0xe3, 0x84, 0xa8, 0x7d, 0x05,
	0xa2, 0x8e, 0x6e, 0x1e, 0x2a, 0x9d, 0x37, 0x67, 0x34, 0x22, 0x5e, 0x4d, 0x37, 0x0f, 0x77, 0xe4,
	0x8a, 0x3c, 0x45, 0x32, 0x77, 0x6c, 0x1d, 0xad, 0x43, 0xc4, 0x6a, 0xb9, 0xc2, 0x60, 0xf1, 0xde,
	0x85, 0x06, 0xb4, 0xd5, 0x72, 0xf9, 0x2d, 0x0c, 0xa5, 0x81, 0xd6, 0x99, 0x67, 0x67, 0x67, 0xf9,
	0x2e, 0x12, 0x46, 0x28, 0x1e, 0x58, 0xde, 0x80, 0x5f, 0x77, 0xec, 0x12, 0x7e, 0xdd, 0x0e, 0x2c,
	0xf0, 0x5b, 0x44, 0xc7, 0xbf, 0x07, 0x44, 0xb4, 0x9e, 0x0f, 0x2e, 0xbb, 0x89, 0x44, 0xf8, 0x0e,
	0xb7, 0x37, 0xcb, 0xa1, 0x8f, 0x20, 0xb0, 0x81, 0x1b, 0x2e, 0x0f, 0x28, 0xc1, 0xbf, 0x7a, 0xb4,
	0x87, 0xe9, 0x67, 0xd0, 0x1e, 0xd2, 0x87, 0x30, 0xed, 0xe3, 0xa4, 0x3e, 0x7e, 0x1e, 0xb7, 0x83,
	0x97, 0x50, 0x6f, 0x5d, 0x60, 0xa8, 0x94, 0xb0, 0xdf, 0xe3, 0xe4, 0x7d, 0x88, 0x79, 0xab, 0x7c,
	0xc1, 0x97, 0x16, 0x7e, 0xb3, 0xf7, 0x84, 0x34, 0x29, 0x4f, 0xf1, 0x37, 0x3f, 0xd9, 0x9f, 0x86,
	0x61, 0xc6, 0x1f, 0xf8, 0xea, 0x9b, 0xf1, 0xac, 0x40, 0x0f, 0x21, 0xbe, 0x6b, 0xb5, 0xf9, 0x6b,
	0x1b, 0x22, 0x5e, 0x23, 0x54, 0xbc, 0xbe, 0x33, 0x62, 0xb8, 0xae, 0x5c, 0x81, 0x57, 0xa6, 0xf2,
	0x74, 0x66, 0xd7, 0xf7, 0x95, 0xfd, 0x08, 0x66, 0xfc, 0xb9, 0x28, 0x0a, 0x91, 0xea, 0x56, 0xb5,
	0xcc, 0x4e, 0x9a, 0x42, 0xbe, 0x78, 0xf7, 0x76, 0x65, 0x63, 0x43, 0x0a, 0x91, 0xf4, 0xf2, 0x67,
	0x95, 0xba, 0x14, 0x66, 0x0f, 0x58, 0x6b, 0xf5, 0xbc, 0x5c, 0xf7, 0xa2, 0x1d, 0x9d, 0x85, 0x20,
	0xee, 0x6f, 0xd0, 0xf9, 0x7a, 0x22, 0x8c, 0xa1, 0x75, 0x98, 0xa0, 0x6e, 0x85, 0x03, 0xdc, 0x82,
	0x06, 0x11, 0x63, 0xa7, 0xac, 0xe3, 0x3d, 0xa6, 0x27, 0x1f, 0xe9, 0x55, 0x98, 0xa0, 0xa9, 0xe8,
	0x15, 0x98, 0xb5, 0x71, 0x83, 0xc8, 0x81, 0xc3, 0x23, 0xa5, 0x61, 0xb5, 0xb9, 0x7d, 0x31, 0x42,
	0x1a, 0x27, 0xc9, 0x77, 0x8f, 0x8a, 0x24, 0x31, 0xfb, 0x37, 0x21, 0x48, 0x7a, 0x6b, 0x44, 0xc9,
	0x6e, 0xaa, 0x2d, 0x24, 0xc3, 0x14, 0x36, 0x5d, 0x5b, 0xf7, 0xf4, 0xdc, 0xf3, 0x6c, 0xd5, 0x3d,
	0xd5, 0x73, 0x7e, 0x5f, 0x20, 0x41, 0x28, 0xfd, 0xff, 0xc3, 0x04, 0xe3, 0xe2, 0x00, 0xeb, 0x84,
	0x2e, 0xc5, 0x3a, 0x5e, 0xa0, 0x81, 0xf0, 0xe8, 0x81, 0x06, 0xb2, 0x7f, 0x16, 0x06, 0xd4, 0xd9,
	0x6f, 0x9e, 0xba, 0xf3, 0xf7, 0xce, 0x47, 0x3b, 0xe3, 0x14, 0xed, 0x3c, 0x78, 0xb6, 0xe0, 0x03,
	0x97, 0x41, 0x3c, 0xdf, 0x87, 0x05, 0x66, 0x7d, 0xc1, 0x47, 0xd8, 0x50, 0x7c, 0x76, 0xe2, 0x89,
	0xa1, 0x2e, 0x85, 0x3d, 0x2b, 0x22, 0xcf, 0x11, 0x52, 0x1b, 0x84, 0x52, 0x27, 0x26, 0x45, 0x97,
	0x88, 0x88, 0x48, 0x13, 0xd9, 0x9f, 0x4d, 0x01, 0x2a, 0xd2, 0x38, 0x38, 0x94, 0x8b, 0xce, 0xb3,
	0xe2, 0x16, 0x60, 0x82, 0x85, 0xcf, 0x09, 0x5f, 0xc4, 0x59, 0xc5, 0x73, 0x58, 0xa2, 0x9a, 0xda,
	0xf7, 0x60, 0xa6, 0x61, 0x19, 0xed, 0x26, 0x8b, 0x1a, 0x20, 0x4c, 0x41, 0xef, 0x9e, 0x27, 0x2f,
	0x7b, 0x3a, 0x97, 0x2b, 0x5a, 0x06, 0xf9, 0xf6, 0xe2, 0xea, 0x51, 0x82, 0x6c, 0x13, 0x5c, 0x85,
	0x98, 0x77, 0xa8, 0x71, 0x25, 0xa6, 0x93, 0x80, 0x6e, 0xc1, 0x04, 0x7d, 0x9d, 0x38, 0x52, 0x80,
	0x10, 0x39, 0xa2, 0x3a, 0x5b, 0x7b, 0xe8, 0x35, 0x48, 0x36, 0xd5, 0xc7, 0xca, 0x9e, 0xad, 0x8a,
	0x10, 0x2b, 0x06, 0x3b, 0x64, 0x43, 0xf2, 0x6c, 0x53, 0x7d, 0x7c, 0x9b, 0xa7, 0x57, 0x34, 0x03,
	0xa3, 0xb7, 0x21, 0xbe, 0xf7, 0x48, 0xe9, 0x84, 0xdb, 0xe2, 0xef, 0x38, 0x66, 0xcf, 0x4e, 0x33,
	0xd3, 0xb7, 0xef, 0xd5, 0x45, 0xcc, 0x2d, 0x79, 0x7a, 0xef, 0x91, 0xf7, 0x81, 0xde, 0x00, 0xa4,
	0xd1, 0x88, 0x27, 0x8a, 0xe5, 0x1e, 0x60, 0x9b, 0x4f, 0x0c, 0x7f, 0xca, 0xc1, 0x72, 0xb6, 0x48,
	0x06, 0x1b, 0xe0, 0xcb, 0x90, 0x68, 0x3b, 0xba, 0xb9, 0xaf, 0xe0, 0xc7, 0xae, 0x8d, 0x9b, 0x5e,
	0x34, 0x90, 0x38, 0x4d, 0x2d, 0xf3, 0x44, 0xf4, 0x02, 0xcc, 0x1c, 0x1f, 0x60, 0x1b, 0x2b, 0x0d,
	0x43, 0x6d, 0x3b, 0x98, 0x1f, 0x8e, 0xd3, 0x34, 0xad, 0x48, 0x93, 0xd0, 0xc7, 0xc0, 0x3e, 0xb9,
	0x5c, 0x9b, 0x1e, 0x65, 0x5f, 0x01, 0xad, 0xc1, 0x84, 0xd8, 0x09, 0x24, 0x58, 0x7d, 0x0f, 0xc3,
	0xb1, 0xe7, 0xc9, 0xf4, 0x7e, 0xf1, 0x01, 0xc9, 0x79, 0x8e, 0x40, 0x8e, 0x8d, 0x86, 0xdf, 0xfe,
	0xa4, 0xff, 0x77, 0x08, 0xa6, 0x38, 0x13, 0xa0, 0x16, 0x00, 0xe7, 0x28, 0x5d, 0x63, 0xb2, 0x2b,
	0x5e, 0xb8, 0x77, 0x76, 0x9a, 0x89, 0x15, 0x69, 0x2a, 0xbb, 0xdf, 0xfc, 0xf4, 0xb2, 0xed, 0x0b,
	0x22, 0x72, 0x8c, 0x35, 0x52, 0xd1, 0xa8, 0x73, 0xc7, 0x81, 0xea, 0xb0, 0x97, 0xcb, 0xfb, 0xb6,
	0xda, 0xe4, 0xae, 0xb7, 0x33, 0x07, 0xaa, 0xb3, 0x26, 0xd2, 0x50, 0x9a, 0x60, 0xdb, 0x23, 0xf6,
	0xd8, 0x86, 0x3d, 0xc2, 0xf3, 0xbe, 0xd1, 0x2d, 0x58, 0xf0, 0x2a, 0x2b, 0x84, 0xb9, 0x76, 0xdb,
	0x8d, 0x43, 0xcc, 0x9f, 0x5f, 0xc6, 0xe5, 0x39, 0x2f, 0x73, 0x53, 0x7d, 0x5c, 0x60, 0x59, 0xd9,
	0x05, 0x98, 0xf3, 0xed, 0x04, 0xcf, 0x72, 0x81, 0x41, 0x62, 0x1e, 0xc2, 0xbe, 0x98, 0x2c, 0xf7,
	0x60, 0xb6, 0x2b, 0xbe, 0x35, 0x97, 0xb9, 0x7e, 0xed, 0x27, 0x18, 0x10, 0x3b, 0xc7, 0x5f, 0xa7,
	0x0a, 0x63, 0x53, 0xa2, 0x11, 0xf8, 0xce, 0x7e, 0x0b, 0x92, 0x5e, 0x33, 0x9e, 0x18, 0xbd, 0x0a,
	0x31, 0xea, 0x61, 0xda, 0x54, 0xed, 0x43, 0xe1, 0x65, 0xea, 0x25, 0x64, 0x33, 0x70, 0x8d, 0xde,
	0x88, 0xdd, 0xdb, 0xa0, 0x3d, 0x2e, 0xb2, 0x37, 0xad, 0xbe, 0x2b, 0xb3, 0x15, 0xb8, 0xde, 0xbf,
	0x80, 0x37, 0xb8, 0x7f, 0x19, 0x06, 0x24, 0x5b, 0xc7, 0x54, 0x88, 0xd1, 0x70, 0x41, 0x6c, 0x7c,
	0x1a, 0x44, 0x45, 0x4c, 0x94, 0xe7, 0x7f, 0x77, 0x3b, 0xc5, 0xe3, 0xa9, 0xa0, 0xef, 0xc0, 0x64,
	0xa3, 0xed, 0x5a, 0x7b, 0x7b, 0x5c, 0xdc, 0x8d, 0x16, 0x2c, 0x85, 0xd7, 0x41, 0x36, 0xc4, 0x59,
	0x1f, 0xc5, 0x0a, 0x50, 0xcf, 0xd7, 0xc2, 0xe6, 0x57, 0xa7, 0x99, 0xca, 0x65, 0x7b, 0xd7, 0x91,
	0xa9, 0x62, 0x99, 0x66, 0x68, 0x1b, 0x62, 0x91, 0xfe, 0x45, 0x18, 0xe6, 0x7c, 0xd3, 0xe5, 0xad,
	0xd3, 0xb7, 0x60, 0xe1, 0x4b, 0x6b, 0x57, 0x61, 0xa2, 0x44, 0x53, 0x6c, 0xeb, 0xd8, 0xa7, 0x1e,
	0x8c, 0xcb, 0xe8, 0x4b, 0x6b, 0x97, 0x85, 0x5c, 0xd2, 0x64, 0xeb, 0x98, 0xea, 0x08, 0xa8, 0x05,
	0xf3, 0x2d, 0xdb, 0x6a, 0x60, 0xc7, 0xb1, 0x6c, 0xcf, 0x61, 0xc4, 0x33, 0x51, 0xbd, 0x7f, 0x9e,
	0xbe, 0x12, 0xe8, 0x00, 0xa3, 0xd0, 0x65, 0x9a, 0x9a, 0x6b, 0x75, 0x67, 0x60, 0x07, 0xad, 0xc2,
	0x3c, 0xe9, 0x24, 0x73, 0x1c, 0xa6, 0xa7, 0x20, 0xeb, 0x23, 0x77, 0x79, 0xfb, 0xd2, 0xda, 0xad,
	0x93, 0x2c, 0x76, 0xc1, 0x4a, 0xba, 0xf8, 0x3e, 0xa4, 0x48, 0x05, 0x4e, 0x8b, 0xab, 0x67, 0xbc,
	0x12, 0xf3, 0x56, 0x25, 0xa3, 0xde, 0x16, 0xd9, 0x5e, 0x45, 0xae, 0xea, 0xfd, 0xd1, 0x38, 0x5c,
	0x3d, 0xaf, 0xaf, 0xe8, 0x16, 0xcc, 0x74, 0xa6, 0xc0, 0x0b, 0x65, 0x46, 0x45, 0xb9, 0x57, 0xb8,
	0x52, 0x92, 0xa7, 0xbd, 0x42, 0x15, 0x0d, 0x3d, 0x86, 0x59, 0xe7, 0x91, 0xa1, 0xe8, 0xa6, 0xe3,
	0xaa, 0x66, 0x03, 0x77, 0x02, 0x98, 0x6d, 0x5f, 0x28, 0x4e, 0x33, 0x7b, 0xcd, 0x78, 0x6f, 0xa3,
	0xc2, 0xe9, 0x50, 0x85, 0x22, 0x1e, 0x48, 0x90, 0xe3, 0xce, 0x23, 0xc3, 0xfb, 0xa4, 0xd1, 0xdb,
	0x7a, 0xd7, 0x97, 0xf9, 0x16, 0xce, 0x6a, 0x5d, 0x8b, 0x7b, 0x03, 0xa4, 0x01, 0xd3, 0x9c, 0x70,
	0x83, 0x73, 0xfc, 0x96, 0xc7, 0x06, 0xc1, 0xf9, 0x9d, 0x64, 0x8c, 0xd3, 0xea, 0x99, 0x5c, 0xf4,
	0x36, 0x2c, 0x74, 0x66, 0xad, 0x61, 0x99, 0x8d, 0xb6, 0x6d, 0x63, 0xb3, 0x71, 0xc2, 0x97, 0xa4,
	0xc3, 0x55, 0xc5, 0x4e, 0x5e, 0x36, 0x25, 0xac, 0xaf, 0x75, 0x6c, 0xe0, 0x26, 0x76, 0xed, 0x13,
	0x21, 0x23, 0x96, 0x61, 0xa9, 0x2b, 0xc7, 0x13, 0x0e, 0x8b, 0x30, 0xbf, 0x6d, 0x19, 0xc6, 0xba,
	0xb5, 0xeb, 0xf8, 0x95, 0x83, 0xec, 0x12, 0x2c, 0x04, 0xd2, 0xbd, 0x0a, 0xcb, 0xb0, 0x44, 0xe4,
	0x0d, 0xbf, 0x9e, 0x6f, 0x9b, 0x66, 0xe7, 0xe2, 0x3c, 0x0d, 0xa9, 0xee, 0x2c, 0xaf, 0x5a, 0x16,
	0xd2, 0x9d, 0xbc, 0xb2, 0x79, 0x14, 0xa8, 0xc9, 0xed, 0xca, 0xd7, 0xe0, 0x4a, 0x9f, 0x32, 0x1e,
	0x89, 0x17, 0x61, 0xa1, 0x93, 0x5d, 0x57, 0x9d, 0xc3, 0x40, 0x6d, 0xa6, 0x8e, 0x91, 0x49, 0x08,
	0x16, 0xf2, 0xaa, 0x5f, 0x87, 0xab, 0x24, 0x67, 0x87, 0xc6, 0x11, 0xa8, 0xdd, 0xdb, 0xc8, 0x37,
	0x5c, 0xfd, 0x48, 0x77, 0xbd, 0x49, 0xe2, 0x92, 0xb6, 0x27, 0xdf, 0x23, 0x90, 0x86, 0xd4, 0xe6,
	0xfd, 0x62, 0x91, 0x4c, 0x87, 0xee, 0xb8, 0x7a, 0xc3, 0x59, 0x27, 0x3b, 0x9e, 0x55, 0xbe, 0x02,
	0xcb, 0x3d, 0x79, 0x5e, 0xc5, 0xab, 0x90, 0xae, 0xb9, 0xaa, 0xa9, 0xed, 0x9e, 0xd0, 0x98, 0xcd,
	0x35, 0x32, 0xb1, 0x9d, 0x59, 0xbb, 0x06, 0x57, 0xfa, 0xe4, 0x7a, 0x95, 0x53, 0xb0, 0xb8, 0x66,
	0xb9, 0x32, 0xb5, 0x03, 0x6f, 0x58, 0xfb, 0xfb, 0x9d, 0x8a, 0xff, 0x23, 0x02, 0x89, 0x8a, 0xe9,
	0xb4, 0x70, 0xc3, 0xf3, 0xb0, 0xbf, 0x03, 0x93, 0x54, 0xdf, 0x15, 0xe8, 0x63, 0xf5, 0x3c, 0xa7,
	0xf8, 0x40, 0xd5, 0x1c, 0x55, 0x6f, 0x65, 0x5e, 0x1d, 0x7d, 0x20, 0x54, 0xbc, 0x0b, 0x20, 0x54,
	0xaa, 0xe8, 0xa5, 0x7f, 0x31, 0x0e, 0x13, 0xec, 0x35, 0x5d, 0x3d, 0x60, 0xfc, 0xfb, 0xf4, 0x82,
	0x5d, 0x11, 0x89, 0xf4, 0xc3, 0x67, 0xf9, 0xf3, 0x1f, 0x5b, 0xe1, 0xaf, 0xed, 0xd8, 0xf2, 0xdb,
	0xd4, 0x99, 0x2f, 0xce, 0xd7, 0x65, 0x53, 0xcf, 0xfe, 0xe3, 0x10, 0x48, 0xdd, 0x63, 0x45, 0x1f,
	0xc2, 0x72, 0xa5, 0x5a, 0xdb, 0x2e, 0x17, 0xeb, 0x4a, 0x71, 0xad, 0x5c, 0xbc, 0xab, 0xec, 0xd0,
	0xaf, 0xca, 0xed, 0x4a, 0xb9, 0x24, 0x8d, 0xa5, 0xaf, 0x3c, 0x79, 0xba, 0xb2, 0xe4, 0xaf, 0xb4,
	0x63, 0x72, 0x63, 0x11, 0xd6, 0x50, 0x19, 0x32, 0xc1, 0xba, 0x95, 0x6a, 0xa9, 0xfc, 0x99, 0x52,
	0xdc, 0xaa, 0xd6, 0x2a, 0xb5, 0x7a, 0xb9, 0x5a, 0x7c, 0x28, 0x85, 0xd2, 0x2b, 0x4f, 0x9e, 0xae,
	0x5c, 0xf5, 0x53, 0xa0, 0xfd, 0x2a, 0x5a, 0xa6, 0xa3, 0x3b, 0x2e, 0x11, 0x27, 0xe9, 0xe8, 0xdf,
	0xf9, 0xf3, 0xeb, 0x63, 0xff, 0xec, 0xa7, 0xd7, 0xc7, 0xb2, 0x2f, 0x40, 0x86, 0xed, 0x0a, 0x76,
	0xc3, 0xc7, 0x7f, 0xd4, 0xa4, 0xa8, 0x36, 0x0e, 0xc4, 0x1d, 0x5b, 0xf6, 0x3f, 0x87, 0x61, 0x65,
	0x50, 0x19, 0x7f, 0x88, 0x41, 0x1a, 0xee, 0xb7, 0x27, 0xa2, 0xd5, 0x30, 0xa5, 0x20, 0x44, 0x95,
	0x82, 0x38, 0xa9, 0xdc, 0x89, 0x38, 0x2b, 0x82, 0x07, 0x77, 0x1c, 0x98, 0x7c, 0x11, 0xae, 0x46,
	0xa3, 0x48, 0x83, 0x07, 0x7b, 0xef, 0xbb, 0x79, 0xe0, 0xc2, 0xa0, 0x4f, 0x4c, 0xe1, 0x1c, 0xb6,
	0x1d, 0x36, 0xe0, 0x6e, 0x6b, 0xfe, 0x2b, 0x9e, 0x35, 0x7f, 0x16, 0xa6, 0xab, 0x5b, 0x75, 0x45,
	0xde, 0xa9, 0x56, 0x2b, 0xd5, 0x3b, 0x3c, 0x0c, 0x18, 0xff, 0x08, 0x65, 0x7f, 0x1f, 0x16, 0x98,
	0xd7, 0xb4, 0x6c, 0x19, 0xc6, 0xae, 0xda, 0x38, 0xfc, 0xad, 0xaa, 0x6c, 0xf4, 0xb4, 0x78, 0x64,
	0x08, 0xf1, 0x77, 0xdb, 0x68, 0x3b, 0x07, 0x3e, 0x09, 0xdf, 0x9d, 0xe5, 0x3f, 0x18, 0xba, 0x04,
	0x95, 0x97, 0x95, 0x84, 0x59, 0xce, 0x6a, 0x7e, 0xb1, 0x16, 0x1c, 0xa3, 0x97, 0xf3, 0x1f, 0x57,
	0x60, 0x6a, 0x5b, 0x3d, 0x31, 0x2c, 0x55, 0x43, 0x2b, 0x34, 0xbe, 0x18, 0x55, 0xd7, 0x84, 0xfe,
	0x1d, 0x93, 0xfd, 0x49, 0x41, 0xa4, 0x2a, 0xd1, 0x17, 0x17, 0x3e, 0xa4, 0x6a, 0x13, 0x98, 0x87,
	0x6d, 0x02, 0x22, 0x15, 0xca, 0x09, 0xcc, 0xdc, 0x57, 0xb8, 0xfb, 0xd5, 0x69, 0xe6, 0xce, 0x68,
	0x73, 0x85, 0x1b, 0x6d, 0x5b, 0x77, 0x4f, 0x56, 0x05, 0x1d, 0xa2, 0x51, 0xec, 0xf0, 0xbf, 0xb7,
	0x09, 0x49, 0x82, 0x19, 0x7d, 0x9f, 0x3c, 0x4a, 0x00, 0x0d, 0x1e, 0xd9, 0xd4, 0x1b, 0xb6, 0xe5,
	0x88, 0xc7, 0x09, 0x3c, 0x75, 0x93, 0x26, 0xa2, 0x57, 0x61, 0x76, 0x4f, 0x37, 0x59, 0x50, 0x4a,
	0x5e, 0x8e, 0x6b, 0x0f, 0x22, 0x99, 0x17, 0x3c, 0xa2, 0x0e, 0xa8, 0x9d, 0xab, 0x0e, 0x66, 0xc2,
	0x8f, 0x17, 0xb6, 0x68, 0x48, 0x56, 0x5f, 0x28, 0x57, 0xe7, 0x19, 0x19, 0x20, 0xee, 0xbf, 0xf2,
	0x70, 0xd0, 0x3c, 0x4c, 0xd0, 0x9f, 0x44, 0x62, 0x51, 0xb6, 0x64, 0xf6, 0x81, 0xca, 0x10, 0xe7,
	0x1e, 0x2e, 0xec, 0xf7, 0x92, 0x78, 0x4c, 0x03, 0xbf, 0x4b, 0xba, 0xf8, 0x45, 0xa5, 0x5c, 0xd9,
	0x6c, 0x58, 0x1a, 0xd6, 0xca, 0xe4, 0x5b, 0xe6, 0x8e, 0x72, 0xf4, 0x83, 0x1c, 0x54, 0x89, 0x86,
	0x81, 0x55, 0xb3, 0xdd, 0x12, 0x74, 0xd0, 0x88, 0x74, 0xe2, 0xbc, 0x1e, 0x27, 0x54, 0x05, 0xb4,
	0x47, 0x1f, 0xd6, 0xfa, 0x7b, 0x45, 0x1f, 0xed, 0x8c, 0x42, 0x4c, 0xa2, 0x75, 0xe5, 0x4e, 0xcf,
	0xd0, 0x4b, 0x10, 0x37, 0x2d, 0xb3, 0x41, 0xf4, 0x41, 0x83, 0x5a, 0x69, 0xe6, 0x99, 0x5d, 0x20,
	0x90, 0x88, 0x0a, 0x30, 0xc9, 0x02, 0x89, 0x70, 0x6f, 0x81, 0x1b, 0xa3, 0xc6, 0xa2, 0x5b, 0x1b,
	0x93, 0x79, 0x4d, 0x54, 0x86, 0x29, 0xfe, 0xec, 0x9a, 0x5b, 0xd5, 0x6f, 0x8e, 0xfc, 0xd4, 0x72,
	0x6d, 0x4c, 0x16, 0x75, 0x51, 0x5d, 0x04, 0xf7, 0x60, 0x16, 0x3a, 0x1e, 0x44, 0x21, 0x37, 0xe2,
	0xd5, 0x63, 0x87, 0x60, 0x80, 0x0a, 0x19, 0xa0, 0x4e, 0xb7, 0xe7, 0x00, 0x7f, 0x81, 0x81, 0xaf,
	0xeb, 0xc8, 0x00, 0x59, 0x4d, 0x54, 0x05, 0x68, 0x78, 0x56, 0x43, 0x1a, 0x79, 0xf9, 0x7c, 0xe3,
	0x5b, 0xcf, 0x35, 0xcd, 0x1a, 0xf5, 0xd7, 0x14, 0x89, 0xe8, 0x1e, 0xf0, 0x50, 0xd3, 0x54, 0x21,
	0xe5, 0xbf, 0x95, 0xf1, 0xe6, 0x85, 0x6c, 0x5e, 0x6b, 0x63, 0xb2, 0x9f, 0x06, 0xfa, 0x1c, 0x12,
	0x4e, 0xe0, 0x22, 0x96, 0x46, 0xe2, 0x3a, 0xff, 0xe6, 0xa1, 0xaf, 0x4b, 0xde, 0xda, 0x98, 0xdc,
	0x45, 0x09, 0x7d, 0x1f, 0x24, 0xb7, 0xeb, 0x01, 0x03, 0x7d, 0x31, 0x36, 0xc4, 0x26, 0xdc, 0xff,
	0x99, 0xc6, 0xda, 0x98, 0xdc, 0x43, 0x0d, 0x7d, 0x01, 0xb3, 0x5d, 0xa1, 0x3d, 0x79, 0xfc, 0x87,
	0x6f, 0x8d, 0x1e, 0x69, 0xb7, 0x43, 0xbf, 0x9b, 0x16, 0x21, 0x6f, 0x06, 0x9d, 0x7a, 0x79, 0xc0,
	0xb0, 0xf3, 0xc8, 0xf7, 0x7f, 0x96, 0x41, 0xc8, 0x77, 0xd1, 0x42, 0x77, 0x21, 0xd6, 0x14, 0xc6,
	0x10, 0x1a, 0x71, 0xe2, 0xfc, 0x17, 0x1a, 0xdd, 0xf6, 0x99, 0xb5, 0x31, 0xb9, 0x53, 0x1f, 0xfd,
	0xed, 0x10, 0x5c, 0x55, 0xcf, 0xf1, 0x1c, 0xa6, 0xef, 0x11, 0xcf, 0x77, 0xb5, 0x1c, 0xc1, 0x3f,
	0x79, 0x6d, 0x4c, 0x3e, 0xb7, 0x15, 0x64, 0xc3, 0xa2, 0xda, 0xd7, 0x18, 0xc3, 0x83, 0x48, 0x7c,
	0x30, 0xac, 0xfd, 0x41, 0x66, 0x9e, 0xb5, 0x31, 0x79, 0x00, 0x65, 0xd4, 0x80, 0xa4, 0xd3, 0x1d,
	0x11, 0x96, 0xc6, 0x7b, 0x98, 0xbe, 0xf5, 0xf6, 0x45, 0xa2, 0xc8, 0x76, 0x5a, 0xea, 0xa5, 0x87,
	0x34, 0x88, 0x13, 0x40, 0xcc, 0x4c, 0xea, 0xae, 0x6b, 0xd0, 0xa0, 0x10, 0xe7, 0xef, 0xbe, 0x5e,
	0x93, 0x13, 0x83, 0xfd, 0xbe, 0x74, 0xb2, 0x1d, 0x6d, 0xf1, 0xe9, 0x1a, 0xe8, 0x7b, 0x20, 0xf1,
	0x30, 0x24, 0xae, 0x00, 0xaa, 0x34, 0xe8, 0xc2, 0x10, 0x8e, 0xee, 0x0b, 0x7a, 0x29, 0x47, 0x07,
	0x73, 0x10, 0x86, 0xf9, 0xc3, 0x3e, 0x1e, 0xdf, 0xa9, 0x57, 0x68, 0x1b, 0xe7, 0x81, 0xa5, 0x7e,
	0x8e, 0xe2, 0x6b, 0x63, 0x72, 0x5f, 0x72, 0xe8, 0x21, 0xcc, 0xb6, 0x2c, 0xc3, 0x50, 0x48, 0x5d,
	0x6e, 0x87, 0x7e, 0x75, 0x68, 0x0b, 0xfd, 0x50, 0xf8, 0xda, 0x98, 0x1c, 0x6f, 0xf9, 0xd3, 0xd1,
	0x2e, 0x20, 0x1a, 0x4e, 0x83, 0x45, 0x09, 0x50, 0x6c, 0x8a, 0x90, 0x53, 0x37, 0x87, 0x8a, 0x95,
	0x01, 0x90, 0x9d, 0x88, 0x15, 0xb5, 0x2b, 0x0b, 0x19, 0x8c, 0x89, 0x45, 0x1b, 0xd8, 0x3c, 0x12,
	0xed, 0xbc, 0x46, 0xdb, 0x79, 0x77, 0xa4, 0x76, 0xba, 0x31, 0xfe, 0xda, 0x98, 0x3c, 0xa7, 0xf6,
	0xe6, 0xa2, 0xdf, 0x05, 0xc9, 0xdf, 0x9a, 0xab, 0x3a, 0x87, 0xa9, 0xd7, 0x87, 0x0a, 0xe1, 0xbe,
	0x86, 0x00, 0x22, 0x84, 0xd5, 0x40, 0x06, 0x3a, 0x82, 0x34, 0xa5, 0xce, 0xa2, 0x07, 0x2a, 0xce,
	0x23, 0x43, 0x51, 0x99, 0xf6, 0xaa, 0x63, 0x27, 0xf5, 0x06, 0x6d, 0xe7, 0xfd, 0x21, 0xed, 0x0c,
	0xb2, 0x18, 0xac, 0x8d, 0xc9, 0x4b, 0x6a, 0x27, 0xdf, 0xd3, 0x8b, 0x75, 0xec, 0xa0, 0x26, 0x2c,
	0x35, 0x8f, 0x1a, 0x0d, 0xba, 0xfa, 0xcc, 0x20, 0xe0, 0xbd, 0x08, 0x7c, 0x73, 0xe8, 0xd6, 0x1c,
	0x64, 0x65, 0x58, 0x1b, 0x93, 0x17, 0x08, 0xd5, 0x4e, 0x9e, 0xe0, 0xb8, 0x2f, 0x61, 0x89, 0x1d,
	0xba, 0x8a, 0xcd, 0xd5, 0x69, 0xaf, 0xb9, 0xdc, 0xd0, 0xb9, 0xec, 0x8b, 0x35, 0x48, 0x5b, 0x7a,
	0x5f, 0x10, 0xd2, 0x82, 0x65, 0x1e, 0x6d, 0x54, 0xb1, 0xc5, 0x2f, 0xba, 0x78, 0xad, 0xad, 0x0e,
	0xe5, 0xc4, 0x01, 0x3f, 0x83, 0x43, 0x26, 0xf3, 0x60, 0xc0, 0x2f, 0xe4, 0x1c, 0xc1, 0x15, 0x83,
	0x05, 0xae, 0x57, 0xfc, 0x3f, 0x5f, 0x22, 0xda, 0x7c, 0x6b, 0x68, 0xf4, 0xd5, 0x81, 0xbf, 0x20,
	0xb0, 0x36, 0x26, 0x2f, 0x1b, 0x03, 0x7f, 0x2a, 0xe6, 0x49, 0x08, 0x5e, 0xe4, 0x8c, 0xc3, 0x1d,
	0x5f, 0x39, 0xca, 0x53, 0x1a, 0x04, 0xe6, 0x79, 0x1d, 0xf8, 0xd6, 0xd0, 0x48, 0x19, 0x43, 0xe0,
	0xf3, 0xda, 0x98, 0x88, 0x6f, 0x39, 0xb0, 0x08, 0xfa, 0x3d, 0xb8, 0xee, 0x30, 0x33, 0x91, 0xc2,
	0x7e, 0x34, 0xcc, 0x51, 0x5a, 0xd4, 0x52, 0xe4, 0x75, 0xe3, 0xd6, 0xd0, 0xdd, 0x39, 0xd8, 0x0a,
	0xb5, 0x36, 0x26, 0xa7, 0x1d, 0x5f, 0xae, 0x13, 0xc8, 0x45, 0x8f, 0x20, 0xed, 0xdb, 0x3a, 0x27,
	0xca, 0x1e, 0x41, 0x7e, 0x5e, 0xc3, 0x6f, 0x0f, 0x5d, 0xf4, 0x01, 0x78, 0x92, 0x2c, 0xba, 0xd3,
	0x3f, 0x0b, 0x99, 0xb0, 0x7c, 0x60, 0xb9, 0x0a, 0xf7, 0x8d, 0x34, 0x28, 0xa0, 0xf4, 0x5a, 0x7c,
	0x67, 0xe8, 0xa1, 0xd0, 0xdf, 0x66, 0x46, 0x8e, 0xd1, 0x83, 0xbe, 0x39, 0xa8, 0x0e, 0xb3, 0x3a,
	0xc3, 0xa8, 0x5e, 0x2b, 0xef, 0x0e, 0x55, 0xcb, 0x83, 0x86, 0x2b, 0x22, 0x7f, 0xf4, 0xa0, 0x41,
	0xee, 0x05, 0x98, 0x69, 0xa9, 0x6d, 0x07, 0x93, 0x35, 0x73, 0x2c, 0x93, 0x06, 0xc2, 0x8a, 0xc9,
	0xd3, 0x34, 0x4d, 0xa6, 0x49, 0xe8, 0x87, 0x21, 0x98, 0xa3, 0x3a, 0x29, 0x8d, 0xfe, 0xd2, 0xf9,
	0xf1, 0x9c, 0x17, 0xe9, 0xfd, 0xf9, 0xf6, 0xb3, 0xdd, 0x9f, 0x27, 0x8b, 0x9c, 0x72, 0xe7, 0xe7,
	0x73, 0x92, 0x8d, 0xae, 0x24, 0x0d, 0x7d, 0x0e, 0xa9, 0x9e, 0x1e, 0x88, 0x1b, 0x97, 0x97, 0xb8,
	0x3d, 0xa5, 0xf7, 0x42, 0x93, 0x5f, 0x98, 0x70, 0xeb, 0xdf, 0x62, 0x17, 0x59, 0xe1, 0x61, 0xbd,
	0x0e, 0xb3, 0x4d, 0xf5, 0xb1, 0xde, 0x6c, 0x37, 0x69, 0xe8, 0x64, 0x75, 0x1f, 0xa7, 0x6e, 0xd0,
	0x0b, 0xce, 0x2c, 0xc1, 0xaf, 0x9b, 0x2c, 0x6b, 0xbb, 0x5e, 0xcb, 0xef, 0xe3, 0xde, 0x48, 0xfe,
	0x71, 0x5e, 0x75, 0xdb, 0x75, 0xf2, 0xfb, 0xb8, 0x10, 0x83, 0x29, 0xcd, 0xb3, 0xf9, 0xb2, 0xc0,
	0x09, 0x2c, 0x42, 0x01, 0x8b, 0x4d, 0x90, 0x96, 0xae, 0xac, 0x47, 0xa2, 0x2b, 0xd2, 0x0b, 0xd9,
	0x9f, 0xa5, 0x21, 0xea, 0x99, 0x9d, 0x56, 0x01, 0x79, 0xd7, 0xce, 0x9d, 0x20, 0x7f, 0xa1, 0x95,
	0xd0, 0x8d, 0x30, 0x51, 0x76, 0x44, 0x5e, 0x27, 0xce, 0xdf, 0xc7, 0x81, 0xc0, 0x2f, 0xe3, 0x23,
	0x58, 0x40, 0x89, 0x32, 0xda, 0x89, 0x0c, 0xf3, 0x2a, 0xcc, 0xf2, 0xb8, 0x73, 0x1e, 0xb4, 0x67,
	0x8f, 0x49, 0x12, 0x22, 0x99, 0x43, 0x7b, 0x1e, 0x50, 0xb0, 0xed, 0x28, 0x4d, 0xec, 0x38, 0x64,
	0x6a, 0xf8, 0x8f, 0xba, 0xb2, 0xd4, 0x4d, 0x96, 0x88, 0x8a, 0x5d, 0x68, 0xf3, 0xe6, 0x50, 0xb4,
	0x29, 0xc6, 0xbe, 0x16, 0xf2, 0xe0, 0xe6, 0xed, 0x6e, 0xb8, 0xf9, 0xda, 0xe8, 0xb1, 0x6a, 0xd6,
	0x42, 0x1d, 0xbc, 0xb9, 0xd3, 0x17, 0x6f, 0xae, 0x8e, 0x08, 0x98, 0x7c, 0x14, 0x83, 0x80, 0xb3,
	0xd8, 0x05, 0x38, 0x6f, 0x0e, 0x3d, 0xb0, 0xfc, 0x63, 0xe4, 0x88, 0x73, 0xab, 0x0f, 0xe2, 0x7c,
	0x73, 0x24, 0xc4, 0xe9, 0x23, 0xe6, 0x87, 0x9c, 0x72, 0x3f, 0xc8, 0x99, 0x1b, 0x0d, 0x72, 0xfa,
	0x48, 0x06, 0x30, 0xe7, 0x77, 0x7b, 0x30, 0xa7, 0x34, 0xa2, 0x8a, 0xdb, 0xed, 0x2d, 0xbc, 0x16,
	0xea, 0x01, 0x9d, 0x6a, 0x1f, 0xd0, 0x99, 0x1c, 0xaa, 0x70, 0x0c, 0x7a, 0x68, 0xbf, 0x16, 0xea,
	0x83, 0x3a, 0x3f, 0x83, 0x19, 0x3f, 0x52, 0xa4, 0x71, 0x53, 0x86, 0x48, 0xff, 0xfe, 0xbf, 0x02,
	0x49, 0x79, 0xc0, 0x97, 0x85, 0xbe, 0xd7, 0x0b, 0x38, 0xe7, 0x86, 0x12, 0x1f, 0xf0, 0xee, 0x74,
	0x2d, 0xd4, 0x8b, 0x38, 0x37, 0xfc, 0x88, 0x73, 0x7e, 0xa8, 0x3d, 0xa2, 0xe7, 0xaa, 0x7e, 0x2d,
	0xe4, 0x87, 0x9c, 0x3f, 0x0a, 0xb1, 0x0b, 0xa5, 0x81, 0x90, 0x93, 0x81, 0xfd, 0x4f, 0x2e, 0x09,
	0x39, 0x7d, 0x8d, 0x9e, 0xdb, 0x0c, 0x72, 0x06, 0x62, 0xce, 0xa5, 0xa1, 0xa1, 0x3c, 0xce, 0xf7,
	0x1c, 0x58, 0x0b, 0x0d, 0x04, 0x9d, 0x5a, 0x3f, 0xd0, 0x99, 0x1a, 0xf1, 0x67, 0x7e, 0xfa, 0xfc,
	0x74, 0xc9, 0x5a, 0xa8, 0x1f, 0xea, 0xc4, 0xdd, 0xa8, 0x73, 0x79, 0xb8, 0xa3, 0x5f, 0xef, 0xcd,
	0x7d, 0x2f, 0xec, 0x0c, 0x05, 0x61, 0xa7, 0xd2, 0x07, 0x76, 0xa6, 0x87, 0x73, 0x75, 0xff, 0x1b,
	0x55, 0xc2, 0x78, 0xdd, 0xb8, 0xf3, 0x00, 0x16, 0x0e, 0xfb, 0xbd, 0x28, 0xe6, 0x56, 0x89, 0xb7,
	0x46, 0x05, 0x9e, 0xbe, 0x36, 0xfa, 0x13, 0x44, 0x9f, 0x41, 0x10, 0x30, 0x52, 0x85, 0xe3, 0xfc,
	0x16, 0xfa, 0x5e, 0xf3, 0xae, 0x85, 0xba, 0x91, 0x67, 0xa3, 0x2f, 0xf2, 0xbc, 0x36, 0x54, 0xb6,
	0x0c, 0xba, 0x11, 0x26, 0xb2, 0xa5, 0x07, 0x7a, 0x36, 0x07, 0x42, 0xcf, 0xeb, 0x7d, 0xe3, 0xe1,
	0x0d, 0x81, 0x9e, 0xbe, 0xb6, 0xfa, 0x62, 0xcf, 0x2f, 0xfa, 0x60, 0xcf, 0xcc, 0x50, 0x61, 0xdc,
	0xff, 0x7e, 0x99, 0x08, 0xe3, 0x2e, 0xf0, 0xf9, 0x25, 0xcc, 0xf5, 0xe2, 0xce, 0x93, 0xd4, 0xca,
	0x48, 0xa6, 0xa0, 0x81, 0xf7, 0xd0, 0x64, 0xab, 0xb4, 0xbb, 0x20, 0xe7, 0x09, 0x6a, 0x41, 0xaa,
	0x1b, 0x70, 0x7a, 0x11, 0x4a, 0x5e, 0x18, 0xba, 0x2f, 0x07, 0xde, 0x5d, 0x13, 0x11, 0x10, 0x84,
	0x9c, 0x1e, 0xab, 0x35, 0x21, 0xd5, 0x8d, 0x39, 0xbd, 0x16, 0xb3, 0x43, 0x27, 0xb1, 0xff, 0xe5,
	0x0f, 0x69, 0x4e, 0xef, 0x9b, 0x83, 0x1e, 0x0d, 0xfe, 0x1d, 0x51, 0xaa, 0x2a, 0x9f, 0xcf, 0x85,
	0x83, 0xaa, 0xae, 0x85, 0xe4, 0xc1, 0x3f, 0x4f, 0xba, 0x0f, 0xa8, 0x17, 0x39, 0x72, 0x85, 0xf8,
	0xdd, 0x0b, 0xc1, 0x4d, 0x5f, 0x73, 0x7d, 0x48, 0x22, 0x0b, 0xe6, 0xfb, 0x01, 0x4c, 0x6e, 0xfb,
	0xfa, 0x9d, 0x67, 0xb8, 0x82, 0x24, 0x0d, 0xba, 0x3d, 0xb9, 0x64, 0x9f, 0xf5, 0x07, 0x93, 0xdc,
	0x14, 0xf6, 0xde, 0xc5, 0x40, 0xa4, 0x7f, 0x9f, 0xf5, 0x41, 0x91, 0x44, 0x76, 0xf4, 0xc2, 0x47,
	0x6e, 0x13, 0x7b, 0xfb, 0x02, 0xb0, 0xd1, 0x2f, 0x3b, 0xba, 0x71, 0x23, 0xfa, 0x3e, 0x24, 0x7b,
	0x00, 0x23, 0x85, 0x1a, 0x43, 0xec, 0x11, 0xfd, 0xef, 0x2c, 0x89, 0x18, 0xef, 0x42, 0x8a, 0x44,
	0x85, 0xe6, 0xf0, 0x8e, 0x5b, 0xdc, 0x5e, 0x1b, 0x0e, 0x0d, 0xfd, 0x2a, 0x34, 0xaf, 0x8c, 0x1e,
	0x41, 0xd4, 0xb5, 0x55, 0xe6, 0xd8, 0xb4, 0x40, 0x1d, 0xda, 0xee, 0x73, 0x94, 0x57, 0x1c, 0x1d,
	0xe5, 0x11, 0x0a, 0xba, 0xb9, 0x2f, 0xfe, 0x27, 0x5a, 0x1c, 0xa1, 0x49, 0x51, 0xdf, 0x14, 0xff,
	0x53, 0x9e, 0xa2, 0xed, 0x54, 0xb4, 0x02, 0x40, 0x54, 0x6c, 0x4e, 0x1f, 0x8a, 0xca, 0xfe, 0x79,
	0x08, 0xc6, 0xd7, 0xad, 0x5d, 0x74, 0xcd, 0xf7, 0xe6, 0x2e, 0xce, 0xfb, 0x32, 0xb1, 0x6e, 0xed,
	0xf2, 0xc7, 0x73, 0x9f, 0x74, 0x6a, 0xf3, 0xfb, 0xf5, 0x17, 0xcf, 0x3b, 0x50, 0xc4, 0x13, 0x47,
	0xaf, 0x12, 0xfa, 0x0e, 0x4c, 0xb5, 0xd8, 0x95, 0x2e, 0x87, 0x53, 0xd9, 0xf3, 0xea, 0xb3, 0x92,
	0xb2, 0xa8, 0x92, 0xfd, 0x9f, 0x61, 0x58, 0x96, 0xb1, 0x6b, 0xeb, 0x84, 0x91, 0xcb, 0x22, 0xc6,
	0xf2, 0x6d, 0x55, 0x37, 0xda, 0x36, 0xfd, 0xd9, 0x0d, 0xdf, 0xab, 0xbb, 0x98, 0xb8, 0x6d, 0x47,
	0xef, 0xc0, 0x62, 0x27, 0x98, 0x33, 0x73, 0x39, 0x08, 0x80, 0xb1, 0x79, 0x2f, 0x97, 0xfa, 0x14,
	0x70, 0x48, 0xf6, 0x16, 0x74, 0xd2, 0x15, 0x6c, 0x76, 0xdd, 0xe1, 0x76, 0xc2, 0x43, 0x97, 0x4d,
	0x01, 0xe2, 0x4c, 0x98, 0xf6, 0x7b, 0xaa, 0x45, 0xa8, 0xa7, 0xda, 0xe6, 0xb3, 0x7b, 0xaa, 0x81,
	0xcf, 0x4d, 0x0d, 0xf4, 0x8e, 0x8f, 0xda, 0x7b, 0xe2, 0x5e, 0x76, 0x62, 0xc4, 0x4b, 0x4e, 0x7e,
	0x73, 0xfb, 0x2a, 0xcc, 0xba, 0x76, 0xdb, 0x64, 0x3f, 0x63, 0xc5, 0x28, 0x50, 0xbf, 0x6a, 0x39,
	0xe1, 0x25, 0xd3, 0xf2, 0xd9, 0x2f, 0x21, 0x46, 0xf9, 0x87, 0x06, 0xf6, 0xfe, 0x02, 0x66, 0xf9,
	0x6f, 0x29, 0x75, 0x3d, 0xdd, 0xc8, 0x75, 0x03, 0x62, 0xce, 0x88, 0xb9, 0x0e, 0x43, 0x32, 0x7f,
	0xfc, 0xc0, 0x0b, 0x8e, 0x84, 0x47, 0x8c, 0x7a, 0x3f, 0xbf, 0xf6, 0x36, 0x24, 0x3a, 0xd1, 0xdc,
	0xe9, 0x2f, 0x64, 0x26, 0x00, 0xb6, 0x55, 0xc7, 0x69, 0x1d, 0xd8, 0xaa, 0x83, 0xd9, 0x0f, 0x6a,
	0xde, 0xdd, 0xac, 0xb1, 0x27, 0x27, 0x55, 0xcb, 0xc4, 0x52, 0xf8, 0xb5, 0xcf, 0x3c, 0x3f, 0x0a,
	0x04, 0x89, 0x92, 0x9c, 0xaf, 0x54, 0x2b, 0xd5, 0x3b, 0x4a, 0x35, 0xbf, 0x59, 0xae, 0x49, 0x63,
	0x28, 0x05, 0xf3, 0x0f, 0xf2, 0x95, 0x3a, 0x7d, 0xf4, 0x78, 0xa7, 0xa8, 0x54, 0xaa, 0xf5, 0xb2,
	0x7c, 0x3f, 0xbf, 0x21, 0x85, 0xd0, 0x22, 0x20, 0x79, 0xab, 0x78, 0xb7, 0x56, 0x2a, 0x28, 0xc5,
	0xad, 0xcd, 0xed, 0x7c, 0xb1, 0x5e, 0xd9, 0xaa, 0x4a, 0x61, 0x42, 0xb9, 0xb4, 0x55, 0x2d, 0x4b,
	0xf0, 0xda, 0xdf, 0x8d, 0xf3, 0xd8, 0x89, 0x2f, 0xc1, 0x74, 0xd0, 0xe3, 0x66, 0xee, 0xc9, 0xd3,
	0x95, 0x59, 0x92, 0xe5, 0xf7, 0xb4, 0x49, 0xc3, 0x64, 0x21, 0x5f, 0xbc, 0xbb, 0xb3, 0x2d, 0x85,
	0xd2, 0x89, 0x27, 0x4f, 0x57, 0x80, 0x86, 0x16, 0x65, 0x78, 0xfb, 0x2a, 0x7b, 0x17, 0xb3, 0x25,
	0x97, 0xa5, 0x70, 0x7a, 0xf6, 0xc9, 0xd3, 0x95, 0x69, 0xea, 0xc4, 0xc4, 0x51, 0xf4, 0xab, 0x10,
	0xaf, 0x15, 0xd7, 0xca, 0x9b, 0x79, 0xa5, 0xb8, 0x96, 0xaf, 0xde, 0x29, 0x4b, 0xe3, 0xe9, 0xf9,
	0x27, 0x4f, 0x57, 0xa4, 0x6e, 0x24, 0x46, 0x9a, 0xa8, 0x6c, 0x6e, 0x6f, 0xc9, 0x75, 0x29, 0xd2,
	0x69, 0x82, 0x1d, 0x9e, 0x28, 0x0b, 0xc0, 0x6a, 0xdf, 0x2e, 0x97, 0x4b, 0xd2, 0x44, 0x1a, 0x3d,
	0x79, 0xba, 0x92, 0x20, 0xf9, 0x1d, 0x5c, 0x8b, 0x5e, 0x86, 0x99, 0xa2, 0x5c, 0xce, 0xd7, 0xcb,
	0x4a, 0xad, 0x9e, 0xaf, 0xd7, 0xa4, 0xc9, 0xce, 0x48, 0x7c, 0x58, 0x15, 0xe5, 0x20, 0x99, 0xdf,
	0xa9, 0x6f, 0x29, 0x81, 0xb2, 0x53, 0xe9, 0xa5, 0x27, 0x4f, 0x57, 0xe6, 0x48, 0x59, 0xaa, 0xf3,
	0xf8, 0xca, 0xbf, 0x01, 0x52, 0xa0, 0xff, 0xca, 0x9d, 0xa2, 0x14, 0x4d, 0x2f, 0x3e, 0x79, 0xba,
	0x82, 0xba, 0x87, 0x70, 0xa7, 0x48, 0xb6, 0x62, 0xfd, 0xe1, 0x76, 0xb9, 0x54, 0xae, 0x15, 0x95,
	0xe0, 0xb0, 0x63, 0xe9, 0xd4, 0x93, 0xa7, 0x2b, 0xf3, 0xa4, 0x4e, 0xcf, 0xd0, 0x4b, 0x70, 0x55,
	0x2e, 0x6f, 0x6f, 0x54, 0x8a, 0x79, 0xb2, 0x4e, 0x4a, 0xad, 0x2e, 0x97, 0xf3, 0x9b, 0x4a, 0xa5,
	0x7a, 0xa7, 0x5c, 0xa3, 0x0b, 0x07, 0xe9, 0xec, 0x93, 0xa7, 0x2b, 0xd7, 0xd9, 0xb4, 0xfa, 0x7e,
	0x92, 0x3a, 0x78, 0x8b, 0x99, 0x83, 0x64, 0xb5, 0xfc, 0xa0, 0xab, 0xd9, 0xe9, 0xce, 0xc8, 0xba,
	0xf0, 0x23, 0x5a, 0x81, 0xd8, 0x66, 0xe5, 0x8e, 0x4c, 0xdb, 0x94, 0x66, 0xd2, 0xc9, 0x27, 0x4f,
	0x57, 0xe2, 0xa4, 0x9c, 0x87, 0x06, 0x51, 0x05, 0x32, 0x74, 0xae, 0x6a, 0xdb, 0xf9, 0xaa, 0x52,
	0xdc, 0xaa, 0xde, 0xae, 0xdc, 0x51, 0xe4, 0x72, 0x71, 0xab, 0x5a, 0xac, 0x6c, 0x54, 0x58, 0xbd,
	0x78, 0xfa, 0xa5, 0x27, 0x4f, 0x57, 0x56, 0xc4, 0xcc, 0x0d, 0xc4, 0x6e, 0x1f, 0xc1, 0x32, 0x23,
	0x75, 0x6f, 0x83, 0xcd, 0xb9, 0x9f, 0x31, 0x13, 0xe9, 0xeb, 0x4f, 0x9e, 0xae, 0xa4, 0x3d, 0x22,
	0xbd, 0x28, 0xac, 0x00, 0x57, 0xfa, 0xcc, 0xd0, 0xb6, 0xbc, 0x55, 0xda, 0x29, 0x96, 0x65, 0x69,
	0x36, 0xfd, 0xc2, 0x93, 0xa7, 0x2b, 0xd7, 0xfa, 0x4e, 0xd0, 0xb6, 0x6d, 0x69, 0xed, 0x06, 0xb6,
	0xd1, 0x2b, 0x10, 0x97, 0xb7, 0x1e, 0x28, 0x1b, 0xe5, 0xfb, 0xe5, 0x0d, 0xa5, 0x5e, 0xdf, 0x90,
	0xa4, 0x0e, 0x87, 0xf8, 0x30, 0x13, 0x7a, 0x0f, 0x16, 0x58, 0x57, 0xd9, 0x44, 0xd6, 0xcb, 0x1b,
	0xe5, 0xcd, 0x72, 0x5d, 0x7e, 0x28, 0x25, 0x99, 0x37, 0x9a, 0xd7, 0xcd, 0x2e, 0xec, 0x73, 0x13,
	0x12, 0x77, 0xcb, 0x0f, 0x95, 0xfb, 0x95, 0xda, 0x4e, 0x7e, 0xa3, 0xf2, 0x79, 0x59, 0x96, 0x50,
	0x7a, 0xe1, 0xc9, 0xd3, 0x95, 0x24, 0xa9, 0x10, 0x40, 0x37, 0xe8, 0x35, 0x98, 0xdd, 0xde, 0xda,
	0xd8, 0x50, 0xd6, 0xb7, 0x0a, 0x35, 0xce, 0x82, 0x73, 0x9d, 0xb2, 0x01, 0x9c, 0x82, 0xde, 0x02,
	0xc4, 0x18, 0x96, 0xcf, 0xff, 0x4e, 0xb5, 0x5a, 0x96, 0xa5, 0xf9, 0x0e, 0x3b, 0x75, 0xe3, 0x0e,
	0xf4, 0x3e, 0x2c, 0xfa, 0x6b, 0x94, 0xab, 0xf7, 0x45, 0xad, 0x85, 0xe0, 0x08, 0xba, 0x51, 0xc2,
	0x1b, 0x20, 0xf9, 0x2b, 0xd6, 0xf3, 0xb5, 0xbb, 0xd2, 0x62, 0x87, 0xd7, 0x83, 0x70, 0x00, 0xfd,
	0x0e, 0xa4, 0x68, 0x69, 0xf6, 0x0b, 0x8f, 0x74, 0x65, 0xc9, 0x7a, 0xde, 0xaf, 0xd4, 0x1f, 0x4a,
	0x4b, 0xe9, 0x6b, 0x4f, 0x9e, 0xae, 0x2c, 0x8b, 0x5a, 0x3d, 0x2a, 0x3e, 0xfa, 0x00, 0x16, 0xe9,
	0x3b, 0x6d, 0x32, 0xf8, 0x4a, 0xad, 0x5e, 0x29, 0xd6, 0x38, 0x1d, 0x29, 0x95, 0xbe, 0xfa, 0xe4,
	0xe9, 0x0a, 0x0d, 0x89, 0x18, 0x54, 0xd6, 0x19, 0x11, 0xf4, 0x3a, 0xcc, 0x32, 0x39, 0xa1, 0xc8,
	0x5b, 0x1b, 0x1b, 0x44, 0x2a, 0x49, 0xcb, 0x9d, 0x3e, 0x06, 0xb5, 0x6d, 0xb4, 0x0a, 0xc9, 0xb5,
	0x0a, 0x91, 0x4d, 0x0f, 0x15, 0xb9, 0x5c, 0x2f, 0x57, 0x29, 0xbb, 0xa5, 0x3b, 0x73, 0xd7, 0xad,
	0x11, 0xa3, 0xb7, 0x61, 0x6e, 0x63, 0xeb, 0x4e, 0xa5, 0x98, 0xdf, 0x50, 0x7c, 0x0c, 0x27, 0x5d,
	0x49, 0xa7, 0x9f, 0x3c, 0x5d, 0x59, 0x24, 0x55, 0xfa, 0x68, 0xb5, 0x82, 0xb9, 0xb9, 0x4c, 0xd9,
	0xce, 0xcb, 0xf5, 0x4a, 0x9e, 0xf3, 0xb9, 0x74, 0x35, 0xc8, 0xdc, 0x4c, 0xb6, 0x6c, 0xab, 0xb6,
	0xab, 0xab, 0x06, 0x5b, 0xe1, 0x3c, 0x5c, 0xe1, 0x73, 0x58, 0xcf, 0x17, 0x36, 0xca, 0xca, 0x66,
	0xb9, 0x9e, 0x2f, 0xe5, 0xeb, 0x79, 0xa5, 0x98, 0x2f, 0xae, 0x95, 0xa5, 0x6b, 0xcc, 0x85, 0x91,
	0x8a, 0xe4, 0x01, 0x4a, 0x30, 0x59, 0xf2, 0x5a, 0x3d, 0x5f, 0x2d, 0x15, 0xc8, 0x38, 0xf3, 0x25,
	0xa5, 0x5e, 0x53, 0x08, 0x83, 0x95, 0x65, 0xe9, 0x7a, 0x67, 0xc9, 0xfb, 0xe8, 0xb3, 0x84, 0xbb,
	0xfc, 0x0b, 0xa7, 0xdc, 0xde, 0xd8, 0xa9, 0xad, 0x49, 0x99, 0xce, 0x0c, 0xf9, 0x16, 0x8d, 0x69,
	0x9f, 0x39, 0x48, 0xae, 0x6d, 0xd5, 0x15, 0x99, 0x88, 0x97, 0x9a, 0xb2, 0xb1, 0x75, 0xe7, 0x4e,
	0x59, 0x96, 0x56, 0x3a, 0x62, 0xa6, 0x4b, 0xcd, 0x24, 0xc7, 0x03, 0x77, 0xd2, 0x94, 0x5e, 0xe8,
	0x1c, 0x0f, 0x5c, 0x69, 0xec, 0xf8, 0x5e, 0x16, 0xe4, 0x9f, 0xff, 0xf7, 0xeb, 0x63, 0x3f, 0x3f,
	0xbb, 0x1e, 0xfa, 0xc5, 0xd9, 0xf5, 0xd0, 0x5f, 0x9d, 0x5d, 0x0f, 0xfd, 0xb7, 0xb3, 0xeb, 0xa1,
	0x3f, 0xfe, 0xd5, 0xf5, 0xb1, 0x5f, 0xfc, 0xea, 0xfa, 0xd8, 0x5f, 0xfd, 0xea, 0xfa, 0xd8, 0xe7,
	0x6f, 0x8d, 0xa4, 0x62, 0x10, 0xdd, 0x6a, 0x95, 0x29, 0x58, 0xbb, 0x93, 0xd4, 0x15, 0xee, 0xed,
	0xff, 0x1b, 0x00, 0x00, 0xff, 0xff, 0x0d, 0xb5, 0xf9, 0x30, 0x2f, 0x8f, 0x00, 0x00,
}

func (this *BackupEncryptionOptions) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*BackupEncryptionOptions)
	if !ok {
		that2, ok := that.(BackupEncryptionOptions)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if !bytes.Equal(this.Key, that1.Key) {
		return false
	}
	if this.Mode != that1.Mode {
		return false
	}
	if !this.KMSInfo.Equal(that1.KMSInfo) {
		return false
	}
	if this.RawPassphrase != that1.RawPassphrase {
		return false
	}
	if len(this.RawKmsUris) != len(that1.RawKmsUris) {
		return false
	}
	for i := range this.RawKmsUris {
		if this.RawKmsUris[i] != that1.RawKmsUris[i] {
			return false
		}
	}
	return true
}
func (this *BackupEncryptionOptions_KMSInfo) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*BackupEncryptionOptions_KMSInfo)
	if !ok {
		that2, ok := that.(BackupEncryptionOptions_KMSInfo)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if this.Uri != that1.Uri {
		return false
	}
	if !bytes.Equal(this.EncryptedDataKey, that1.EncryptedDataKey) {
		return false
	}
	return true
}
func (this *EncryptionInfo) Equal(that interface{}) bool {
	if that == nil {
		return this == nil
	}

	that1, ok := that.(*EncryptionInfo)
	if !ok {
		that2, ok := that.(EncryptionInfo)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		return this == nil
	} else if this == nil {
		return false
	}
	if this.Scheme != that1.Scheme {
		return false
	}
	if !bytes.Equal(this.Salt, that1.Salt) {
		return false
	}
	if len(this.EncryptedDataKeyByKMSMasterKeyID) != len(that1.EncryptedDataKeyByKMSMasterKeyID) {
		return false
	}
	for i := range this.EncryptedDataKeyByKMSMasterKeyID {
		if !bytes.Equal(this.EncryptedDataKeyByKMSMasterKeyID[i], that1.EncryptedDataKeyByKMSMasterKeyID[i]) {
			return false
		}
	}
	return true
}
func (m *BackupEncryptionOptions) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BackupEncryptionOptions) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *BackupEncryptionOptions) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.RawKmsUris) > 0 {
		for iNdEx := len(m.RawKmsUris) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.RawKmsUris[iNdEx])
			copy(dAtA[i:], m.RawKmsUris[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(m.RawKmsUris[iNdEx])))
			i--
			dAtA[i] = 0x2a
		}
	}
	if len(m.RawPassphrase) > 0 {
		i -= len(m.RawPassphrase)
		copy(dAtA[i:], m.RawPassphrase)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.RawPassphrase)))
		i--
		dAtA[i] = 0x22
	}
	if m.KMSInfo != nil {
		{
			size, err := m.KMSInfo.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1a
	}
	if m.Mode != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Mode))
		i--
		dAtA[i] = 0x10
	}
	if len(m.Key) > 0 {
		i -= len(m.Key)
		copy(dAtA[i:], m.Key)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Key)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *BackupEncryptionOptions_KMSInfo) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BackupEncryptionOptions_KMSInfo) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *BackupEncryptionOptions_KMSInfo) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.EncryptedDataKey) > 0 {
		i -= len(m.EncryptedDataKey)
		copy(dAtA[i:], m.EncryptedDataKey)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.EncryptedDataKey)))
		i--
		dAtA[i] = 0x12
	}
	if len(m.Uri) > 0 {
		i -= len(m.Uri)
		copy(dAtA[i:], m.Uri)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Uri)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *EncryptionInfo) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *EncryptionInfo) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *EncryptionInfo) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.EncryptedDataKeyByKMSMasterKeyID) > 0 {
		keysForEncryptedDataKeyByKMSMasterKeyID := make([]string, 0, len(m.EncryptedDataKeyByKMSMasterKeyID))
		for k := range m.EncryptedDataKeyByKMSMasterKeyID {
			keysForEncryptedDataKeyByKMSMasterKeyID = append(keysForEncryptedDataKeyByKMSMasterKeyID, string(k))
		}
		github_com_gogo_protobuf_sortkeys.Strings(keysForEncryptedDataKeyByKMSMasterKeyID)
		for iNdEx := len(keysForEncryptedDataKeyByKMSMasterKeyID) - 1; iNdEx >= 0; iNdEx-- {
			v := m.EncryptedDataKeyByKMSMasterKeyID[string(keysForEncryptedDataKeyByKMSMasterKeyID[iNdEx])]
			baseI := i
			if len(v) > 0 {
				i -= len(v)
				copy(dAtA[i:], v)
				i = encodeVarintJobs(dAtA, i, uint64(len(v)))
				i--
				dAtA[i] = 0x12
			}
			i -= len(keysForEncryptedDataKeyByKMSMasterKeyID[iNdEx])
			copy(dAtA[i:], keysForEncryptedDataKeyByKMSMasterKeyID[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(keysForEncryptedDataKeyByKMSMasterKeyID[iNdEx])))
			i--
			dAtA[i] = 0xa
			i = encodeVarintJobs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x1a
		}
	}
	if len(m.Salt) > 0 {
		i -= len(m.Salt)
		copy(dAtA[i:], m.Salt)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Salt)))
		i--
		dAtA[i] = 0x12
	}
	if m.Scheme != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Scheme))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *StreamIngestionDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *StreamIngestionDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *StreamIngestionDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	{
		size, err := m.ReadTenantID.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x7a
	{
		size := m.SourceClusterID.Size()
		i -= size
		if _, err := m.SourceClusterID.MarshalTo(dAtA[i:]); err != nil {
			return 0, err
		}
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x72
	{
		size, err := m.SourceTenantID.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x6a
	{
		size, err := m.ReplicationStartTime.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x62
	if m.ReplicationTTLSeconds != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ReplicationTTLSeconds))
		i--
		dAtA[i] = 0x58
	}
	if m.ProtectedTimestampRecordID != nil {
		{
			size := m.ProtectedTimestampRecordID.Size()
			i -= size
			if _, err := m.ProtectedTimestampRecordID.MarshalTo(dAtA[i:]); err != nil {
				return 0, err
			}
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x52
	}
	if len(m.SourceTenantName) > 0 {
		i -= len(m.SourceTenantName)
		copy(dAtA[i:], m.SourceTenantName)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.SourceTenantName)))
		i--
		dAtA[i] = 0x42
	}
	{
		size, err := m.DestinationTenantID.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x3a
	if m.StreamID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.StreamID))
		i--
		dAtA[i] = 0x20
	}
	{
		size, err := m.Span.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	if len(m.SourceClusterConnUri) > 0 {
		i -= len(m.SourceClusterConnUri)
		copy(dAtA[i:], m.SourceClusterConnUri)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.SourceClusterConnUri)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *StreamIngestionCheckpoint) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *StreamIngestionCheckpoint) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *StreamIngestionCheckpoint) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.ResolvedSpans) > 0 {
		for iNdEx := len(m.ResolvedSpans) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ResolvedSpans[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *StreamIngestionProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *StreamIngestionProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *StreamIngestionProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	{
		size, err := m.ReplicatedTimeAtCutover.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x62
	{
		size, err := m.InitialRevertTo.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x5a
	if m.InitialRevertRequired {
		i--
		if m.InitialRevertRequired {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x50
	}
	if m.InitialSplitComplete {
		i--
		if m.InitialSplitComplete {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x48
	}
	if len(m.RemainingCutoverSpans) > 0 {
		for iNdEx := len(m.RemainingCutoverSpans) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.RemainingCutoverSpans[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x42
		}
	}
	{
		size, err := m.ReplicatedTime.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x3a
	if m.ReplicationStatus != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ReplicationStatus))
		i--
		dAtA[i] = 0x30
	}
	if len(m.PartitionConnUris) > 0 {
		for iNdEx := len(m.PartitionConnUris) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.PartitionConnUris[iNdEx])
			copy(dAtA[i:], m.PartitionConnUris[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(m.PartitionConnUris[iNdEx])))
			i--
			dAtA[i] = 0x2a
		}
	}
	{
		size, err := m.Checkpoint.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x22
	{
		size, err := m.CutoverTime.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *HistoryRetentionDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *HistoryRetentionDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *HistoryRetentionDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.ExpirationWindow != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ExpirationWindow))
		i--
		dAtA[i] = 0x20
	}
	{
		size := m.ProtectedTimestampRecordID.Size()
		i -= size
		if _, err := m.ProtectedTimestampRecordID.MarshalTo(dAtA[i:]); err != nil {
			return 0, err
		}
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *HistoryRetentionProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *HistoryRetentionProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *HistoryRetentionProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	n12, err12 := github_com_gogo_protobuf_types.StdTimeMarshalTo(m.LastHeartbeatTime, dAtA[i-github_com_gogo_protobuf_types.SizeOfStdTime(m.LastHeartbeatTime):])
	if err12 != nil {
		return 0, err12
	}
	i -= n12
	i = encodeVarintJobs(dAtA, i, uint64(n12))
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *LogicalReplicationDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *LogicalReplicationDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *LogicalReplicationDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.SkipSchemaCheck {
		i--
		if m.SkipSchemaCheck {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x88
	}
	if len(m.Command) > 0 {
		i -= len(m.Command)
		copy(dAtA[i:], m.Command)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Command)))
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x82
	}
	if m.ParentID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ParentID))
		i--
		dAtA[i] = 0x78
	}
	if len(m.ReverseStreamCommand) > 0 {
		i -= len(m.ReverseStreamCommand)
		copy(dAtA[i:], m.ReverseStreamCommand)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.ReverseStreamCommand)))
		i--
		dAtA[i] = 0x72
	}
	{
		size, err := m.IngestedExternalCatalog.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x6a
	if m.CreateTable {
		i--
		if m.CreateTable {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x60
	}
	if m.Discard != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Discard))
		i--
		dAtA[i] = 0x58
	}
	if len(m.MetricsLabel) > 0 {
		i -= len(m.MetricsLabel)
		copy(dAtA[i:], m.MetricsLabel)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.MetricsLabel)))
		i--
		dAtA[i] = 0x52
	}
	if m.Mode != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Mode))
		i--
		dAtA[i] = 0x48
	}
	{
		size, err := m.DefaultConflictResolution.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x3a
	{
		size := m.SourceClusterID.Size()
		i -= size
		if _, err := m.SourceClusterID.MarshalTo(dAtA[i:]); err != nil {
			return 0, err
		}
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x32
	{
		size, err := m.ReplicationStartTime.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x2a
	if m.StreamID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.StreamID))
		i--
		dAtA[i] = 0x20
	}
	if len(m.ReplicationPairs) > 0 {
		for iNdEx := len(m.ReplicationPairs) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ReplicationPairs[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1a
		}
	}
	if len(m.TableNames) > 0 {
		for iNdEx := len(m.TableNames) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.TableNames[iNdEx])
			copy(dAtA[i:], m.TableNames[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(m.TableNames[iNdEx])))
			i--
			dAtA[i] = 0x12
		}
	}
	if len(m.SourceClusterConnUri) > 0 {
		i -= len(m.SourceClusterConnUri)
		copy(dAtA[i:], m.SourceClusterConnUri)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.SourceClusterConnUri)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *LogicalReplicationDetails_ReplicationPair) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *LogicalReplicationDetails_ReplicationPair) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *LogicalReplicationDetails_ReplicationPair) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.DstFunctionID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.DstFunctionID))
		i--
		dAtA[i] = 0x18
	}
	if m.DstDescriptorID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.DstDescriptorID))
		i--
		dAtA[i] = 0x10
	}
	if m.SrcDescriptorID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.SrcDescriptorID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *LogicalReplicationDetails_DefaultConflictResolution) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *LogicalReplicationDetails_DefaultConflictResolution) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *LogicalReplicationDetails_DefaultConflictResolution) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.FunctionId != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.FunctionId))
		i--
		dAtA[i] = 0x10
	}
	if m.ConflictResolutionType != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ConflictResolutionType))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *LogicalReplicationProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *LogicalReplicationProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *LogicalReplicationProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.StartedReverseStream {
		i--
		if m.StartedReverseStream {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x50
	}
	if m.PublishedNewTables {
		i--
		if m.PublishedNewTables {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x48
	}
	if len(m.PartitionConnUris) > 0 {
		for iNdEx := len(m.PartitionConnUris) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.PartitionConnUris[iNdEx])
			copy(dAtA[i:], m.PartitionConnUris[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(m.PartitionConnUris[iNdEx])))
			i--
			dAtA[i] = 0x42
		}
	}
	{
		size, err := m.Checkpoint.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x32
	{
		size, err := m.ReplicatedTime.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x2a
	return len(dAtA) - i, nil
}

func (m *StreamReplicationDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *StreamReplicationDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *StreamReplicationDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.TableIDs) > 0 {
		l := 0
		for _, e := range m.TableIDs {
			l += sovJobs(uint64(e))
		}
		i -= l
		if l == len(m.TableIDs) {
			dest := dAtA[i : i+len(m.TableIDs)]
			for k, num := range m.TableIDs {
				dest[k] = uint8(num)
			}
		} else {
			j18 := i
			for _, num := range m.TableIDs {
				for num >= 1<<7 {
					dAtA[j18] = uint8(uint64(num)&0x7f | 0x80)
					num >>= 7
					j18++
				}
				dAtA[j18] = uint8(num)
				j18++
			}
		}
		i = encodeVarintJobs(dAtA, i, uint64(uint64(l)))
		i--
		dAtA[i] = 0x2a
	}
	if m.ExpirationWindow != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ExpirationWindow))
		i--
		dAtA[i] = 0x20
	}
	{
		size, err := m.TenantID.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x1a
	{
		size := m.ProtectedTimestampRecordID.Size()
		i -= size
		if _, err := m.ProtectedTimestampRecordID.MarshalTo(dAtA[i:]); err != nil {
			return 0, err
		}
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	if len(m.Spans) > 0 {
		for iNdEx := len(m.Spans) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Spans[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *StreamReplicationProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *StreamReplicationProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *StreamReplicationProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.StreamIngestionStatus != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.StreamIngestionStatus))
		i--
		dAtA[i] = 0x10
	}
	n20, err20 := github_com_gogo_protobuf_types.StdTimeMarshalTo(m.Expiration, dAtA[i-github_com_gogo_protobuf_types.SizeOfStdTime(m.Expiration):])
	if err20 != nil {
		return 0, err20
	}
	i -= n20
	i = encodeVarintJobs(dAtA, i, uint64(n20))
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *SchedulePTSChainingRecord) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchedulePTSChainingRecord) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchedulePTSChainingRecord) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Action != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Action))
		i--
		dAtA[i] = 0x10
	}
	if m.ProtectedTimestampRecord != nil {
		{
			size := m.ProtectedTimestampRecord.Size()
			i -= size
			if _, err := m.ProtectedTimestampRecord.MarshalTo(dAtA[i:]); err != nil {
				return 0, err
			}
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *BackupDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BackupDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *BackupDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Compact {
		i--
		if m.Compact {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xd8
	}
	if m.UpdatesClusterMonitoringMetrics {
		i--
		if m.UpdatesClusterMonitoringMetrics {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xd0
	}
	if m.IncludeAllSecondaryTenants {
		i--
		if m.IncludeAllSecondaryTenants {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xc8
	}
	{
		size, err := m.ExecutionLocality.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x1
	i--
	dAtA[i] = 0xc2
	if len(m.ApplicationName) > 0 {
		i -= len(m.ApplicationName)
		copy(dAtA[i:], m.ApplicationName)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.ApplicationName)))
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xba
	}
	if m.AsOfInterval != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.AsOfInterval))
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xb0
	}
	if m.Detached {
		i--
		if m.Detached {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xa8
	}
	if len(m.RequestedTargets) > 0 {
		for iNdEx := len(m.RequestedTargets) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.RequestedTargets[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0xa2
		}
	}
	if len(m.SpecificTenantIds) > 0 {
		for iNdEx := len(m.SpecificTenantIds) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.SpecificTenantIds[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0x9a
		}
	}
	if len(m.ResolvedCompleteDbs) > 0 {
		l := 0
		for _, e := range m.ResolvedCompleteDbs {
			l += sovJobs(uint64(e))
		}
		i -= l
		if l == len(m.ResolvedCompleteDbs) {
			dest := dAtA[i : i+len(m.ResolvedCompleteDbs)]
			for k, num := range m.ResolvedCompleteDbs {
				dest[k] = uint8(num)
			}
		} else {
			j22 := i
			for _, num := range m.ResolvedCompleteDbs {
				for num >= 1<<7 {
					dAtA[j22] = uint8(uint64(num)&0x7f | 0x80)
					num >>= 7
					j22++
				}
				dAtA[j22] = uint8(num)
				j22++
			}
		}
		i = encodeVarintJobs(dAtA, i, uint64(uint64(l)))
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x92
	}
	if len(m.ResolvedTargets) > 0 {
		for iNdEx := len(m.ResolvedTargets) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ResolvedTargets[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0x8a
		}
	}
	if m.FullCluster {
		i--
		if m.FullCluster {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x78
	}
	if m.RevisionHistory {
		i--
		if m.RevisionHistory {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x68
	}
	if m.ScheduleID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ScheduleID))
		i--
		dAtA[i] = 0x60
	}
	{
		size, err := m.Destination.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x5a
	if m.SchedulePTSChainingRecord != nil {
		{
			size, err := m.SchedulePTSChainingRecord.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x52
	}
	if m.EncryptionInfo != nil {
		{
			size, err := m.EncryptionInfo.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x4a
	}
	if len(m.CollectionURI) > 0 {
		i -= len(m.CollectionURI)
		copy(dAtA[i:], m.CollectionURI)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.CollectionURI)))
		i--
		dAtA[i] = 0x42
	}
	if m.ProtectedTimestampRecord != nil {
		{
			size := m.ProtectedTimestampRecord.Size()
			i -= size
			if _, err := m.ProtectedTimestampRecord.MarshalTo(dAtA[i:]); err != nil {
				return 0, err
			}
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x3a
	}
	if m.EncryptionOptions != nil {
		{
			size, err := m.EncryptionOptions.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x32
	}
	if len(m.URIsByLocalityKV) > 0 {
		keysForURIsByLocalityKV := make([]string, 0, len(m.URIsByLocalityKV))
		for k := range m.URIsByLocalityKV {
			keysForURIsByLocalityKV = append(keysForURIsByLocalityKV, string(k))
		}
		github_com_gogo_protobuf_sortkeys.Strings(keysForURIsByLocalityKV)
		for iNdEx := len(keysForURIsByLocalityKV) - 1; iNdEx >= 0; iNdEx-- {
			v := m.URIsByLocalityKV[string(keysForURIsByLocalityKV[iNdEx])]
			baseI := i
			i -= len(v)
			copy(dAtA[i:], v)
			i = encodeVarintJobs(dAtA, i, uint64(len(v)))
			i--
			dAtA[i] = 0x12
			i -= len(keysForURIsByLocalityKV[iNdEx])
			copy(dAtA[i:], keysForURIsByLocalityKV[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(keysForURIsByLocalityKV[iNdEx])))
			i--
			dAtA[i] = 0xa
			i = encodeVarintJobs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x2a
		}
	}
	if len(m.DeprecatedBackupManifest) > 0 {
		i -= len(m.DeprecatedBackupManifest)
		copy(dAtA[i:], m.DeprecatedBackupManifest)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.DeprecatedBackupManifest)))
		i--
		dAtA[i] = 0x22
	}
	if len(m.URI) > 0 {
		i -= len(m.URI)
		copy(dAtA[i:], m.URI)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.URI)))
		i--
		dAtA[i] = 0x1a
	}
	{
		size, err := m.EndTime.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	{
		size, err := m.StartTime.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *BackupDetails_Destination) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BackupDetails_Destination) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *BackupDetails_Destination) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Exists {
		i--
		if m.Exists {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x20
	}
	if len(m.IncrementalStorage) > 0 {
		for iNdEx := len(m.IncrementalStorage) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.IncrementalStorage[iNdEx])
			copy(dAtA[i:], m.IncrementalStorage[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(m.IncrementalStorage[iNdEx])))
			i--
			dAtA[i] = 0x1a
		}
	}
	if len(m.Subdir) > 0 {
		i -= len(m.Subdir)
		copy(dAtA[i:], m.Subdir)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Subdir)))
		i--
		dAtA[i] = 0x12
	}
	if len(m.To) > 0 {
		for iNdEx := len(m.To) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.To[iNdEx])
			copy(dAtA[i:], m.To[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(m.To[iNdEx])))
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *BackupProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BackupProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *BackupProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *DescriptorRewrite) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *DescriptorRewrite) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *DescriptorRewrite) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.ParentSchemaID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ParentSchemaID))
		i--
		dAtA[i] = 0x28
	}
	if len(m.NewDBName) > 0 {
		i -= len(m.NewDBName)
		copy(dAtA[i:], m.NewDBName)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.NewDBName)))
		i--
		dAtA[i] = 0x22
	}
	if m.ToExisting {
		i--
		if m.ToExisting {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x18
	}
	if m.ParentID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ParentID))
		i--
		dAtA[i] = 0x10
	}
	if m.ID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *RestoreDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *RestoreDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *RestoreDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.ExperimentalCopy {
		i--
		if m.ExperimentalCopy {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xa8
	}
	if m.DownloadJob {
		i--
		if m.DownloadJob {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xa0
	}
	if len(m.PostDownloadTableAutoStatsSettings) > 0 {
		keysForPostDownloadTableAutoStatsSettings := make([]uint32, 0, len(m.PostDownloadTableAutoStatsSettings))
		for k := range m.PostDownloadTableAutoStatsSettings {
			keysForPostDownloadTableAutoStatsSettings = append(keysForPostDownloadTableAutoStatsSettings, uint32(k))
		}
		github_com_gogo_protobuf_sortkeys.Uint32s(keysForPostDownloadTableAutoStatsSettings)
		for iNdEx := len(keysForPostDownloadTableAutoStatsSettings) - 1; iNdEx >= 0; iNdEx-- {
			v := m.PostDownloadTableAutoStatsSettings[uint32(keysForPostDownloadTableAutoStatsSettings[iNdEx])]
			baseI := i
			if v != nil {
				{
					size, err := v.MarshalToSizedBuffer(dAtA[:i])
					if err != nil {
						return 0, err
					}
					i -= size
					i = encodeVarintJobs(dAtA, i, uint64(size))
				}
				i--
				dAtA[i] = 0x12
			}
			i = encodeVarintJobs(dAtA, i, uint64(keysForPostDownloadTableAutoStatsSettings[iNdEx]))
			i--
			dAtA[i] = 0x8
			i = encodeVarintJobs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x2
			i--
			dAtA[i] = 0x9a
		}
	}
	if m.UnsafeRestoreIncompatibleVersion {
		i--
		if m.UnsafeRestoreIncompatibleVersion {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0x90
	}
	if m.RemoveRegions {
		i--
		if m.RemoveRegions {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0x88
	}
	if len(m.DownloadSpans) > 0 {
		for iNdEx := len(m.DownloadSpans) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.DownloadSpans[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x2
			i--
			dAtA[i] = 0x82
		}
	}
	if m.ExperimentalOnline {
		i--
		if m.ExperimentalOnline {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xf8
	}
	{
		size, err := m.ExecutionLocality.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x1
	i--
	dAtA[i] = 0xf2
	if m.SkipLocalitiesCheck {
		i--
		if m.SkipLocalitiesCheck {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xe8
	}
	if m.ProtectedTimestampRecord != nil {
		{
			size := m.ProtectedTimestampRecord.Size()
			i -= size
			if _, err := m.ProtectedTimestampRecord.MarshalTo(dAtA[i:]); err != nil {
				return 0, err
			}
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xe2
	}
	if len(m.FunctionDescs) > 0 {
		for iNdEx := len(m.FunctionDescs) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.FunctionDescs[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0xda
		}
	}
	if m.VerifyData {
		i--
		if m.VerifyData {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xd0
	}
	if m.SchemaOnly {
		i--
		if m.SchemaOnly {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xc8
	}
	if m.PreRewriteTenantId != nil {
		{
			size, err := m.PreRewriteTenantId.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xba
	}
	if m.RestoreSystemUsers {
		i--
		if m.RestoreSystemUsers {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xb0
	}
	if len(m.Tenants) > 0 {
		for iNdEx := len(m.Tenants) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Tenants[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0xaa
		}
	}
	if len(m.DatabaseModifiers) > 0 {
		keysForDatabaseModifiers := make([]uint32, 0, len(m.DatabaseModifiers))
		for k := range m.DatabaseModifiers {
			keysForDatabaseModifiers = append(keysForDatabaseModifiers, uint32(k))
		}
		github_com_gogo_protobuf_sortkeys.Uint32s(keysForDatabaseModifiers)
		for iNdEx := len(keysForDatabaseModifiers) - 1; iNdEx >= 0; iNdEx-- {
			v := m.DatabaseModifiers[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(keysForDatabaseModifiers[iNdEx])]
			baseI := i
			if v != nil {
				{
					size, err := v.MarshalToSizedBuffer(dAtA[:i])
					if err != nil {
						return 0, err
					}
					i -= size
					i = encodeVarintJobs(dAtA, i, uint64(size))
				}
				i--
				dAtA[i] = 0x12
			}
			i = encodeVarintJobs(dAtA, i, uint64(keysForDatabaseModifiers[iNdEx]))
			i--
			dAtA[i] = 0x8
			i = encodeVarintJobs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0x9a
		}
	}
	if len(m.SystemTablesMigrated) > 0 {
		keysForSystemTablesMigrated := make([]string, 0, len(m.SystemTablesMigrated))
		for k := range m.SystemTablesMigrated {
			keysForSystemTablesMigrated = append(keysForSystemTablesMigrated, string(k))
		}
		github_com_gogo_protobuf_sortkeys.Strings(keysForSystemTablesMigrated)
		for iNdEx := len(keysForSystemTablesMigrated) - 1; iNdEx >= 0; iNdEx-- {
			v := m.SystemTablesMigrated[string(keysForSystemTablesMigrated[iNdEx])]
			baseI := i
			i--
			if v {
				dAtA[i] = 1
			} else {
				dAtA[i] = 0
			}
			i--
			dAtA[i] = 0x10
			i -= len(keysForSystemTablesMigrated[iNdEx])
			copy(dAtA[i:], keysForSystemTablesMigrated[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(keysForSystemTablesMigrated[iNdEx])))
			i--
			dAtA[i] = 0xa
			i = encodeVarintJobs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0x8a
		}
	}
	if len(m.DatabaseDescs) > 0 {
		for iNdEx := len(m.DatabaseDescs) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.DatabaseDescs[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0x82
		}
	}
	if len(m.SchemaDescs) > 0 {
		for iNdEx := len(m.SchemaDescs) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.SchemaDescs[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x7a
		}
	}
	if len(m.TypeDescs) > 0 {
		for iNdEx := len(m.TypeDescs) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.TypeDescs[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x72
		}
	}
	if m.Encryption != nil {
		{
			size, err := m.Encryption.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x62
	}
	if m.DescriptorCoverage != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.DescriptorCoverage))
		i--
		dAtA[i] = 0x58
	}
	if m.DescriptorsPublished {
		i--
		if m.DescriptorsPublished {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x50
	}
	if m.StatsInserted {
		i--
		if m.StatsInserted {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x48
	}
	if m.PrepareCompleted {
		i--
		if m.PrepareCompleted {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x40
	}
	if len(m.BackupLocalityInfo) > 0 {
		for iNdEx := len(m.BackupLocalityInfo) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.BackupLocalityInfo[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x3a
		}
	}
	if len(m.OverrideDB) > 0 {
		i -= len(m.OverrideDB)
		copy(dAtA[i:], m.OverrideDB)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.OverrideDB)))
		i--
		dAtA[i] = 0x32
	}
	if len(m.TableDescs) > 0 {
		for iNdEx := len(m.TableDescs) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.TableDescs[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x2a
		}
	}
	{
		size, err := m.EndTime.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x22
	if len(m.URIs) > 0 {
		for iNdEx := len(m.URIs) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.URIs[iNdEx])
			copy(dAtA[i:], m.URIs[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(m.URIs[iNdEx])))
			i--
			dAtA[i] = 0x1a
		}
	}
	if len(m.DescriptorRewrites) > 0 {
		keysForDescriptorRewrites := make([]uint32, 0, len(m.DescriptorRewrites))
		for k := range m.DescriptorRewrites {
			keysForDescriptorRewrites = append(keysForDescriptorRewrites, uint32(k))
		}
		github_com_gogo_protobuf_sortkeys.Uint32s(keysForDescriptorRewrites)
		for iNdEx := len(keysForDescriptorRewrites) - 1; iNdEx >= 0; iNdEx-- {
			v := m.DescriptorRewrites[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(keysForDescriptorRewrites[iNdEx])]
			baseI := i
			if v != nil {
				{
					size, err := v.MarshalToSizedBuffer(dAtA[:i])
					if err != nil {
						return 0, err
					}
					i -= size
					i = encodeVarintJobs(dAtA, i, uint64(size))
				}
				i--
				dAtA[i] = 0x12
			}
			i = encodeVarintJobs(dAtA, i, uint64(keysForDescriptorRewrites[iNdEx]))
			i--
			dAtA[i] = 0x8
			i = encodeVarintJobs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x12
		}
	}
	return len(dAtA) - i, nil
}

func (m *RestoreDetails_BackupLocalityInfo) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *RestoreDetails_BackupLocalityInfo) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *RestoreDetails_BackupLocalityInfo) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.URIsByOriginalLocalityKV) > 0 {
		keysForURIsByOriginalLocalityKV := make([]string, 0, len(m.URIsByOriginalLocalityKV))
		for k := range m.URIsByOriginalLocalityKV {
			keysForURIsByOriginalLocalityKV = append(keysForURIsByOriginalLocalityKV, string(k))
		}
		github_com_gogo_protobuf_sortkeys.Strings(keysForURIsByOriginalLocalityKV)
		for iNdEx := len(keysForURIsByOriginalLocalityKV) - 1; iNdEx >= 0; iNdEx-- {
			v := m.URIsByOriginalLocalityKV[string(keysForURIsByOriginalLocalityKV[iNdEx])]
			baseI := i
			i -= len(v)
			copy(dAtA[i:], v)
			i = encodeVarintJobs(dAtA, i, uint64(len(v)))
			i--
			dAtA[i] = 0x12
			i -= len(keysForURIsByOriginalLocalityKV[iNdEx])
			copy(dAtA[i:], keysForURIsByOriginalLocalityKV[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(keysForURIsByOriginalLocalityKV[iNdEx])))
			i--
			dAtA[i] = 0xa
			i = encodeVarintJobs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *RestoreDetails_DatabaseModifier) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *RestoreDetails_DatabaseModifier) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *RestoreDetails_DatabaseModifier) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.RegionConfig != nil {
		{
			size, err := m.RegionConfig.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x12
	}
	if len(m.ExtraTypeDescs) > 0 {
		for iNdEx := len(m.ExtraTypeDescs) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ExtraTypeDescs[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *RestoreProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *RestoreProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *RestoreProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.TotalDownloadRequired != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.TotalDownloadRequired))
		i--
		dAtA[i] = 0x18
	}
	if len(m.Checkpoint) > 0 {
		for iNdEx := len(m.Checkpoint) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Checkpoint[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x12
		}
	}
	if len(m.HighWater) > 0 {
		i -= len(m.HighWater)
		copy(dAtA[i:], m.HighWater)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.HighWater)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *RestoreProgress_FrontierEntry) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *RestoreProgress_FrontierEntry) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *RestoreProgress_FrontierEntry) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	{
		size, err := m.Timestamp.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	{
		size, err := m.Span.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *ImportDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ImportDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ImportDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.DatabasePrimaryRegion) > 0 {
		i -= len(m.DatabasePrimaryRegion)
		copy(dAtA[i:], m.DatabasePrimaryRegion)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.DatabasePrimaryRegion)))
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xda
	}
	if len(m.Types) > 0 {
		for iNdEx := len(m.Types) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Types[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0xd2
		}
	}
	if m.TablesPublished {
		i--
		if m.TablesPublished {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x68
	}
	if m.PrepareComplete {
		i--
		if m.PrepareComplete {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x60
	}
	if m.ParentID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ParentID))
		i--
		dAtA[i] = 0x30
	}
	if m.Walltime != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Walltime))
		i--
		dAtA[i] = 0x28
	}
	{
		size, err := m.Format.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x1a
	if len(m.URIs) > 0 {
		for iNdEx := len(m.URIs) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.URIs[iNdEx])
			copy(dAtA[i:], m.URIs[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(m.URIs[iNdEx])))
			i--
			dAtA[i] = 0x12
		}
	}
	if len(m.Tables) > 0 {
		for iNdEx := len(m.Tables) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Tables[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *ImportDetails_Table) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ImportDetails_Table) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ImportDetails_Table) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.WasEmpty {
		i--
		if m.WasEmpty {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xb0
	}
	if len(m.TargetCols) > 0 {
		for iNdEx := len(m.TargetCols) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.TargetCols[iNdEx])
			copy(dAtA[i:], m.TargetCols[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(m.TargetCols[iNdEx])))
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0xaa
		}
	}
	if m.SeqVal != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.SeqVal))
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x98
	}
	if len(m.Name) > 0 {
		i -= len(m.Name)
		copy(dAtA[i:], m.Name)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Name)))
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x92
	}
	if m.Desc != nil {
		{
			size, err := m.Desc.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *ImportDetails_Type) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ImportDetails_Type) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ImportDetails_Type) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Desc != nil {
		{
			size, err := m.Desc.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *SequenceValChunk) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SequenceValChunk) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SequenceValChunk) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.NextChunkStartRow != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.NextChunkStartRow))
		i--
		dAtA[i] = 0x20
	}
	if m.ChunkStartRow != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ChunkStartRow))
		i--
		dAtA[i] = 0x18
	}
	if m.ChunkSize != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ChunkSize))
		i--
		dAtA[i] = 0x10
	}
	if m.ChunkStartVal != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ChunkStartVal))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *SequenceDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SequenceDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SequenceDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.SeqIdToChunks) > 0 {
		keysForSeqIdToChunks := make([]int32, 0, len(m.SeqIdToChunks))
		for k := range m.SeqIdToChunks {
			keysForSeqIdToChunks = append(keysForSeqIdToChunks, int32(k))
		}
		github_com_gogo_protobuf_sortkeys.Int32s(keysForSeqIdToChunks)
		for iNdEx := len(keysForSeqIdToChunks) - 1; iNdEx >= 0; iNdEx-- {
			v := m.SeqIdToChunks[int32(keysForSeqIdToChunks[iNdEx])]
			baseI := i
			if v != nil {
				{
					size, err := v.MarshalToSizedBuffer(dAtA[:i])
					if err != nil {
						return 0, err
					}
					i -= size
					i = encodeVarintJobs(dAtA, i, uint64(size))
				}
				i--
				dAtA[i] = 0x12
			}
			i = encodeVarintJobs(dAtA, i, uint64(keysForSeqIdToChunks[iNdEx]))
			i--
			dAtA[i] = 0x8
			i = encodeVarintJobs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *SequenceDetails_SequenceChunks) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SequenceDetails_SequenceChunks) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SequenceDetails_SequenceChunks) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Chunks) > 0 {
		for iNdEx := len(m.Chunks) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Chunks[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *ImportProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ImportProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ImportProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	{
		size, err := m.Summary.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x3a
	if len(m.SequenceDetails) > 0 {
		for iNdEx := len(m.SequenceDetails) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.SequenceDetails[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x32
		}
	}
	if len(m.ResumePos) > 0 {
		l := 0
		for _, e := range m.ResumePos {
			l += sovJobs(uint64(e))
		}
		i -= l
		if l == len(m.ResumePos) {
			dest := dAtA[i : i+len(m.ResumePos)]
			for k, num := range m.ResumePos {
				dest[k] = uint8(num)
			}
		} else {
			j44 := i
			for _, num1 := range m.ResumePos {
				num := uint64(num1)
				for num >= 1<<7 {
					dAtA[j44] = uint8(uint64(num)&0x7f | 0x80)
					num >>= 7
					j44++
				}
				dAtA[j44] = uint8(num)
				j44++
			}
		}
		i = encodeVarintJobs(dAtA, i, uint64(uint64(l)))
		i--
		dAtA[i] = 0x2a
	}
	if len(m.SpanProgress) > 0 {
		for iNdEx := len(m.SpanProgress) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.SpanProgress[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x22
		}
	}
	if len(m.WriteProgress) > 0 {
		for iNdEx := len(m.WriteProgress) - 1; iNdEx >= 0; iNdEx-- {
			f45 := math.Float32bits(float32(m.WriteProgress[iNdEx]))
			i -= 4
			encoding_binary.LittleEndian.PutUint32(dAtA[i:], uint32(f45))
		}
		i = encodeVarintJobs(dAtA, i, uint64(len(m.WriteProgress)*4))
		i--
		dAtA[i] = 0x1a
	}
	if len(m.ReadProgress) > 0 {
		for iNdEx := len(m.ReadProgress) - 1; iNdEx >= 0; iNdEx-- {
			f46 := math.Float32bits(float32(m.ReadProgress[iNdEx]))
			i -= 4
			encoding_binary.LittleEndian.PutUint32(dAtA[i:], uint32(f46))
		}
		i = encodeVarintJobs(dAtA, i, uint64(len(m.ReadProgress)*4))
		i--
		dAtA[i] = 0x12
	}
	if len(m.SamplingProgress) > 0 {
		for iNdEx := len(m.SamplingProgress) - 1; iNdEx >= 0; iNdEx-- {
			f47 := math.Float32bits(float32(m.SamplingProgress[iNdEx]))
			i -= 4
			encoding_binary.LittleEndian.PutUint32(dAtA[i:], uint32(f47))
		}
		i = encodeVarintJobs(dAtA, i, uint64(len(m.SamplingProgress)*4))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *TypeSchemaChangeDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TypeSchemaChangeDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *TypeSchemaChangeDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.TransitioningMembers) > 0 {
		for iNdEx := len(m.TransitioningMembers) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.TransitioningMembers[iNdEx])
			copy(dAtA[i:], m.TransitioningMembers[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(m.TransitioningMembers[iNdEx])))
			i--
			dAtA[i] = 0x12
		}
	}
	if m.TypeID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.TypeID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *TypeSchemaChangeProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TypeSchemaChangeProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *TypeSchemaChangeProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *NewSchemaChangeDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NewSchemaChangeDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *NewSchemaChangeDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.ProtectedTimestampRecord != nil {
		{
			size := m.ProtectedTimestampRecord.Size()
			i -= size
			if _, err := m.ProtectedTimestampRecord.MarshalTo(dAtA[i:]); err != nil {
				return 0, err
			}
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x3a
	}
	if len(m.MergeProgress) > 0 {
		for iNdEx := len(m.MergeProgress) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.MergeProgress[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x32
		}
	}
	if len(m.BackfillProgress) > 0 {
		for iNdEx := len(m.BackfillProgress) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.BackfillProgress[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x22
		}
	}
	return len(dAtA) - i, nil
}

func (m *BackfillProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BackfillProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *BackfillProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.CompletedSpans) > 0 {
		for iNdEx := len(m.CompletedSpans) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.CompletedSpans[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x2a
		}
	}
	{
		size, err := m.WriteTimestamp.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x22
	if len(m.DestIndexIDs) > 0 {
		l := 0
		for _, e := range m.DestIndexIDs {
			l += sovJobs(uint64(e))
		}
		i -= l
		if l == len(m.DestIndexIDs) {
			dest := dAtA[i : i+len(m.DestIndexIDs)]
			for k, num := range m.DestIndexIDs {
				dest[k] = uint8(num)
			}
		} else {
			j49 := i
			for _, num := range m.DestIndexIDs {
				for num >= 1<<7 {
					dAtA[j49] = uint8(uint64(num)&0x7f | 0x80)
					num >>= 7
					j49++
				}
				dAtA[j49] = uint8(num)
				j49++
			}
		}
		i = encodeVarintJobs(dAtA, i, uint64(uint64(l)))
		i--
		dAtA[i] = 0x1a
	}
	if m.SourceIndexID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.SourceIndexID))
		i--
		dAtA[i] = 0x10
	}
	if m.TableID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.TableID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *MergeProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MergeProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *MergeProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.MergePairs) > 0 {
		for iNdEx := len(m.MergePairs) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.MergePairs[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x12
		}
	}
	if m.TableID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.TableID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *MergeProgress_MergePair) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MergeProgress_MergePair) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *MergeProgress_MergePair) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.CompletedSpans) > 0 {
		for iNdEx := len(m.CompletedSpans) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.CompletedSpans[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x22
		}
	}
	if m.DestIndexID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.DestIndexID))
		i--
		dAtA[i] = 0x18
	}
	if m.SourceIndexID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.SourceIndexID))
		i--
		dAtA[i] = 0x10
	}
	return len(dAtA) - i, nil
}

func (m *NewSchemaChangeProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NewSchemaChangeProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *NewSchemaChangeProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *AutoSpanConfigReconciliationDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoSpanConfigReconciliationDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoSpanConfigReconciliationDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *AutoSpanConfigReconciliationProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoSpanConfigReconciliationProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoSpanConfigReconciliationProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	{
		size, err := m.Checkpoint.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *KeyVisualizerDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *KeyVisualizerDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *KeyVisualizerDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *KeyVisualizerProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *KeyVisualizerProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *KeyVisualizerProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *ResumeSpanList) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ResumeSpanList) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ResumeSpanList) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.ResumeSpans) > 0 {
		for iNdEx := len(m.ResumeSpans) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ResumeSpans[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *DroppedTableDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *DroppedTableDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *DroppedTableDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Status != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Status))
		i--
		dAtA[i] = 0x18
	}
	if m.ID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ID))
		i--
		dAtA[i] = 0x10
	}
	if len(m.Name) > 0 {
		i -= len(m.Name)
		copy(dAtA[i:], m.Name)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Name)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *SchemaChangeGCDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaChangeGCDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaChangeGCDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Tenant != nil {
		{
			size, err := m.Tenant.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x32
	}
	if m.ParentID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ParentID))
		i--
		dAtA[i] = 0x18
	}
	if len(m.Tables) > 0 {
		for iNdEx := len(m.Tables) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Tables[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x12
		}
	}
	if len(m.Indexes) > 0 {
		for iNdEx := len(m.Indexes) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Indexes[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *SchemaChangeGCDetails_DroppedIndex) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaChangeGCDetails_DroppedIndex) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaChangeGCDetails_DroppedIndex) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.DropTime != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.DropTime))
		i--
		dAtA[i] = 0x10
	}
	if m.IndexID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.IndexID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *SchemaChangeGCDetails_DroppedID) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaChangeGCDetails_DroppedID) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaChangeGCDetails_DroppedID) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.DropTime != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.DropTime))
		i--
		dAtA[i] = 0x10
	}
	if m.ID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *SchemaChangeGCDetails_DroppedTenant) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaChangeGCDetails_DroppedTenant) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaChangeGCDetails_DroppedTenant) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.DropTime != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.DropTime))
		i--
		dAtA[i] = 0x10
	}
	if m.ID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *SchemaChangeDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaChangeDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaChangeDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.SessionData != nil {
		{
			size, err := m.SessionData.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x6a
	}
	if len(m.DroppedFunctions) > 0 {
		l := 0
		for _, e := range m.DroppedFunctions {
			l += sovJobs(uint64(e))
		}
		i -= l
		if l == len(m.DroppedFunctions) {
			dest := dAtA[i : i+len(m.DroppedFunctions)]
			for k, num := range m.DroppedFunctions {
				dest[k] = uint8(num)
			}
		} else {
			j53 := i
			for _, num := range m.DroppedFunctions {
				for num >= 1<<7 {
					dAtA[j53] = uint8(uint64(num)&0x7f | 0x80)
					num >>= 7
					j53++
				}
				dAtA[j53] = uint8(num)
				j53++
			}
		}
		i = encodeVarintJobs(dAtA, i, uint64(uint64(l)))
		i--
		dAtA[i] = 0x62
	}
	if m.ProtectedTimestampRecord != nil {
		{
			size := m.ProtectedTimestampRecord.Size()
			i -= size
			if _, err := m.ProtectedTimestampRecord.MarshalTo(dAtA[i:]); err != nil {
				return 0, err
			}
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x5a
	}
	{
		size, err := m.WriteTimestamp.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x52
	if len(m.DroppedSchemas) > 0 {
		l := 0
		for _, e := range m.DroppedSchemas {
			l += sovJobs(uint64(e))
		}
		i -= l
		if l == len(m.DroppedSchemas) {
			dest := dAtA[i : i+len(m.DroppedSchemas)]
			for k, num := range m.DroppedSchemas {
				dest[k] = uint8(num)
			}
		} else {
			j55 := i
			for _, num := range m.DroppedSchemas {
				for num >= 1<<7 {
					dAtA[j55] = uint8(uint64(num)&0x7f | 0x80)
					num >>= 7
					j55++
				}
				dAtA[j55] = uint8(num)
				j55++
			}
		}
		i = encodeVarintJobs(dAtA, i, uint64(uint64(l)))
		i--
		dAtA[i] = 0x4a
	}
	if len(m.DroppedTypes) > 0 {
		l := 0
		for _, e := range m.DroppedTypes {
			l += sovJobs(uint64(e))
		}
		i -= l
		if l == len(m.DroppedTypes) {
			dest := dAtA[i : i+len(m.DroppedTypes)]
			for k, num := range m.DroppedTypes {
				dest[k] = uint8(num)
			}
		} else {
			j56 := i
			for _, num := range m.DroppedTypes {
				for num >= 1<<7 {
					dAtA[j56] = uint8(uint64(num)&0x7f | 0x80)
					num >>= 7
					j56++
				}
				dAtA[j56] = uint8(num)
				j56++
			}
		}
		i = encodeVarintJobs(dAtA, i, uint64(uint64(l)))
		i--
		dAtA[i] = 0x42
	}
	if m.FormatVersion != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.FormatVersion))
		i--
		dAtA[i] = 0x38
	}
	if m.TableMutationID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.TableMutationID))
		i--
		dAtA[i] = 0x30
	}
	if m.DescID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.DescID))
		i--
		dAtA[i] = 0x28
	}
	if m.DroppedDatabaseID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.DroppedDatabaseID))
		i--
		dAtA[i] = 0x20
	}
	if len(m.DroppedTables) > 0 {
		for iNdEx := len(m.DroppedTables) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.DroppedTables[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1a
		}
	}
	if len(m.ResumeSpanList) > 0 {
		for iNdEx := len(m.ResumeSpanList) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ResumeSpanList[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x12
		}
	}
	return len(dAtA) - i, nil
}

func (m *SchemaChangeProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaChangeProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaChangeProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *SchemaChangeGCProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaChangeGCProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaChangeGCProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.RangesUnsplitDone {
		i--
		if m.RangesUnsplitDone {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x20
	}
	if m.Tenant != nil {
		{
			size, err := m.Tenant.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1a
	}
	if len(m.Tables) > 0 {
		for iNdEx := len(m.Tables) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Tables[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x12
		}
	}
	if len(m.Indexes) > 0 {
		for iNdEx := len(m.Indexes) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Indexes[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *SchemaChangeGCProgress_IndexProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaChangeGCProgress_IndexProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaChangeGCProgress_IndexProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Status != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Status))
		i--
		dAtA[i] = 0x10
	}
	if m.IndexID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.IndexID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *SchemaChangeGCProgress_TableProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaChangeGCProgress_TableProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaChangeGCProgress_TableProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Status != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Status))
		i--
		dAtA[i] = 0x10
	}
	if m.ID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *SchemaChangeGCProgress_TenantProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaChangeGCProgress_TenantProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaChangeGCProgress_TenantProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Status != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Status))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *ChangefeedTargetTable) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ChangefeedTargetTable) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ChangefeedTargetTable) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.StatementTimeName) > 0 {
		i -= len(m.StatementTimeName)
		copy(dAtA[i:], m.StatementTimeName)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.StatementTimeName)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *ChangefeedTargetSpecification) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ChangefeedTargetSpecification) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ChangefeedTargetSpecification) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.StatementTimeName) > 0 {
		i -= len(m.StatementTimeName)
		copy(dAtA[i:], m.StatementTimeName)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.StatementTimeName)))
		i--
		dAtA[i] = 0x22
	}
	if len(m.FamilyName) > 0 {
		i -= len(m.FamilyName)
		copy(dAtA[i:], m.FamilyName)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.FamilyName)))
		i--
		dAtA[i] = 0x1a
	}
	if m.DescID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.DescID))
		i--
		dAtA[i] = 0x10
	}
	if m.Type != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Type))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *ChangefeedDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ChangefeedDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ChangefeedDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.SessionData != nil {
		{
			size, err := m.SessionData.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x5a
	}
	if len(m.Select) > 0 {
		i -= len(m.Select)
		copy(dAtA[i:], m.Select)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Select)))
		i--
		dAtA[i] = 0x52
	}
	{
		size, err := m.EndTime.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x4a
	if len(m.TargetSpecifications) > 0 {
		for iNdEx := len(m.TargetSpecifications) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.TargetSpecifications[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x42
		}
	}
	{
		size, err := m.StatementTime.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x3a
	if len(m.Tables) > 0 {
		keysForTables := make([]uint32, 0, len(m.Tables))
		for k := range m.Tables {
			keysForTables = append(keysForTables, uint32(k))
		}
		github_com_gogo_protobuf_sortkeys.Uint32s(keysForTables)
		for iNdEx := len(keysForTables) - 1; iNdEx >= 0; iNdEx-- {
			v := m.Tables[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(keysForTables[iNdEx])]
			baseI := i
			{
				size, err := (&v).MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x12
			i = encodeVarintJobs(dAtA, i, uint64(keysForTables[iNdEx]))
			i--
			dAtA[i] = 0x8
			i = encodeVarintJobs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x32
		}
	}
	if len(m.Opts) > 0 {
		keysForOpts := make([]string, 0, len(m.Opts))
		for k := range m.Opts {
			keysForOpts = append(keysForOpts, string(k))
		}
		github_com_gogo_protobuf_sortkeys.Strings(keysForOpts)
		for iNdEx := len(keysForOpts) - 1; iNdEx >= 0; iNdEx-- {
			v := m.Opts[string(keysForOpts[iNdEx])]
			baseI := i
			i -= len(v)
			copy(dAtA[i:], v)
			i = encodeVarintJobs(dAtA, i, uint64(len(v)))
			i--
			dAtA[i] = 0x12
			i -= len(keysForOpts[iNdEx])
			copy(dAtA[i:], keysForOpts[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(keysForOpts[iNdEx])))
			i--
			dAtA[i] = 0xa
			i = encodeVarintJobs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x22
		}
	}
	if len(m.SinkURI) > 0 {
		i -= len(m.SinkURI)
		copy(dAtA[i:], m.SinkURI)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.SinkURI)))
		i--
		dAtA[i] = 0x1a
	}
	return len(dAtA) - i, nil
}

func (m *ResolvedSpan) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ResolvedSpan) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ResolvedSpan) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.BoundaryType != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.BoundaryType))
		i--
		dAtA[i] = 0x20
	}
	{
		size, err := m.Timestamp.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	{
		size, err := m.Span.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *ResolvedSpans) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ResolvedSpans) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ResolvedSpans) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	{
		size, err := m.Stats.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	if len(m.ResolvedSpans) > 0 {
		for iNdEx := len(m.ResolvedSpans) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ResolvedSpans[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *ResolvedSpans_Stats) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ResolvedSpans_Stats) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ResolvedSpans_Stats) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.RecentKvCount != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.RecentKvCount))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *TimestampSpansMap) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TimestampSpansMap) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *TimestampSpansMap) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Entries) > 0 {
		for iNdEx := len(m.Entries) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Entries[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *TimestampSpansMap_Entry) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TimestampSpansMap_Entry) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *TimestampSpansMap_Entry) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Spans) > 0 {
		for iNdEx := len(m.Spans) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Spans[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x12
		}
	}
	{
		size, err := m.Timestamp.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *ChangefeedProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ChangefeedProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ChangefeedProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.SpanLevelCheckpoint != nil {
		{
			size, err := m.SpanLevelCheckpoint.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2a
	}
	{
		size := m.ProtectedTimestampRecord.Size()
		i -= size
		if _, err := m.ProtectedTimestampRecord.MarshalTo(dAtA[i:]); err != nil {
			return 0, err
		}
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x1a
	return len(dAtA) - i, nil
}

func (m *CreateStatsDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *CreateStatsDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *CreateStatsDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.WhereIndexID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.WhereIndexID))
		i--
		dAtA[i] = 0x60
	}
	if len(m.WhereSpans) > 0 {
		for iNdEx := len(m.WhereSpans) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.WhereSpans[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x5a
		}
	}
	if len(m.WhereClause) > 0 {
		i -= len(m.WhereClause)
		copy(dAtA[i:], m.WhereClause)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.WhereClause)))
		i--
		dAtA[i] = 0x52
	}
	if m.UsingExtremes {
		i--
		if m.UsingExtremes {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x48
	}
	if m.DeleteOtherStats {
		i--
		if m.DeleteOtherStats {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x40
	}
	if m.MaxFractionIdle != 0 {
		i -= 8
		encoding_binary.LittleEndian.PutUint64(dAtA[i:], uint64(math.Float64bits(float64(m.MaxFractionIdle))))
		i--
		dAtA[i] = 0x39
	}
	if len(m.FQTableName) > 0 {
		i -= len(m.FQTableName)
		copy(dAtA[i:], m.FQTableName)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.FQTableName)))
		i--
		dAtA[i] = 0x32
	}
	if m.AsOf != nil {
		{
			size, err := m.AsOf.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2a
	}
	if len(m.Statement) > 0 {
		i -= len(m.Statement)
		copy(dAtA[i:], m.Statement)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Statement)))
		i--
		dAtA[i] = 0x22
	}
	if len(m.ColumnStats) > 0 {
		for iNdEx := len(m.ColumnStats) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ColumnStats[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1a
		}
	}
	{
		size, err := m.Table.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	if len(m.Name) > 0 {
		i -= len(m.Name)
		copy(dAtA[i:], m.Name)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Name)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *CreateStatsDetails_ColStat) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *CreateStatsDetails_ColStat) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *CreateStatsDetails_ColStat) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.HistogramMaxBuckets != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.HistogramMaxBuckets))
		i--
		dAtA[i] = 0x20
	}
	if m.Inverted {
		i--
		if m.Inverted {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x18
	}
	if m.HasHistogram {
		i--
		if m.HasHistogram {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x10
	}
	if len(m.ColumnIDs) > 0 {
		l := 0
		for _, e := range m.ColumnIDs {
			l += sovJobs(uint64(e))
		}
		i -= l
		if l == len(m.ColumnIDs) {
			dest := dAtA[i : i+len(m.ColumnIDs)]
			for k, num := range m.ColumnIDs {
				dest[k] = uint8(num)
			}
		} else {
			j69 := i
			for _, num := range m.ColumnIDs {
				for num >= 1<<7 {
					dAtA[j69] = uint8(uint64(num)&0x7f | 0x80)
					num >>= 7
					j69++
				}
				dAtA[j69] = uint8(num)
				j69++
			}
		}
		i = encodeVarintJobs(dAtA, i, uint64(uint64(l)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *CreateStatsProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *CreateStatsProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *CreateStatsProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *MigrationDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MigrationDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *MigrationDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.ClusterVersion != nil {
		{
			size, err := m.ClusterVersion.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *MigrationProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MigrationProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *MigrationProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Watermark) > 0 {
		i -= len(m.Watermark)
		copy(dAtA[i:], m.Watermark)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Watermark)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *AutoSQLStatsCompactionDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoSQLStatsCompactionDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoSQLStatsCompactionDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *AutoSQLStatsCompactionProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoSQLStatsCompactionProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoSQLStatsCompactionProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *RowLevelTTLDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *RowLevelTTLDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *RowLevelTTLDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.TableVersion != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.TableVersion))
		i--
		dAtA[i] = 0x18
	}
	n71, err71 := github_com_gogo_protobuf_types.StdTimeMarshalTo(m.Cutoff, dAtA[i-github_com_gogo_protobuf_types.SizeOfStdTime(m.Cutoff):])
	if err71 != nil {
		return 0, err71
	}
	i -= n71
	i = encodeVarintJobs(dAtA, i, uint64(n71))
	i--
	dAtA[i] = 0x12
	if m.TableID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.TableID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *RowLevelTTLProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *RowLevelTTLProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *RowLevelTTLProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.JobProcessedSpanCount != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.JobProcessedSpanCount))
		i--
		dAtA[i] = 0x28
	}
	if m.JobTotalSpanCount != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.JobTotalSpanCount))
		i--
		dAtA[i] = 0x20
	}
	if len(m.ProcessorProgresses) > 0 {
		for iNdEx := len(m.ProcessorProgresses) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ProcessorProgresses[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x12
		}
	}
	if m.JobDeletedRowCount != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.JobDeletedRowCount))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *RowLevelTTLProcessorProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *RowLevelTTLProcessorProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *RowLevelTTLProcessorProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.ProcessedSpanCount != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ProcessedSpanCount))
		i--
		dAtA[i] = 0x30
	}
	if m.ProcessorConcurrency != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ProcessorConcurrency))
		i--
		dAtA[i] = 0x28
	}
	if m.TotalSpanCount != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.TotalSpanCount))
		i--
		dAtA[i] = 0x20
	}
	if m.DeletedRowCount != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.DeletedRowCount))
		i--
		dAtA[i] = 0x18
	}
	if m.SQLInstanceID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.SQLInstanceID))
		i--
		dAtA[i] = 0x10
	}
	if m.ProcessorID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ProcessorID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *SchemaTelemetryDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaTelemetryDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaTelemetryDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *SchemaTelemetryProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SchemaTelemetryProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SchemaTelemetryProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *PollJobsStatsDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *PollJobsStatsDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *PollJobsStatsDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *PollJobsStatsProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *PollJobsStatsProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *PollJobsStatsProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *AutoConfigRunnerDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoConfigRunnerDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoConfigRunnerDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *AutoConfigRunnerProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoConfigRunnerProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoConfigRunnerProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *AutoConfigEnvRunnerDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoConfigEnvRunnerDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoConfigEnvRunnerDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *AutoConfigEnvRunnerProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoConfigEnvRunnerProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoConfigEnvRunnerProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *AutoConfigTaskDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoConfigTaskDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoConfigTaskDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *AutoConfigTaskProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoConfigTaskProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoConfigTaskProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *AutoUpdateSQLActivityDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoUpdateSQLActivityDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoUpdateSQLActivityDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *AutoUpdateSQLActivityProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AutoUpdateSQLActivityProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AutoUpdateSQLActivityProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *MVCCStatisticsJobDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MVCCStatisticsJobDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *MVCCStatisticsJobDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *MVCCStatisticsJobProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MVCCStatisticsJobProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *MVCCStatisticsJobProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *StandbyReadTSPollerDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *StandbyReadTSPollerDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *StandbyReadTSPollerDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *StandbyReadTSPollerProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *StandbyReadTSPollerProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *StandbyReadTSPollerProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *HotRangesLoggerDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *HotRangesLoggerDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *HotRangesLoggerDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *InspectDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InspectDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InspectDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	{
		size, err := m.AsOf.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	if len(m.Checks) > 0 {
		for iNdEx := len(m.Checks) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Checks[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *InspectDetails_Check) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InspectDetails_Check) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InspectDetails_Check) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.IndexID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.IndexID))
		i--
		dAtA[i] = 0x18
	}
	if m.TableID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.TableID))
		i--
		dAtA[i] = 0x10
	}
	if m.Type != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Type))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *UpdateTableMetadataCacheDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *UpdateTableMetadataCacheDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *UpdateTableMetadataCacheDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *UpdateTableMetadataCacheProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *UpdateTableMetadataCacheProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *UpdateTableMetadataCacheProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Status != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Status))
		i--
		dAtA[i] = 0x18
	}
	if m.LastCompletedTime != nil {
		n73, err73 := github_com_gogo_protobuf_types.StdTimeMarshalTo(*m.LastCompletedTime, dAtA[i-github_com_gogo_protobuf_types.SizeOfStdTime(*m.LastCompletedTime):])
		if err73 != nil {
			return 0, err73
		}
		i -= n73
		i = encodeVarintJobs(dAtA, i, uint64(n73))
		i--
		dAtA[i] = 0x12
	}
	if m.LastStartTime != nil {
		n74, err74 := github_com_gogo_protobuf_types.StdTimeMarshalTo(*m.LastStartTime, dAtA[i-github_com_gogo_protobuf_types.SizeOfStdTime(*m.LastStartTime):])
		if err74 != nil {
			return 0, err74
		}
		i -= n74
		i = encodeVarintJobs(dAtA, i, uint64(n74))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *ImportRollbackDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ImportRollbackDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ImportRollbackDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.TableID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.TableID))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *SqlActivityFlushDetails) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SqlActivityFlushDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SqlActivityFlushDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *SqlActivityFlushProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SqlActivityFlushProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *SqlActivityFlushProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *HotRangesLoggerProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *HotRangesLoggerProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *HotRangesLoggerProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *InspectProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InspectProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *InspectProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *ImportRollbackProgress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ImportRollbackProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ImportRollbackProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *Payload) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *Payload) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Details != nil {
		{
			size := m.Details.Size()
			i -= size
			if _, err := m.Details.MarshalTo(dAtA[i:]); err != nil {
				return 0, err
			}
		}
	}
	if m.MaximumPTSAge != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.MaximumPTSAge))
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xc0
	}
	{
		size, err := m.CreationClusterVersion.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x2
	i--
	dAtA[i] = 0xa2
	{
		size := m.CreationClusterID.Size()
		i -= size
		if _, err := m.CreationClusterID.MarshalTo(dAtA[i:]); err != nil {
			return 0, err
		}
		i = encodeVarintJobs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x2
	i--
	dAtA[i] = 0x9a
	if len(m.PauseReason) > 0 {
		i -= len(m.PauseReason)
		copy(dAtA[i:], m.PauseReason)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.PauseReason)))
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xe2
	}
	if m.Noncancelable {
		i--
		if m.Noncancelable {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xa0
	}
	if m.FinalResumeError != nil {
		{
			size, err := m.FinalResumeError.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x9a
	}
	if len(m.CleanupErrors) > 0 {
		for iNdEx := len(m.CleanupErrors) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.CleanupErrors[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0x92
		}
	}
	if len(m.ResumeErrors) > 0 {
		for iNdEx := len(m.ResumeErrors) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ResumeErrors[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0x8a
		}
	}
	if len(m.Statement) > 0 {
		for iNdEx := len(m.Statement) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.Statement[iNdEx])
			copy(dAtA[i:], m.Statement[iNdEx])
			i = encodeVarintJobs(dAtA, i, uint64(len(m.Statement[iNdEx])))
			i--
			dAtA[i] = 0x1
			i--
			dAtA[i] = 0x82
		}
	}
	if len(m.Error) > 0 {
		i -= len(m.Error)
		copy(dAtA[i:], m.Error)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Error)))
		i--
		dAtA[i] = 0x42
	}
	if len(m.DescriptorIDs) > 0 {
		l := 0
		for _, e := range m.DescriptorIDs {
			l += sovJobs(uint64(e))
		}
		i -= l
		if l == len(m.DescriptorIDs) {
			dest := dAtA[i : i+len(m.DescriptorIDs)]
			for k, num := range m.DescriptorIDs {
				dest[k] = uint8(num)
			}
		} else {
			j77 := i
			for _, num := range m.DescriptorIDs {
				for num >= 1<<7 {
					dAtA[j77] = uint8(uint64(num)&0x7f | 0x80)
					num >>= 7
					j77++
				}
				dAtA[j77] = uint8(num)
				j77++
			}
		}
		i = encodeVarintJobs(dAtA, i, uint64(uint64(l)))
		i--
		dAtA[i] = 0x32
	}
	if m.FinishedMicros != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.FinishedMicros))
		i--
		dAtA[i] = 0x20
	}
	if m.StartedMicros != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.StartedMicros))
		i--
		dAtA[i] = 0x18
	}
	if len(m.UsernameProto) > 0 {
		i -= len(m.UsernameProto)
		copy(dAtA[i:], m.UsernameProto)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.UsernameProto)))
		i--
		dAtA[i] = 0x12
	}
	if len(m.Description) > 0 {
		i -= len(m.Description)
		copy(dAtA[i:], m.Description)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Description)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *Payload_Backup) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_Backup) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Backup != nil {
		{
			size, err := m.Backup.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x52
	}
	return len(dAtA) - i, nil
}
func (m *Payload_Restore) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_Restore) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Restore != nil {
		{
			size, err := m.Restore.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x5a
	}
	return len(dAtA) - i, nil
}
func (m *Payload_SchemaChange) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_SchemaChange) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.SchemaChange != nil {
		{
			size, err := m.SchemaChange.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x62
	}
	return len(dAtA) - i, nil
}
func (m *Payload_Import) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_Import) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Import != nil {
		{
			size, err := m.Import.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x6a
	}
	return len(dAtA) - i, nil
}
func (m *Payload_Changefeed) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_Changefeed) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Changefeed != nil {
		{
			size, err := m.Changefeed.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x72
	}
	return len(dAtA) - i, nil
}
func (m *Payload_CreateStats) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_CreateStats) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.CreateStats != nil {
		{
			size, err := m.CreateStats.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x7a
	}
	return len(dAtA) - i, nil
}
func (m *Payload_SchemaChangeGC) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_SchemaChangeGC) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.SchemaChangeGC != nil {
		{
			size, err := m.SchemaChangeGC.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xaa
	}
	return len(dAtA) - i, nil
}
func (m *Payload_TypeSchemaChange) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_TypeSchemaChange) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.TypeSchemaChange != nil {
		{
			size, err := m.TypeSchemaChange.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xb2
	}
	return len(dAtA) - i, nil
}
func (m *Payload_StreamIngestion) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_StreamIngestion) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.StreamIngestion != nil {
		{
			size, err := m.StreamIngestion.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xba
	}
	return len(dAtA) - i, nil
}
func (m *Payload_NewSchemaChange) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_NewSchemaChange) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.NewSchemaChange != nil {
		{
			size, err := m.NewSchemaChange.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xc2
	}
	return len(dAtA) - i, nil
}
func (m *Payload_Migration) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_Migration) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Migration != nil {
		{
			size, err := m.Migration.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xca
	}
	return len(dAtA) - i, nil
}
func (m *Payload_AutoSpanConfigReconciliation) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_AutoSpanConfigReconciliation) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.AutoSpanConfigReconciliation != nil {
		{
			size, err := m.AutoSpanConfigReconciliation.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xda
	}
	return len(dAtA) - i, nil
}
func (m *Payload_AutoSQLStatsCompaction) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_AutoSQLStatsCompaction) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.AutoSQLStatsCompaction != nil {
		{
			size, err := m.AutoSQLStatsCompaction.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xf2
	}
	return len(dAtA) - i, nil
}
func (m *Payload_StreamReplication) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_StreamReplication) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.StreamReplication != nil {
		{
			size, err := m.StreamReplication.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0x8a
	}
	return len(dAtA) - i, nil
}
func (m *Payload_RowLevelTTL) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_RowLevelTTL) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.RowLevelTTL != nil {
		{
			size, err := m.RowLevelTTL.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0x92
	}
	return len(dAtA) - i, nil
}
func (m *Payload_SchemaTelemetry) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_SchemaTelemetry) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.SchemaTelemetry != nil {
		{
			size, err := m.SchemaTelemetry.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xaa
	}
	return len(dAtA) - i, nil
}
func (m *Payload_KeyVisualizerDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_KeyVisualizerDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.KeyVisualizerDetails != nil {
		{
			size, err := m.KeyVisualizerDetails.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xb2
	}
	return len(dAtA) - i, nil
}
func (m *Payload_PollJobsStats) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_PollJobsStats) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.PollJobsStats != nil {
		{
			size, err := m.PollJobsStats.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xba
	}
	return len(dAtA) - i, nil
}
func (m *Payload_AutoConfigRunner) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_AutoConfigRunner) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.AutoConfigRunner != nil {
		{
			size, err := m.AutoConfigRunner.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xca
	}
	return len(dAtA) - i, nil
}
func (m *Payload_AutoConfigEnvRunner) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_AutoConfigEnvRunner) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.AutoConfigEnvRunner != nil {
		{
			size, err := m.AutoConfigEnvRunner.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xd2
	}
	return len(dAtA) - i, nil
}
func (m *Payload_AutoConfigTask) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_AutoConfigTask) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.AutoConfigTask != nil {
		{
			size, err := m.AutoConfigTask.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xda
	}
	return len(dAtA) - i, nil
}
func (m *Payload_AutoUpdateSqlActivities) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_AutoUpdateSqlActivities) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.AutoUpdateSqlActivities != nil {
		{
			size, err := m.AutoUpdateSqlActivities.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xe2
	}
	return len(dAtA) - i, nil
}
func (m *Payload_MvccStatisticsDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_MvccStatisticsDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.MvccStatisticsDetails != nil {
		{
			size, err := m.MvccStatisticsDetails.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xea
	}
	return len(dAtA) - i, nil
}
func (m *Payload_ImportRollbackDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_ImportRollbackDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.ImportRollbackDetails != nil {
		{
			size, err := m.ImportRollbackDetails.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xf2
	}
	return len(dAtA) - i, nil
}
func (m *Payload_HistoryRetentionDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_HistoryRetentionDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.HistoryRetentionDetails != nil {
		{
			size, err := m.HistoryRetentionDetails.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xfa
	}
	return len(dAtA) - i, nil
}
func (m *Payload_LogicalReplicationDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_LogicalReplicationDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.LogicalReplicationDetails != nil {
		{
			size, err := m.LogicalReplicationDetails.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x3
		i--
		dAtA[i] = 0x82
	}
	return len(dAtA) - i, nil
}
func (m *Payload_UpdateTableMetadataCacheDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_UpdateTableMetadataCacheDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.UpdateTableMetadataCacheDetails != nil {
		{
			size, err := m.UpdateTableMetadataCacheDetails.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x3
		i--
		dAtA[i] = 0x8a
	}
	return len(dAtA) - i, nil
}
func (m *Payload_StandbyReadTsPollerDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_StandbyReadTsPollerDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.StandbyReadTsPollerDetails != nil {
		{
			size, err := m.StandbyReadTsPollerDetails.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x3
		i--
		dAtA[i] = 0x92
	}
	return len(dAtA) - i, nil
}
func (m *Payload_SqlActivityFlushDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_SqlActivityFlushDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.SqlActivityFlushDetails != nil {
		{
			size, err := m.SqlActivityFlushDetails.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x3
		i--
		dAtA[i] = 0x9a
	}
	return len(dAtA) - i, nil
}
func (m *Payload_HotRangesLoggerDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_HotRangesLoggerDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.HotRangesLoggerDetails != nil {
		{
			size, err := m.HotRangesLoggerDetails.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x3
		i--
		dAtA[i] = 0xa2
	}
	return len(dAtA) - i, nil
}
func (m *Payload_InspectDetails) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Payload_InspectDetails) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.InspectDetails != nil {
		{
			size, err := m.InspectDetails.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x3
		i--
		dAtA[i] = 0xaa
	}
	return len(dAtA) - i, nil
}
func (m *Progress) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *Progress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Details != nil {
		{
			size := m.Details.Size()
			i -= size
			if _, err := m.Details.MarshalTo(dAtA[i:]); err != nil {
				return 0, err
			}
		}
	}
	if m.TraceID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.TraceID))
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xa8
	}
	if len(m.StatusMessage) > 0 {
		i -= len(m.StatusMessage)
		copy(dAtA[i:], m.StatusMessage)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.StatusMessage)))
		i--
		dAtA[i] = 0x22
	}
	if m.Progress != nil {
		{
			size := m.Progress.Size()
			i -= size
			if _, err := m.Progress.MarshalTo(dAtA[i:]); err != nil {
				return 0, err
			}
		}
	}
	if m.ModifiedMicros != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ModifiedMicros))
		i--
		dAtA[i] = 0x10
	}
	return len(dAtA) - i, nil
}

func (m *Progress_FractionCompleted) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_FractionCompleted) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	i -= 4
	encoding_binary.LittleEndian.PutUint32(dAtA[i:], uint32(math.Float32bits(float32(m.FractionCompleted))))
	i--
	dAtA[i] = 0xd
	return len(dAtA) - i, nil
}
func (m *Progress_HighWater) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_HighWater) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.HighWater != nil {
		{
			size, err := m.HighWater.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1a
	}
	return len(dAtA) - i, nil
}
func (m *Progress_Backup) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_Backup) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Backup != nil {
		{
			size, err := m.Backup.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x52
	}
	return len(dAtA) - i, nil
}
func (m *Progress_Restore) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_Restore) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Restore != nil {
		{
			size, err := m.Restore.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x5a
	}
	return len(dAtA) - i, nil
}
func (m *Progress_SchemaChange) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_SchemaChange) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.SchemaChange != nil {
		{
			size, err := m.SchemaChange.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x62
	}
	return len(dAtA) - i, nil
}
func (m *Progress_Import) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_Import) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Import != nil {
		{
			size, err := m.Import.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x6a
	}
	return len(dAtA) - i, nil
}
func (m *Progress_Changefeed) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_Changefeed) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Changefeed != nil {
		{
			size, err := m.Changefeed.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x72
	}
	return len(dAtA) - i, nil
}
func (m *Progress_CreateStats) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_CreateStats) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.CreateStats != nil {
		{
			size, err := m.CreateStats.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x7a
	}
	return len(dAtA) - i, nil
}
func (m *Progress_SchemaChangeGC) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_SchemaChangeGC) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.SchemaChangeGC != nil {
		{
			size, err := m.SchemaChangeGC.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x82
	}
	return len(dAtA) - i, nil
}
func (m *Progress_TypeSchemaChange) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_TypeSchemaChange) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.TypeSchemaChange != nil {
		{
			size, err := m.TypeSchemaChange.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x8a
	}
	return len(dAtA) - i, nil
}
func (m *Progress_StreamIngest) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_StreamIngest) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.StreamIngest != nil {
		{
			size, err := m.StreamIngest.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x92
	}
	return len(dAtA) - i, nil
}
func (m *Progress_NewSchemaChange) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_NewSchemaChange) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.NewSchemaChange != nil {
		{
			size, err := m.NewSchemaChange.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0x9a
	}
	return len(dAtA) - i, nil
}
func (m *Progress_Migration) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_Migration) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Migration != nil {
		{
			size, err := m.Migration.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xa2
	}
	return len(dAtA) - i, nil
}
func (m *Progress_AutoSpanConfigReconciliation) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_AutoSpanConfigReconciliation) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.AutoSpanConfigReconciliation != nil {
		{
			size, err := m.AutoSpanConfigReconciliation.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xb2
	}
	return len(dAtA) - i, nil
}
func (m *Progress_AutoSQLStatsCompaction) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_AutoSQLStatsCompaction) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.AutoSQLStatsCompaction != nil {
		{
			size, err := m.AutoSQLStatsCompaction.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xba
	}
	return len(dAtA) - i, nil
}
func (m *Progress_StreamReplication) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_StreamReplication) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.StreamReplication != nil {
		{
			size, err := m.StreamReplication.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xc2
	}
	return len(dAtA) - i, nil
}
func (m *Progress_RowLevelTTL) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_RowLevelTTL) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.RowLevelTTL != nil {
		{
			size, err := m.RowLevelTTL.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xca
	}
	return len(dAtA) - i, nil
}
func (m *Progress_SchemaTelemetry) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_SchemaTelemetry) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.SchemaTelemetry != nil {
		{
			size, err := m.SchemaTelemetry.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xd2
	}
	return len(dAtA) - i, nil
}
func (m *Progress_KeyVisualizerProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_KeyVisualizerProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.KeyVisualizerProgress != nil {
		{
			size, err := m.KeyVisualizerProgress.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xda
	}
	return len(dAtA) - i, nil
}
func (m *Progress_PollJobsStats) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_PollJobsStats) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.PollJobsStats != nil {
		{
			size, err := m.PollJobsStats.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xe2
	}
	return len(dAtA) - i, nil
}
func (m *Progress_AutoConfigRunner) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_AutoConfigRunner) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.AutoConfigRunner != nil {
		{
			size, err := m.AutoConfigRunner.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xea
	}
	return len(dAtA) - i, nil
}
func (m *Progress_AutoConfigEnvRunner) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_AutoConfigEnvRunner) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.AutoConfigEnvRunner != nil {
		{
			size, err := m.AutoConfigEnvRunner.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xf2
	}
	return len(dAtA) - i, nil
}
func (m *Progress_AutoConfigTask) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_AutoConfigTask) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.AutoConfigTask != nil {
		{
			size, err := m.AutoConfigTask.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1
		i--
		dAtA[i] = 0xfa
	}
	return len(dAtA) - i, nil
}
func (m *Progress_UpdateSqlActivity) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_UpdateSqlActivity) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.UpdateSqlActivity != nil {
		{
			size, err := m.UpdateSqlActivity.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0x82
	}
	return len(dAtA) - i, nil
}
func (m *Progress_MvccStatisticsProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_MvccStatisticsProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.MvccStatisticsProgress != nil {
		{
			size, err := m.MvccStatisticsProgress.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0x8a
	}
	return len(dAtA) - i, nil
}
func (m *Progress_ImportRollbackProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_ImportRollbackProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.ImportRollbackProgress != nil {
		{
			size, err := m.ImportRollbackProgress.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0x92
	}
	return len(dAtA) - i, nil
}
func (m *Progress_HistoryRetentionProgress) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_HistoryRetentionProgress) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.HistoryRetentionProgress != nil {
		{
			size, err := m.HistoryRetentionProgress.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0x9a
	}
	return len(dAtA) - i, nil
}
func (m *Progress_LogicalReplication) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_LogicalReplication) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.LogicalReplication != nil {
		{
			size, err := m.LogicalReplication.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xa2
	}
	return len(dAtA) - i, nil
}
func (m *Progress_TableMetadataCache) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_TableMetadataCache) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.TableMetadataCache != nil {
		{
			size, err := m.TableMetadataCache.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xaa
	}
	return len(dAtA) - i, nil
}
func (m *Progress_StandbyReadTsPoller) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_StandbyReadTsPoller) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.StandbyReadTsPoller != nil {
		{
			size, err := m.StandbyReadTsPoller.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xb2
	}
	return len(dAtA) - i, nil
}
func (m *Progress_SqlActivityFlush) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_SqlActivityFlush) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.SqlActivityFlush != nil {
		{
			size, err := m.SqlActivityFlush.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xba
	}
	return len(dAtA) - i, nil
}
func (m *Progress_HotRangesLogger) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_HotRangesLogger) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.HotRangesLogger != nil {
		{
			size, err := m.HotRangesLogger.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xc2
	}
	return len(dAtA) - i, nil
}
func (m *Progress_Inspect) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Progress_Inspect) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	if m.Inspect != nil {
		{
			size, err := m.Inspect.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2
		i--
		dAtA[i] = 0xca
	}
	return len(dAtA) - i, nil
}
func (m *Job) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *Job) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Job) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Payload != nil {
		{
			size, err := m.Payload.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1a
	}
	if m.Progress != nil {
		{
			size, err := m.Progress.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x12
	}
	if m.Id != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.Id))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *RetriableExecutionFailure) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *RetriableExecutionFailure) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *RetriableExecutionFailure) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.TruncatedError) > 0 {
		i -= len(m.TruncatedError)
		copy(dAtA[i:], m.TruncatedError)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.TruncatedError)))
		i--
		dAtA[i] = 0x32
	}
	if m.Error != nil {
		{
			size, err := m.Error.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintJobs(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x2a
	}
	if m.InstanceID != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.InstanceID))
		i--
		dAtA[i] = 0x20
	}
	if m.ExecutionEndMicros != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ExecutionEndMicros))
		i--
		dAtA[i] = 0x18
	}
	if m.ExecutionStartMicros != 0 {
		i = encodeVarintJobs(dAtA, i, uint64(m.ExecutionStartMicros))
		i--
		dAtA[i] = 0x10
	}
	if len(m.Status) > 0 {
		i -= len(m.Status)
		copy(dAtA[i:], m.Status)
		i = encodeVarintJobs(dAtA, i, uint64(len(m.Status)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *TraceData) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *TraceData) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *TraceData) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.CollectedSpans) > 0 {
		for iNdEx := len(m.CollectedSpans) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.CollectedSpans[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintJobs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func encodeVarintJobs(dAtA []byte, offset int, v uint64) int {
	offset -= sovJobs(v)
	base := offset
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return base
}
func (m *BackupEncryptionOptions) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.Key)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.Mode != 0 {
		n += 1 + sovJobs(uint64(m.Mode))
	}
	if m.KMSInfo != nil {
		l = m.KMSInfo.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	l = len(m.RawPassphrase)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if len(m.RawKmsUris) > 0 {
		for _, s := range m.RawKmsUris {
			l = len(s)
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	return n
}

func (m *BackupEncryptionOptions_KMSInfo) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.Uri)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	l = len(m.EncryptedDataKey)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *EncryptionInfo) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Scheme != 0 {
		n += 1 + sovJobs(uint64(m.Scheme))
	}
	l = len(m.Salt)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if len(m.EncryptedDataKeyByKMSMasterKeyID) > 0 {
		for k, v := range m.EncryptedDataKeyByKMSMasterKeyID {
			_ = k
			_ = v
			l = 0
			if len(v) > 0 {
				l = 1 + len(v) + sovJobs(uint64(len(v)))
			}
			mapEntrySize := 1 + len(k) + sovJobs(uint64(len(k))) + l
			n += mapEntrySize + 1 + sovJobs(uint64(mapEntrySize))
		}
	}
	return n
}

func (m *StreamIngestionDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.SourceClusterConnUri)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	l = m.Span.Size()
	n += 1 + l + sovJobs(uint64(l))
	if m.StreamID != 0 {
		n += 1 + sovJobs(uint64(m.StreamID))
	}
	l = m.DestinationTenantID.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = len(m.SourceTenantName)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.ProtectedTimestampRecordID != nil {
		l = m.ProtectedTimestampRecordID.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.ReplicationTTLSeconds != 0 {
		n += 1 + sovJobs(uint64(m.ReplicationTTLSeconds))
	}
	l = m.ReplicationStartTime.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.SourceTenantID.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.SourceClusterID.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.ReadTenantID.Size()
	n += 1 + l + sovJobs(uint64(l))
	return n
}

func (m *StreamIngestionCheckpoint) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.ResolvedSpans) > 0 {
		for _, e := range m.ResolvedSpans {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	return n
}

func (m *StreamIngestionProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.CutoverTime.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.Checkpoint.Size()
	n += 1 + l + sovJobs(uint64(l))
	if len(m.PartitionConnUris) > 0 {
		for _, s := range m.PartitionConnUris {
			l = len(s)
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.ReplicationStatus != 0 {
		n += 1 + sovJobs(uint64(m.ReplicationStatus))
	}
	l = m.ReplicatedTime.Size()
	n += 1 + l + sovJobs(uint64(l))
	if len(m.RemainingCutoverSpans) > 0 {
		for _, e := range m.RemainingCutoverSpans {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.InitialSplitComplete {
		n += 2
	}
	if m.InitialRevertRequired {
		n += 2
	}
	l = m.InitialRevertTo.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.ReplicatedTimeAtCutover.Size()
	n += 1 + l + sovJobs(uint64(l))
	return n
}

func (m *HistoryRetentionDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.ProtectedTimestampRecordID.Size()
	n += 1 + l + sovJobs(uint64(l))
	if m.ExpirationWindow != 0 {
		n += 1 + sovJobs(uint64(m.ExpirationWindow))
	}
	return n
}

func (m *HistoryRetentionProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = github_com_gogo_protobuf_types.SizeOfStdTime(m.LastHeartbeatTime)
	n += 1 + l + sovJobs(uint64(l))
	return n
}

func (m *LogicalReplicationDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.SourceClusterConnUri)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if len(m.TableNames) > 0 {
		for _, s := range m.TableNames {
			l = len(s)
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if len(m.ReplicationPairs) > 0 {
		for _, e := range m.ReplicationPairs {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.StreamID != 0 {
		n += 1 + sovJobs(uint64(m.StreamID))
	}
	l = m.ReplicationStartTime.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.SourceClusterID.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.DefaultConflictResolution.Size()
	n += 1 + l + sovJobs(uint64(l))
	if m.Mode != 0 {
		n += 1 + sovJobs(uint64(m.Mode))
	}
	l = len(m.MetricsLabel)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.Discard != 0 {
		n += 1 + sovJobs(uint64(m.Discard))
	}
	if m.CreateTable {
		n += 2
	}
	l = m.IngestedExternalCatalog.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = len(m.ReverseStreamCommand)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.ParentID != 0 {
		n += 1 + sovJobs(uint64(m.ParentID))
	}
	l = len(m.Command)
	if l > 0 {
		n += 2 + l + sovJobs(uint64(l))
	}
	if m.SkipSchemaCheck {
		n += 3
	}
	return n
}

func (m *LogicalReplicationDetails_ReplicationPair) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.SrcDescriptorID != 0 {
		n += 1 + sovJobs(uint64(m.SrcDescriptorID))
	}
	if m.DstDescriptorID != 0 {
		n += 1 + sovJobs(uint64(m.DstDescriptorID))
	}
	if m.DstFunctionID != 0 {
		n += 1 + sovJobs(uint64(m.DstFunctionID))
	}
	return n
}

func (m *LogicalReplicationDetails_DefaultConflictResolution) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.ConflictResolutionType != 0 {
		n += 1 + sovJobs(uint64(m.ConflictResolutionType))
	}
	if m.FunctionId != 0 {
		n += 1 + sovJobs(uint64(m.FunctionId))
	}
	return n
}

func (m *LogicalReplicationProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.ReplicatedTime.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.Checkpoint.Size()
	n += 1 + l + sovJobs(uint64(l))
	if len(m.PartitionConnUris) > 0 {
		for _, s := range m.PartitionConnUris {
			l = len(s)
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.PublishedNewTables {
		n += 2
	}
	if m.StartedReverseStream {
		n += 2
	}
	return n
}

func (m *StreamReplicationDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Spans) > 0 {
		for _, e := range m.Spans {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	l = m.ProtectedTimestampRecordID.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.TenantID.Size()
	n += 1 + l + sovJobs(uint64(l))
	if m.ExpirationWindow != 0 {
		n += 1 + sovJobs(uint64(m.ExpirationWindow))
	}
	if len(m.TableIDs) > 0 {
		l = 0
		for _, e := range m.TableIDs {
			l += sovJobs(uint64(e))
		}
		n += 1 + sovJobs(uint64(l)) + l
	}
	return n
}

func (m *StreamReplicationProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = github_com_gogo_protobuf_types.SizeOfStdTime(m.Expiration)
	n += 1 + l + sovJobs(uint64(l))
	if m.StreamIngestionStatus != 0 {
		n += 1 + sovJobs(uint64(m.StreamIngestionStatus))
	}
	return n
}

func (m *SchedulePTSChainingRecord) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.ProtectedTimestampRecord != nil {
		l = m.ProtectedTimestampRecord.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.Action != 0 {
		n += 1 + sovJobs(uint64(m.Action))
	}
	return n
}

func (m *BackupDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.StartTime.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.EndTime.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = len(m.URI)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	l = len(m.DeprecatedBackupManifest)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if len(m.URIsByLocalityKV) > 0 {
		for k, v := range m.URIsByLocalityKV {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sovJobs(uint64(len(k))) + 1 + len(v) + sovJobs(uint64(len(v)))
			n += mapEntrySize + 1 + sovJobs(uint64(mapEntrySize))
		}
	}
	if m.EncryptionOptions != nil {
		l = m.EncryptionOptions.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.ProtectedTimestampRecord != nil {
		l = m.ProtectedTimestampRecord.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	l = len(m.CollectionURI)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.EncryptionInfo != nil {
		l = m.EncryptionInfo.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.SchedulePTSChainingRecord != nil {
		l = m.SchedulePTSChainingRecord.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	l = m.Destination.Size()
	n += 1 + l + sovJobs(uint64(l))
	if m.ScheduleID != 0 {
		n += 1 + sovJobs(uint64(m.ScheduleID))
	}
	if m.RevisionHistory {
		n += 2
	}
	if m.FullCluster {
		n += 2
	}
	if len(m.ResolvedTargets) > 0 {
		for _, e := range m.ResolvedTargets {
			l = e.Size()
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	if len(m.ResolvedCompleteDbs) > 0 {
		l = 0
		for _, e := range m.ResolvedCompleteDbs {
			l += sovJobs(uint64(e))
		}
		n += 2 + sovJobs(uint64(l)) + l
	}
	if len(m.SpecificTenantIds) > 0 {
		for _, e := range m.SpecificTenantIds {
			l = e.Size()
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	if len(m.RequestedTargets) > 0 {
		for _, e := range m.RequestedTargets {
			l = e.Size()
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	if m.Detached {
		n += 3
	}
	if m.AsOfInterval != 0 {
		n += 2 + sovJobs(uint64(m.AsOfInterval))
	}
	l = len(m.ApplicationName)
	if l > 0 {
		n += 2 + l + sovJobs(uint64(l))
	}
	l = m.ExecutionLocality.Size()
	n += 2 + l + sovJobs(uint64(l))
	if m.IncludeAllSecondaryTenants {
		n += 3
	}
	if m.UpdatesClusterMonitoringMetrics {
		n += 3
	}
	if m.Compact {
		n += 3
	}
	return n
}

func (m *BackupDetails_Destination) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.To) > 0 {
		for _, s := range m.To {
			l = len(s)
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	l = len(m.Subdir)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if len(m.IncrementalStorage) > 0 {
		for _, s := range m.IncrementalStorage {
			l = len(s)
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.Exists {
		n += 2
	}
	return n
}

func (m *BackupProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *DescriptorRewrite) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.ID != 0 {
		n += 1 + sovJobs(uint64(m.ID))
	}
	if m.ParentID != 0 {
		n += 1 + sovJobs(uint64(m.ParentID))
	}
	if m.ToExisting {
		n += 2
	}
	l = len(m.NewDBName)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.ParentSchemaID != 0 {
		n += 1 + sovJobs(uint64(m.ParentSchemaID))
	}
	return n
}

func (m *RestoreDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.DescriptorRewrites) > 0 {
		for k, v := range m.DescriptorRewrites {
			_ = k
			_ = v
			l = 0
			if v != nil {
				l = v.Size()
				l += 1 + sovJobs(uint64(l))
			}
			mapEntrySize := 1 + sovJobs(uint64(k)) + l
			n += mapEntrySize + 1 + sovJobs(uint64(mapEntrySize))
		}
	}
	if len(m.URIs) > 0 {
		for _, s := range m.URIs {
			l = len(s)
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	l = m.EndTime.Size()
	n += 1 + l + sovJobs(uint64(l))
	if len(m.TableDescs) > 0 {
		for _, e := range m.TableDescs {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	l = len(m.OverrideDB)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if len(m.BackupLocalityInfo) > 0 {
		for _, e := range m.BackupLocalityInfo {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.PrepareCompleted {
		n += 2
	}
	if m.StatsInserted {
		n += 2
	}
	if m.DescriptorsPublished {
		n += 2
	}
	if m.DescriptorCoverage != 0 {
		n += 1 + sovJobs(uint64(m.DescriptorCoverage))
	}
	if m.Encryption != nil {
		l = m.Encryption.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	if len(m.TypeDescs) > 0 {
		for _, e := range m.TypeDescs {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if len(m.SchemaDescs) > 0 {
		for _, e := range m.SchemaDescs {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if len(m.DatabaseDescs) > 0 {
		for _, e := range m.DatabaseDescs {
			l = e.Size()
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	if len(m.SystemTablesMigrated) > 0 {
		for k, v := range m.SystemTablesMigrated {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sovJobs(uint64(len(k))) + 1 + 1
			n += mapEntrySize + 2 + sovJobs(uint64(mapEntrySize))
		}
	}
	if len(m.DatabaseModifiers) > 0 {
		for k, v := range m.DatabaseModifiers {
			_ = k
			_ = v
			l = 0
			if v != nil {
				l = v.Size()
				l += 1 + sovJobs(uint64(l))
			}
			mapEntrySize := 1 + sovJobs(uint64(k)) + l
			n += mapEntrySize + 2 + sovJobs(uint64(mapEntrySize))
		}
	}
	if len(m.Tenants) > 0 {
		for _, e := range m.Tenants {
			l = e.Size()
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	if m.RestoreSystemUsers {
		n += 3
	}
	if m.PreRewriteTenantId != nil {
		l = m.PreRewriteTenantId.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	if m.SchemaOnly {
		n += 3
	}
	if m.VerifyData {
		n += 3
	}
	if len(m.FunctionDescs) > 0 {
		for _, e := range m.FunctionDescs {
			l = e.Size()
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	if m.ProtectedTimestampRecord != nil {
		l = m.ProtectedTimestampRecord.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	if m.SkipLocalitiesCheck {
		n += 3
	}
	l = m.ExecutionLocality.Size()
	n += 2 + l + sovJobs(uint64(l))
	if m.ExperimentalOnline {
		n += 3
	}
	if len(m.DownloadSpans) > 0 {
		for _, e := range m.DownloadSpans {
			l = e.Size()
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	if m.RemoveRegions {
		n += 3
	}
	if m.UnsafeRestoreIncompatibleVersion {
		n += 3
	}
	if len(m.PostDownloadTableAutoStatsSettings) > 0 {
		for k, v := range m.PostDownloadTableAutoStatsSettings {
			_ = k
			_ = v
			l = 0
			if v != nil {
				l = v.Size()
				l += 1 + sovJobs(uint64(l))
			}
			mapEntrySize := 1 + sovJobs(uint64(k)) + l
			n += mapEntrySize + 2 + sovJobs(uint64(mapEntrySize))
		}
	}
	if m.DownloadJob {
		n += 3
	}
	if m.ExperimentalCopy {
		n += 3
	}
	return n
}

func (m *RestoreDetails_BackupLocalityInfo) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.URIsByOriginalLocalityKV) > 0 {
		for k, v := range m.URIsByOriginalLocalityKV {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sovJobs(uint64(len(k))) + 1 + len(v) + sovJobs(uint64(len(v)))
			n += mapEntrySize + 1 + sovJobs(uint64(mapEntrySize))
		}
	}
	return n
}

func (m *RestoreDetails_DatabaseModifier) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.ExtraTypeDescs) > 0 {
		for _, e := range m.ExtraTypeDescs {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.RegionConfig != nil {
		l = m.RegionConfig.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *RestoreProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.HighWater)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if len(m.Checkpoint) > 0 {
		for _, e := range m.Checkpoint {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.TotalDownloadRequired != 0 {
		n += 1 + sovJobs(uint64(m.TotalDownloadRequired))
	}
	return n
}

func (m *RestoreProgress_FrontierEntry) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.Span.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.Timestamp.Size()
	n += 1 + l + sovJobs(uint64(l))
	return n
}

func (m *ImportDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Tables) > 0 {
		for _, e := range m.Tables {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if len(m.URIs) > 0 {
		for _, s := range m.URIs {
			l = len(s)
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	l = m.Format.Size()
	n += 1 + l + sovJobs(uint64(l))
	if m.Walltime != 0 {
		n += 1 + sovJobs(uint64(m.Walltime))
	}
	if m.ParentID != 0 {
		n += 1 + sovJobs(uint64(m.ParentID))
	}
	if m.PrepareComplete {
		n += 2
	}
	if m.TablesPublished {
		n += 2
	}
	if len(m.Types) > 0 {
		for _, e := range m.Types {
			l = e.Size()
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	l = len(m.DatabasePrimaryRegion)
	if l > 0 {
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *ImportDetails_Table) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Desc != nil {
		l = m.Desc.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	l = len(m.Name)
	if l > 0 {
		n += 2 + l + sovJobs(uint64(l))
	}
	if m.SeqVal != 0 {
		n += 2 + sovJobs(uint64(m.SeqVal))
	}
	if len(m.TargetCols) > 0 {
		for _, s := range m.TargetCols {
			l = len(s)
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	if m.WasEmpty {
		n += 3
	}
	return n
}

func (m *ImportDetails_Type) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Desc != nil {
		l = m.Desc.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *SequenceValChunk) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.ChunkStartVal != 0 {
		n += 1 + sovJobs(uint64(m.ChunkStartVal))
	}
	if m.ChunkSize != 0 {
		n += 1 + sovJobs(uint64(m.ChunkSize))
	}
	if m.ChunkStartRow != 0 {
		n += 1 + sovJobs(uint64(m.ChunkStartRow))
	}
	if m.NextChunkStartRow != 0 {
		n += 1 + sovJobs(uint64(m.NextChunkStartRow))
	}
	return n
}

func (m *SequenceDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.SeqIdToChunks) > 0 {
		for k, v := range m.SeqIdToChunks {
			_ = k
			_ = v
			l = 0
			if v != nil {
				l = v.Size()
				l += 1 + sovJobs(uint64(l))
			}
			mapEntrySize := 1 + sovJobs(uint64(k)) + l
			n += mapEntrySize + 1 + sovJobs(uint64(mapEntrySize))
		}
	}
	return n
}

func (m *SequenceDetails_SequenceChunks) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Chunks) > 0 {
		for _, e := range m.Chunks {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	return n
}

func (m *ImportProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.SamplingProgress) > 0 {
		n += 1 + sovJobs(uint64(len(m.SamplingProgress)*4)) + len(m.SamplingProgress)*4
	}
	if len(m.ReadProgress) > 0 {
		n += 1 + sovJobs(uint64(len(m.ReadProgress)*4)) + len(m.ReadProgress)*4
	}
	if len(m.WriteProgress) > 0 {
		n += 1 + sovJobs(uint64(len(m.WriteProgress)*4)) + len(m.WriteProgress)*4
	}
	if len(m.SpanProgress) > 0 {
		for _, e := range m.SpanProgress {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if len(m.ResumePos) > 0 {
		l = 0
		for _, e := range m.ResumePos {
			l += sovJobs(uint64(e))
		}
		n += 1 + sovJobs(uint64(l)) + l
	}
	if len(m.SequenceDetails) > 0 {
		for _, e := range m.SequenceDetails {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	l = m.Summary.Size()
	n += 1 + l + sovJobs(uint64(l))
	return n
}

func (m *TypeSchemaChangeDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.TypeID != 0 {
		n += 1 + sovJobs(uint64(m.TypeID))
	}
	if len(m.TransitioningMembers) > 0 {
		for _, b := range m.TransitioningMembers {
			l = len(b)
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	return n
}

func (m *TypeSchemaChangeProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *NewSchemaChangeDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.BackfillProgress) > 0 {
		for _, e := range m.BackfillProgress {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if len(m.MergeProgress) > 0 {
		for _, e := range m.MergeProgress {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.ProtectedTimestampRecord != nil {
		l = m.ProtectedTimestampRecord.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *BackfillProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.TableID != 0 {
		n += 1 + sovJobs(uint64(m.TableID))
	}
	if m.SourceIndexID != 0 {
		n += 1 + sovJobs(uint64(m.SourceIndexID))
	}
	if len(m.DestIndexIDs) > 0 {
		l = 0
		for _, e := range m.DestIndexIDs {
			l += sovJobs(uint64(e))
		}
		n += 1 + sovJobs(uint64(l)) + l
	}
	l = m.WriteTimestamp.Size()
	n += 1 + l + sovJobs(uint64(l))
	if len(m.CompletedSpans) > 0 {
		for _, e := range m.CompletedSpans {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	return n
}

func (m *MergeProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.TableID != 0 {
		n += 1 + sovJobs(uint64(m.TableID))
	}
	if len(m.MergePairs) > 0 {
		for _, e := range m.MergePairs {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	return n
}

func (m *MergeProgress_MergePair) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.SourceIndexID != 0 {
		n += 1 + sovJobs(uint64(m.SourceIndexID))
	}
	if m.DestIndexID != 0 {
		n += 1 + sovJobs(uint64(m.DestIndexID))
	}
	if len(m.CompletedSpans) > 0 {
		for _, e := range m.CompletedSpans {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	return n
}

func (m *NewSchemaChangeProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *AutoSpanConfigReconciliationDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *AutoSpanConfigReconciliationProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.Checkpoint.Size()
	n += 1 + l + sovJobs(uint64(l))
	return n
}

func (m *KeyVisualizerDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *KeyVisualizerProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *ResumeSpanList) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.ResumeSpans) > 0 {
		for _, e := range m.ResumeSpans {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	return n
}

func (m *DroppedTableDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.Name)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.ID != 0 {
		n += 1 + sovJobs(uint64(m.ID))
	}
	if m.Status != 0 {
		n += 1 + sovJobs(uint64(m.Status))
	}
	return n
}

func (m *SchemaChangeGCDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Indexes) > 0 {
		for _, e := range m.Indexes {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if len(m.Tables) > 0 {
		for _, e := range m.Tables {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.ParentID != 0 {
		n += 1 + sovJobs(uint64(m.ParentID))
	}
	if m.Tenant != nil {
		l = m.Tenant.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *SchemaChangeGCDetails_DroppedIndex) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.IndexID != 0 {
		n += 1 + sovJobs(uint64(m.IndexID))
	}
	if m.DropTime != 0 {
		n += 1 + sovJobs(uint64(m.DropTime))
	}
	return n
}

func (m *SchemaChangeGCDetails_DroppedID) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.ID != 0 {
		n += 1 + sovJobs(uint64(m.ID))
	}
	if m.DropTime != 0 {
		n += 1 + sovJobs(uint64(m.DropTime))
	}
	return n
}

func (m *SchemaChangeGCDetails_DroppedTenant) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.ID != 0 {
		n += 1 + sovJobs(uint64(m.ID))
	}
	if m.DropTime != 0 {
		n += 1 + sovJobs(uint64(m.DropTime))
	}
	return n
}

func (m *SchemaChangeDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.ResumeSpanList) > 0 {
		for _, e := range m.ResumeSpanList {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if len(m.DroppedTables) > 0 {
		for _, e := range m.DroppedTables {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.DroppedDatabaseID != 0 {
		n += 1 + sovJobs(uint64(m.DroppedDatabaseID))
	}
	if m.DescID != 0 {
		n += 1 + sovJobs(uint64(m.DescID))
	}
	if m.TableMutationID != 0 {
		n += 1 + sovJobs(uint64(m.TableMutationID))
	}
	if m.FormatVersion != 0 {
		n += 1 + sovJobs(uint64(m.FormatVersion))
	}
	if len(m.DroppedTypes) > 0 {
		l = 0
		for _, e := range m.DroppedTypes {
			l += sovJobs(uint64(e))
		}
		n += 1 + sovJobs(uint64(l)) + l
	}
	if len(m.DroppedSchemas) > 0 {
		l = 0
		for _, e := range m.DroppedSchemas {
			l += sovJobs(uint64(e))
		}
		n += 1 + sovJobs(uint64(l)) + l
	}
	l = m.WriteTimestamp.Size()
	n += 1 + l + sovJobs(uint64(l))
	if m.ProtectedTimestampRecord != nil {
		l = m.ProtectedTimestampRecord.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	if len(m.DroppedFunctions) > 0 {
		l = 0
		for _, e := range m.DroppedFunctions {
			l += sovJobs(uint64(e))
		}
		n += 1 + sovJobs(uint64(l)) + l
	}
	if m.SessionData != nil {
		l = m.SessionData.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *SchemaChangeProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *SchemaChangeGCProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Indexes) > 0 {
		for _, e := range m.Indexes {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if len(m.Tables) > 0 {
		for _, e := range m.Tables {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.Tenant != nil {
		l = m.Tenant.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.RangesUnsplitDone {
		n += 2
	}
	return n
}

func (m *SchemaChangeGCProgress_IndexProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.IndexID != 0 {
		n += 1 + sovJobs(uint64(m.IndexID))
	}
	if m.Status != 0 {
		n += 1 + sovJobs(uint64(m.Status))
	}
	return n
}

func (m *SchemaChangeGCProgress_TableProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.ID != 0 {
		n += 1 + sovJobs(uint64(m.ID))
	}
	if m.Status != 0 {
		n += 1 + sovJobs(uint64(m.Status))
	}
	return n
}

func (m *SchemaChangeGCProgress_TenantProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Status != 0 {
		n += 1 + sovJobs(uint64(m.Status))
	}
	return n
}

func (m *ChangefeedTargetTable) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.StatementTimeName)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *ChangefeedTargetSpecification) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Type != 0 {
		n += 1 + sovJobs(uint64(m.Type))
	}
	if m.DescID != 0 {
		n += 1 + sovJobs(uint64(m.DescID))
	}
	l = len(m.FamilyName)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	l = len(m.StatementTimeName)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *ChangefeedDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.SinkURI)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if len(m.Opts) > 0 {
		for k, v := range m.Opts {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sovJobs(uint64(len(k))) + 1 + len(v) + sovJobs(uint64(len(v)))
			n += mapEntrySize + 1 + sovJobs(uint64(mapEntrySize))
		}
	}
	if len(m.Tables) > 0 {
		for k, v := range m.Tables {
			_ = k
			_ = v
			l = v.Size()
			mapEntrySize := 1 + sovJobs(uint64(k)) + 1 + l + sovJobs(uint64(l))
			n += mapEntrySize + 1 + sovJobs(uint64(mapEntrySize))
		}
	}
	l = m.StatementTime.Size()
	n += 1 + l + sovJobs(uint64(l))
	if len(m.TargetSpecifications) > 0 {
		for _, e := range m.TargetSpecifications {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	l = m.EndTime.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = len(m.Select)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.SessionData != nil {
		l = m.SessionData.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *ResolvedSpan) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.Span.Size()
	n += 1 + l + sovJobs(uint64(l))
	l = m.Timestamp.Size()
	n += 1 + l + sovJobs(uint64(l))
	if m.BoundaryType != 0 {
		n += 1 + sovJobs(uint64(m.BoundaryType))
	}
	return n
}

func (m *ResolvedSpans) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.ResolvedSpans) > 0 {
		for _, e := range m.ResolvedSpans {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	l = m.Stats.Size()
	n += 1 + l + sovJobs(uint64(l))
	return n
}

func (m *ResolvedSpans_Stats) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.RecentKvCount != 0 {
		n += 1 + sovJobs(uint64(m.RecentKvCount))
	}
	return n
}

func (m *TimestampSpansMap) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Entries) > 0 {
		for _, e := range m.Entries {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	return n
}

func (m *TimestampSpansMap_Entry) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.Timestamp.Size()
	n += 1 + l + sovJobs(uint64(l))
	if len(m.Spans) > 0 {
		for _, e := range m.Spans {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	return n
}

func (m *ChangefeedProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.ProtectedTimestampRecord.Size()
	n += 1 + l + sovJobs(uint64(l))
	if m.SpanLevelCheckpoint != nil {
		l = m.SpanLevelCheckpoint.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *CreateStatsDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.Name)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	l = m.Table.Size()
	n += 1 + l + sovJobs(uint64(l))
	if len(m.ColumnStats) > 0 {
		for _, e := range m.ColumnStats {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	l = len(m.Statement)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.AsOf != nil {
		l = m.AsOf.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	l = len(m.FQTableName)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.MaxFractionIdle != 0 {
		n += 9
	}
	if m.DeleteOtherStats {
		n += 2
	}
	if m.UsingExtremes {
		n += 2
	}
	l = len(m.WhereClause)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if len(m.WhereSpans) > 0 {
		for _, e := range m.WhereSpans {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.WhereIndexID != 0 {
		n += 1 + sovJobs(uint64(m.WhereIndexID))
	}
	return n
}

func (m *CreateStatsDetails_ColStat) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.ColumnIDs) > 0 {
		l = 0
		for _, e := range m.ColumnIDs {
			l += sovJobs(uint64(e))
		}
		n += 1 + sovJobs(uint64(l)) + l
	}
	if m.HasHistogram {
		n += 2
	}
	if m.Inverted {
		n += 2
	}
	if m.HistogramMaxBuckets != 0 {
		n += 1 + sovJobs(uint64(m.HistogramMaxBuckets))
	}
	return n
}

func (m *CreateStatsProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *MigrationDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.ClusterVersion != nil {
		l = m.ClusterVersion.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *MigrationProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.Watermark)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *AutoSQLStatsCompactionDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *AutoSQLStatsCompactionProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *RowLevelTTLDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.TableID != 0 {
		n += 1 + sovJobs(uint64(m.TableID))
	}
	l = github_com_gogo_protobuf_types.SizeOfStdTime(m.Cutoff)
	n += 1 + l + sovJobs(uint64(l))
	if m.TableVersion != 0 {
		n += 1 + sovJobs(uint64(m.TableVersion))
	}
	return n
}

func (m *RowLevelTTLProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.JobDeletedRowCount != 0 {
		n += 1 + sovJobs(uint64(m.JobDeletedRowCount))
	}
	if len(m.ProcessorProgresses) > 0 {
		for _, e := range m.ProcessorProgresses {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	if m.JobTotalSpanCount != 0 {
		n += 1 + sovJobs(uint64(m.JobTotalSpanCount))
	}
	if m.JobProcessedSpanCount != 0 {
		n += 1 + sovJobs(uint64(m.JobProcessedSpanCount))
	}
	return n
}

func (m *RowLevelTTLProcessorProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.ProcessorID != 0 {
		n += 1 + sovJobs(uint64(m.ProcessorID))
	}
	if m.SQLInstanceID != 0 {
		n += 1 + sovJobs(uint64(m.SQLInstanceID))
	}
	if m.DeletedRowCount != 0 {
		n += 1 + sovJobs(uint64(m.DeletedRowCount))
	}
	if m.TotalSpanCount != 0 {
		n += 1 + sovJobs(uint64(m.TotalSpanCount))
	}
	if m.ProcessorConcurrency != 0 {
		n += 1 + sovJobs(uint64(m.ProcessorConcurrency))
	}
	if m.ProcessedSpanCount != 0 {
		n += 1 + sovJobs(uint64(m.ProcessedSpanCount))
	}
	return n
}

func (m *SchemaTelemetryDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *SchemaTelemetryProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *PollJobsStatsDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *PollJobsStatsProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *AutoConfigRunnerDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *AutoConfigRunnerProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *AutoConfigEnvRunnerDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *AutoConfigEnvRunnerProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *AutoConfigTaskDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *AutoConfigTaskProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *AutoUpdateSQLActivityDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *AutoUpdateSQLActivityProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *MVCCStatisticsJobDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *MVCCStatisticsJobProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *StandbyReadTSPollerDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *StandbyReadTSPollerProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *HotRangesLoggerDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *InspectDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Checks) > 0 {
		for _, e := range m.Checks {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	l = m.AsOf.Size()
	n += 1 + l + sovJobs(uint64(l))
	return n
}

func (m *InspectDetails_Check) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Type != 0 {
		n += 1 + sovJobs(uint64(m.Type))
	}
	if m.TableID != 0 {
		n += 1 + sovJobs(uint64(m.TableID))
	}
	if m.IndexID != 0 {
		n += 1 + sovJobs(uint64(m.IndexID))
	}
	return n
}

func (m *UpdateTableMetadataCacheDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *UpdateTableMetadataCacheProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.LastStartTime != nil {
		l = github_com_gogo_protobuf_types.SizeOfStdTime(*m.LastStartTime)
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.LastCompletedTime != nil {
		l = github_com_gogo_protobuf_types.SizeOfStdTime(*m.LastCompletedTime)
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.Status != 0 {
		n += 1 + sovJobs(uint64(m.Status))
	}
	return n
}

func (m *ImportRollbackDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.TableID != 0 {
		n += 1 + sovJobs(uint64(m.TableID))
	}
	return n
}

func (m *SqlActivityFlushDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *SqlActivityFlushProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *HotRangesLoggerProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *InspectProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *ImportRollbackProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *Payload) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.Description)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	l = len(m.UsernameProto)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.StartedMicros != 0 {
		n += 1 + sovJobs(uint64(m.StartedMicros))
	}
	if m.FinishedMicros != 0 {
		n += 1 + sovJobs(uint64(m.FinishedMicros))
	}
	if len(m.DescriptorIDs) > 0 {
		l = 0
		for _, e := range m.DescriptorIDs {
			l += sovJobs(uint64(e))
		}
		n += 1 + sovJobs(uint64(l)) + l
	}
	l = len(m.Error)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.Details != nil {
		n += m.Details.Size()
	}
	if len(m.Statement) > 0 {
		for _, s := range m.Statement {
			l = len(s)
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	if len(m.ResumeErrors) > 0 {
		for _, e := range m.ResumeErrors {
			l = e.Size()
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	if len(m.CleanupErrors) > 0 {
		for _, e := range m.CleanupErrors {
			l = e.Size()
			n += 2 + l + sovJobs(uint64(l))
		}
	}
	if m.FinalResumeError != nil {
		l = m.FinalResumeError.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	if m.Noncancelable {
		n += 3
	}
	l = len(m.PauseReason)
	if l > 0 {
		n += 2 + l + sovJobs(uint64(l))
	}
	l = m.CreationClusterID.Size()
	n += 2 + l + sovJobs(uint64(l))
	l = m.CreationClusterVersion.Size()
	n += 2 + l + sovJobs(uint64(l))
	if m.MaximumPTSAge != 0 {
		n += 2 + sovJobs(uint64(m.MaximumPTSAge))
	}
	return n
}

func (m *Payload_Backup) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Backup != nil {
		l = m.Backup.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_Restore) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Restore != nil {
		l = m.Restore.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_SchemaChange) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.SchemaChange != nil {
		l = m.SchemaChange.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_Import) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Import != nil {
		l = m.Import.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_Changefeed) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Changefeed != nil {
		l = m.Changefeed.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_CreateStats) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.CreateStats != nil {
		l = m.CreateStats.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_SchemaChangeGC) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.SchemaChangeGC != nil {
		l = m.SchemaChangeGC.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_TypeSchemaChange) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.TypeSchemaChange != nil {
		l = m.TypeSchemaChange.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_StreamIngestion) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.StreamIngestion != nil {
		l = m.StreamIngestion.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_NewSchemaChange) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.NewSchemaChange != nil {
		l = m.NewSchemaChange.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_Migration) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Migration != nil {
		l = m.Migration.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_AutoSpanConfigReconciliation) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.AutoSpanConfigReconciliation != nil {
		l = m.AutoSpanConfigReconciliation.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_AutoSQLStatsCompaction) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.AutoSQLStatsCompaction != nil {
		l = m.AutoSQLStatsCompaction.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_StreamReplication) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.StreamReplication != nil {
		l = m.StreamReplication.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_RowLevelTTL) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.RowLevelTTL != nil {
		l = m.RowLevelTTL.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_SchemaTelemetry) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.SchemaTelemetry != nil {
		l = m.SchemaTelemetry.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_KeyVisualizerDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.KeyVisualizerDetails != nil {
		l = m.KeyVisualizerDetails.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_PollJobsStats) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.PollJobsStats != nil {
		l = m.PollJobsStats.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_AutoConfigRunner) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.AutoConfigRunner != nil {
		l = m.AutoConfigRunner.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_AutoConfigEnvRunner) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.AutoConfigEnvRunner != nil {
		l = m.AutoConfigEnvRunner.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_AutoConfigTask) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.AutoConfigTask != nil {
		l = m.AutoConfigTask.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_AutoUpdateSqlActivities) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.AutoUpdateSqlActivities != nil {
		l = m.AutoUpdateSqlActivities.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_MvccStatisticsDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.MvccStatisticsDetails != nil {
		l = m.MvccStatisticsDetails.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_ImportRollbackDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.ImportRollbackDetails != nil {
		l = m.ImportRollbackDetails.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_HistoryRetentionDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.HistoryRetentionDetails != nil {
		l = m.HistoryRetentionDetails.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_LogicalReplicationDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.LogicalReplicationDetails != nil {
		l = m.LogicalReplicationDetails.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_UpdateTableMetadataCacheDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.UpdateTableMetadataCacheDetails != nil {
		l = m.UpdateTableMetadataCacheDetails.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_StandbyReadTsPollerDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.StandbyReadTsPollerDetails != nil {
		l = m.StandbyReadTsPollerDetails.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_SqlActivityFlushDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.SqlActivityFlushDetails != nil {
		l = m.SqlActivityFlushDetails.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_HotRangesLoggerDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.HotRangesLoggerDetails != nil {
		l = m.HotRangesLoggerDetails.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Payload_InspectDetails) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.InspectDetails != nil {
		l = m.InspectDetails.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Progress != nil {
		n += m.Progress.Size()
	}
	if m.ModifiedMicros != 0 {
		n += 1 + sovJobs(uint64(m.ModifiedMicros))
	}
	l = len(m.StatusMessage)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.Details != nil {
		n += m.Details.Size()
	}
	if m.TraceID != 0 {
		n += 2 + sovJobs(uint64(m.TraceID))
	}
	return n
}

func (m *Progress_FractionCompleted) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	n += 5
	return n
}
func (m *Progress_HighWater) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.HighWater != nil {
		l = m.HighWater.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_Backup) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Backup != nil {
		l = m.Backup.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_Restore) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Restore != nil {
		l = m.Restore.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_SchemaChange) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.SchemaChange != nil {
		l = m.SchemaChange.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_Import) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Import != nil {
		l = m.Import.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_Changefeed) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Changefeed != nil {
		l = m.Changefeed.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_CreateStats) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.CreateStats != nil {
		l = m.CreateStats.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_SchemaChangeGC) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.SchemaChangeGC != nil {
		l = m.SchemaChangeGC.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_TypeSchemaChange) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.TypeSchemaChange != nil {
		l = m.TypeSchemaChange.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_StreamIngest) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.StreamIngest != nil {
		l = m.StreamIngest.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_NewSchemaChange) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.NewSchemaChange != nil {
		l = m.NewSchemaChange.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_Migration) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Migration != nil {
		l = m.Migration.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_AutoSpanConfigReconciliation) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.AutoSpanConfigReconciliation != nil {
		l = m.AutoSpanConfigReconciliation.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_AutoSQLStatsCompaction) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.AutoSQLStatsCompaction != nil {
		l = m.AutoSQLStatsCompaction.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_StreamReplication) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.StreamReplication != nil {
		l = m.StreamReplication.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_RowLevelTTL) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.RowLevelTTL != nil {
		l = m.RowLevelTTL.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_SchemaTelemetry) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.SchemaTelemetry != nil {
		l = m.SchemaTelemetry.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_KeyVisualizerProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.KeyVisualizerProgress != nil {
		l = m.KeyVisualizerProgress.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_PollJobsStats) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.PollJobsStats != nil {
		l = m.PollJobsStats.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_AutoConfigRunner) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.AutoConfigRunner != nil {
		l = m.AutoConfigRunner.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_AutoConfigEnvRunner) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.AutoConfigEnvRunner != nil {
		l = m.AutoConfigEnvRunner.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_AutoConfigTask) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.AutoConfigTask != nil {
		l = m.AutoConfigTask.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_UpdateSqlActivity) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.UpdateSqlActivity != nil {
		l = m.UpdateSqlActivity.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_MvccStatisticsProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.MvccStatisticsProgress != nil {
		l = m.MvccStatisticsProgress.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_ImportRollbackProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.ImportRollbackProgress != nil {
		l = m.ImportRollbackProgress.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_HistoryRetentionProgress) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.HistoryRetentionProgress != nil {
		l = m.HistoryRetentionProgress.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_LogicalReplication) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.LogicalReplication != nil {
		l = m.LogicalReplication.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_TableMetadataCache) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.TableMetadataCache != nil {
		l = m.TableMetadataCache.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_StandbyReadTsPoller) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.StandbyReadTsPoller != nil {
		l = m.StandbyReadTsPoller.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_SqlActivityFlush) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.SqlActivityFlush != nil {
		l = m.SqlActivityFlush.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_HotRangesLogger) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.HotRangesLogger != nil {
		l = m.HotRangesLogger.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Progress_Inspect) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Inspect != nil {
		l = m.Inspect.Size()
		n += 2 + l + sovJobs(uint64(l))
	}
	return n
}
func (m *Job) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Id != 0 {
		n += 1 + sovJobs(uint64(m.Id))
	}
	if m.Progress != nil {
		l = m.Progress.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.Payload != nil {
		l = m.Payload.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *RetriableExecutionFailure) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.Status)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	if m.ExecutionStartMicros != 0 {
		n += 1 + sovJobs(uint64(m.ExecutionStartMicros))
	}
	if m.ExecutionEndMicros != 0 {
		n += 1 + sovJobs(uint64(m.ExecutionEndMicros))
	}
	if m.InstanceID != 0 {
		n += 1 + sovJobs(uint64(m.InstanceID))
	}
	if m.Error != nil {
		l = m.Error.Size()
		n += 1 + l + sovJobs(uint64(l))
	}
	l = len(m.TruncatedError)
	if l > 0 {
		n += 1 + l + sovJobs(uint64(l))
	}
	return n
}

func (m *TraceData) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.CollectedSpans) > 0 {
		for _, e := range m.CollectedSpans {
			l = e.Size()
			n += 1 + l + sovJobs(uint64(l))
		}
	}
	return n
}

func sovJobs(x uint64) (n int) {
	return int((uint32(math_bits.Len64(x|1)+6) * 37) >> 8)
}
func sozJobs(x uint64) (n int) {
	return sovJobs(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (m *BackupEncryptionOptions) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: BackupEncryptionOptions: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: BackupEncryptionOptions: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Key = append(m.Key[:0], dAtA[iNdEx:postIndex]...)
			if m.Key == nil {
				m.Key = []byte{}
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Mode", wireType)
			}
			m.Mode = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Mode |= EncryptionMode(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field KMSInfo", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.KMSInfo == nil {
				m.KMSInfo = &BackupEncryptionOptions_KMSInfo{}
			}
			if err := m.KMSInfo.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RawPassphrase", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.RawPassphrase = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RawKmsUris", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.RawKmsUris = append(m.RawKmsUris, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *BackupEncryptionOptions_KMSInfo) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: KMSInfo: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: KMSInfo: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Uri", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Uri = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field EncryptedDataKey", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.EncryptedDataKey = append(m.EncryptedDataKey[:0], dAtA[iNdEx:postIndex]...)
			if m.EncryptedDataKey == nil {
				m.EncryptedDataKey = []byte{}
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *EncryptionInfo) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: EncryptionInfo: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: EncryptionInfo: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Scheme", wireType)
			}
			m.Scheme = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Scheme |= EncryptionInfo_Scheme(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Salt", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Salt = append(m.Salt[:0], dAtA[iNdEx:postIndex]...)
			if m.Salt == nil {
				m.Salt = []byte{}
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field EncryptedDataKeyByKMSMasterKeyID", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.EncryptedDataKeyByKMSMasterKeyID == nil {
				m.EncryptedDataKeyByKMSMasterKeyID = make(map[string][]byte)
			}
			var mapkey string
			mapvalue := []byte{}
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthJobs
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthJobs
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var mapbyteLen uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapbyteLen |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intMapbyteLen := int(mapbyteLen)
					if intMapbyteLen < 0 {
						return ErrInvalidLengthJobs
					}
					postbytesIndex := iNdEx + intMapbyteLen
					if postbytesIndex < 0 {
						return ErrInvalidLengthJobs
					}
					if postbytesIndex > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = make([]byte, mapbyteLen)
					copy(mapvalue, dAtA[iNdEx:postbytesIndex])
					iNdEx = postbytesIndex
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipJobs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthJobs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.EncryptedDataKeyByKMSMasterKeyID[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *StreamIngestionDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: StreamIngestionDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: StreamIngestionDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SourceClusterConnUri", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.SourceClusterConnUri = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Span", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Span.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field StreamID", wireType)
			}
			m.StreamID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.StreamID |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field DestinationTenantID", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.DestinationTenantID.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SourceTenantName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.SourceTenantName = github_com_cockroachdb_cockroach_pkg_roachpb.TenantName(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProtectedTimestampRecordID", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			var v github_com_cockroachdb_cockroach_pkg_util_uuid.UUID
			m.ProtectedTimestampRecordID = &v
			if err := m.ProtectedTimestampRecordID.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 11:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReplicationTTLSeconds", wireType)
			}
			m.ReplicationTTLSeconds = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ReplicationTTLSeconds |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 12:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReplicationStartTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ReplicationStartTime.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 13:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SourceTenantID", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.SourceTenantID.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 14:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SourceClusterID", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.SourceClusterID.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReadTenantID", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ReadTenantID.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *StreamIngestionCheckpoint) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: StreamIngestionCheckpoint: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: StreamIngestionCheckpoint: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ResolvedSpans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ResolvedSpans = append(m.ResolvedSpans, ResolvedSpan{})
			if err := m.ResolvedSpans[len(m.ResolvedSpans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *StreamIngestionProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: StreamIngestionProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: StreamIngestionProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CutoverTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.CutoverTime.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Checkpoint", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Checkpoint.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field PartitionConnUris", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.PartitionConnUris = append(m.PartitionConnUris, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReplicationStatus", wireType)
			}
			m.ReplicationStatus = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ReplicationStatus |= ReplicationStatus(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReplicatedTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ReplicatedTime.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RemainingCutoverSpans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.RemainingCutoverSpans = append(m.RemainingCutoverSpans, roachpb.Span{})
			if err := m.RemainingCutoverSpans[len(m.RemainingCutoverSpans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 9:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InitialSplitComplete", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.InitialSplitComplete = bool(v != 0)
		case 10:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InitialRevertRequired", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.InitialRevertRequired = bool(v != 0)
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InitialRevertTo", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.InitialRevertTo.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 12:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReplicatedTimeAtCutover", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ReplicatedTimeAtCutover.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *HistoryRetentionDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: HistoryRetentionDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: HistoryRetentionDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProtectedTimestampRecordID", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ProtectedTimestampRecordID.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExpirationWindow", wireType)
			}
			m.ExpirationWindow = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ExpirationWindow |= time.Duration(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *HistoryRetentionProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: HistoryRetentionProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: HistoryRetentionProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field LastHeartbeatTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := github_com_gogo_protobuf_types.StdTimeUnmarshal(&m.LastHeartbeatTime, dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *LogicalReplicationDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: LogicalReplicationDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: LogicalReplicationDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SourceClusterConnUri", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.SourceClusterConnUri = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableNames", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TableNames = append(m.TableNames, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReplicationPairs", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ReplicationPairs = append(m.ReplicationPairs, LogicalReplicationDetails_ReplicationPair{})
			if err := m.ReplicationPairs[len(m.ReplicationPairs)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field StreamID", wireType)
			}
			m.StreamID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.StreamID |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReplicationStartTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ReplicationStartTime.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SourceClusterID", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.SourceClusterID.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field DefaultConflictResolution", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.DefaultConflictResolution.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 9:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Mode", wireType)
			}
			m.Mode = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Mode |= LogicalReplicationDetails_ApplyMode(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field MetricsLabel", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.MetricsLabel = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 11:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Discard", wireType)
			}
			m.Discard = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Discard |= LogicalReplicationDetails_Discard(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 12:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field CreateTable", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.CreateTable = bool(v != 0)
		case 13:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field IngestedExternalCatalog", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.IngestedExternalCatalog.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 14:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReverseStreamCommand", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ReverseStreamCommand = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 15:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ParentID", wireType)
			}
			m.ParentID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ParentID |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 16:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Command", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Command = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 17:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SkipSchemaCheck", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.SkipSchemaCheck = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *LogicalReplicationDetails_ReplicationPair) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ReplicationPair: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ReplicationPair: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SrcDescriptorID", wireType)
			}
			m.SrcDescriptorID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.SrcDescriptorID |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DstDescriptorID", wireType)
			}
			m.DstDescriptorID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DstDescriptorID |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DstFunctionID", wireType)
			}
			m.DstFunctionID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DstFunctionID |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *LogicalReplicationDetails_DefaultConflictResolution) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: DefaultConflictResolution: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: DefaultConflictResolution: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ConflictResolutionType", wireType)
			}
			m.ConflictResolutionType = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ConflictResolutionType |= LogicalReplicationDetails_DefaultConflictResolution_DefaultConflictResolution(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field FunctionId", wireType)
			}
			m.FunctionId = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.FunctionId |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *LogicalReplicationProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: LogicalReplicationProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: LogicalReplicationProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReplicatedTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ReplicatedTime.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Checkpoint", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Checkpoint.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field PartitionConnUris", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.PartitionConnUris = append(m.PartitionConnUris, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 9:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field PublishedNewTables", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.PublishedNewTables = bool(v != 0)
		case 10:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field StartedReverseStream", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.StartedReverseStream = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *StreamReplicationDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: StreamReplicationDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: StreamReplicationDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Spans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Spans = append(m.Spans, roachpb.Span{})
			if err := m.Spans[len(m.Spans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProtectedTimestampRecordID", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ProtectedTimestampRecordID.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TenantID", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.TenantID.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExpirationWindow", wireType)
			}
			m.ExpirationWindow = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ExpirationWindow |= time.Duration(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType == 0 {
				var v uint32
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= uint32(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.TableIDs = append(m.TableIDs, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 {
					if m.TableIDs == nil {
						m.TableIDs = make([]uint32, 0, elementCount)
					} else {
						m.TableIDs = slices.Grow(m.TableIDs, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v uint32
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= uint32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.TableIDs = append(m.TableIDs, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field TableIDs", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *StreamReplicationProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: StreamReplicationProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: StreamReplicationProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Expiration", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := github_com_gogo_protobuf_types.StdTimeUnmarshal(&m.Expiration, dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field StreamIngestionStatus", wireType)
			}
			m.StreamIngestionStatus = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.StreamIngestionStatus |= StreamReplicationProgress_StreamIngestionStatus(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchedulePTSChainingRecord) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SchedulePTSChainingRecord: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SchedulePTSChainingRecord: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProtectedTimestampRecord", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			var v github_com_cockroachdb_cockroach_pkg_util_uuid.UUID
			m.ProtectedTimestampRecord = &v
			if err := m.ProtectedTimestampRecord.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Action", wireType)
			}
			m.Action = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Action |= SchedulePTSChainingRecord_PTSAction(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *BackupDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: BackupDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: BackupDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StartTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.StartTime.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field EndTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.EndTime.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field URI", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.URI = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field DeprecatedBackupManifest", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.DeprecatedBackupManifest = append(m.DeprecatedBackupManifest[:0], dAtA[iNdEx:postIndex]...)
			if m.DeprecatedBackupManifest == nil {
				m.DeprecatedBackupManifest = []byte{}
			}
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field URIsByLocalityKV", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.URIsByLocalityKV == nil {
				m.URIsByLocalityKV = make(map[string]string)
			}
			var mapkey string
			var mapvalue string
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthJobs
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthJobs
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var stringLenmapvalue uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapvalue |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapvalue := int(stringLenmapvalue)
					if intStringLenmapvalue < 0 {
						return ErrInvalidLengthJobs
					}
					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
					if postStringIndexmapvalue < 0 {
						return ErrInvalidLengthJobs
					}
					if postStringIndexmapvalue > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
					iNdEx = postStringIndexmapvalue
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipJobs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthJobs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.URIsByLocalityKV[mapkey] = mapvalue
			iNdEx = postIndex
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field EncryptionOptions", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.EncryptionOptions == nil {
				m.EncryptionOptions = &BackupEncryptionOptions{}
			}
			if err := m.EncryptionOptions.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProtectedTimestampRecord", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			var v github_com_cockroachdb_cockroach_pkg_util_uuid.UUID
			m.ProtectedTimestampRecord = &v
			if err := m.ProtectedTimestampRecord.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CollectionURI", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.CollectionURI = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 9:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field EncryptionInfo", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.EncryptionInfo == nil {
				m.EncryptionInfo = &EncryptionInfo{}
			}
			if err := m.EncryptionInfo.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SchedulePTSChainingRecord", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.SchedulePTSChainingRecord == nil {
				m.SchedulePTSChainingRecord = &SchedulePTSChainingRecord{}
			}
			if err := m.SchedulePTSChainingRecord.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Destination", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Destination.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 12:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ScheduleID", wireType)
			}
			m.ScheduleID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ScheduleID |= ScheduleID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 13:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field RevisionHistory", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.RevisionHistory = bool(v != 0)
		case 15:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field FullCluster", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.FullCluster = bool(v != 0)
		case 17:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ResolvedTargets", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ResolvedTargets = append(m.ResolvedTargets, descpb.Descriptor{})
			if err := m.ResolvedTargets[len(m.ResolvedTargets)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 18:
			if wireType == 0 {
				var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.ResolvedCompleteDbs = append(m.ResolvedCompleteDbs, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 {
					if m.ResolvedCompleteDbs == nil {
						m.ResolvedCompleteDbs = make([]github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID, 0, elementCount)
					} else {
						m.ResolvedCompleteDbs = slices.Grow(m.ResolvedCompleteDbs, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.ResolvedCompleteDbs = append(m.ResolvedCompleteDbs, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field ResolvedCompleteDbs", wireType)
			}
		case 19:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SpecificTenantIds", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.SpecificTenantIds = append(m.SpecificTenantIds, roachpb.TenantID{})
			if err := m.SpecificTenantIds[len(m.SpecificTenantIds)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 20:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RequestedTargets", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.RequestedTargets = append(m.RequestedTargets, descpb.Descriptor{})
			if err := m.RequestedTargets[len(m.RequestedTargets)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 21:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Detached", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Detached = bool(v != 0)
		case 22:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field AsOfInterval", wireType)
			}
			m.AsOfInterval = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.AsOfInterval |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 23:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ApplicationName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ApplicationName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 24:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExecutionLocality", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ExecutionLocality.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 25:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field IncludeAllSecondaryTenants", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.IncludeAllSecondaryTenants = bool(v != 0)
		case 26:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UpdatesClusterMonitoringMetrics", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.UpdatesClusterMonitoringMetrics = bool(v != 0)
		case 27:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Compact", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Compact = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *BackupDetails_Destination) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Destination: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Destination: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field To", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.To = append(m.To, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Subdir", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Subdir = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field IncrementalStorage", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.IncrementalStorage = append(m.IncrementalStorage, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Exists", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Exists = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *BackupProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: BackupProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: BackupProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *DescriptorRewrite) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: DescriptorRewrite: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: DescriptorRewrite: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ID", wireType)
			}
			m.ID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ParentID", wireType)
			}
			m.ParentID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ParentID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ToExisting", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.ToExisting = bool(v != 0)
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field NewDBName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.NewDBName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ParentSchemaID", wireType)
			}
			m.ParentSchemaID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ParentSchemaID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *RestoreDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: RestoreDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: RestoreDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field DescriptorRewrites", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.DescriptorRewrites == nil {
				m.DescriptorRewrites = make(map[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID]*DescriptorRewrite)
			}
			var mapkey uint32
			var mapvalue *DescriptorRewrite
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapkey |= uint32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else if fieldNum == 2 {
					var mapmsglen int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapmsglen |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					if mapmsglen < 0 {
						return ErrInvalidLengthJobs
					}
					postmsgIndex := iNdEx + mapmsglen
					if postmsgIndex < 0 {
						return ErrInvalidLengthJobs
					}
					if postmsgIndex > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = &DescriptorRewrite{}
					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
						return err
					}
					iNdEx = postmsgIndex
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipJobs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthJobs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.DescriptorRewrites[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(mapkey)] = mapvalue
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field URIs", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.URIs = append(m.URIs, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field EndTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.EndTime.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableDescs", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TableDescs = append(m.TableDescs, &descpb.TableDescriptor{})
			if err := m.TableDescs[len(m.TableDescs)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OverrideDB", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.OverrideDB = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field BackupLocalityInfo", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.BackupLocalityInfo = append(m.BackupLocalityInfo, RestoreDetails_BackupLocalityInfo{})
			if err := m.BackupLocalityInfo[len(m.BackupLocalityInfo)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 8:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field PrepareCompleted", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.PrepareCompleted = bool(v != 0)
		case 9:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field StatsInserted", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.StatsInserted = bool(v != 0)
		case 10:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DescriptorsPublished", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.DescriptorsPublished = bool(v != 0)
		case 11:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DescriptorCoverage", wireType)
			}
			m.DescriptorCoverage = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DescriptorCoverage |= github_com_cockroachdb_cockroach_pkg_sql_sem_tree.DescriptorCoverage(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 12:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Encryption", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Encryption == nil {
				m.Encryption = &BackupEncryptionOptions{}
			}
			if err := m.Encryption.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 14:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TypeDescs", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TypeDescs = append(m.TypeDescs, &descpb.TypeDescriptor{})
			if err := m.TypeDescs[len(m.TypeDescs)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SchemaDescs", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.SchemaDescs = append(m.SchemaDescs, &descpb.SchemaDescriptor{})
			if err := m.SchemaDescs[len(m.SchemaDescs)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 16:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field DatabaseDescs", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.DatabaseDescs = append(m.DatabaseDescs, &descpb.DatabaseDescriptor{})
			if err := m.DatabaseDescs[len(m.DatabaseDescs)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 17:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SystemTablesMigrated", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.SystemTablesMigrated == nil {
				m.SystemTablesMigrated = make(map[string]bool)
			}
			var mapkey string
			var mapvalue bool
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthJobs
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthJobs
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var mapvaluetemp int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapvaluetemp |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					mapvalue = bool(mapvaluetemp != 0)
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipJobs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthJobs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.SystemTablesMigrated[mapkey] = mapvalue
			iNdEx = postIndex
		case 19:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field DatabaseModifiers", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.DatabaseModifiers == nil {
				m.DatabaseModifiers = make(map[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID]*RestoreDetails_DatabaseModifier)
			}
			var mapkey uint32
			var mapvalue *RestoreDetails_DatabaseModifier
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapkey |= uint32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else if fieldNum == 2 {
					var mapmsglen int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapmsglen |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					if mapmsglen < 0 {
						return ErrInvalidLengthJobs
					}
					postmsgIndex := iNdEx + mapmsglen
					if postmsgIndex < 0 {
						return ErrInvalidLengthJobs
					}
					if postmsgIndex > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = &RestoreDetails_DatabaseModifier{}
					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
						return err
					}
					iNdEx = postmsgIndex
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipJobs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthJobs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.DatabaseModifiers[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(mapkey)] = mapvalue
			iNdEx = postIndex
		case 21:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tenants", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Tenants = append(m.Tenants, mtinfopb.TenantInfoWithUsage{})
			if err := m.Tenants[len(m.Tenants)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 22:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field RestoreSystemUsers", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.RestoreSystemUsers = bool(v != 0)
		case 23:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field PreRewriteTenantId", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.PreRewriteTenantId == nil {
				m.PreRewriteTenantId = &roachpb.TenantID{}
			}
			if err := m.PreRewriteTenantId.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 25:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SchemaOnly", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.SchemaOnly = bool(v != 0)
		case 26:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field VerifyData", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.VerifyData = bool(v != 0)
		case 27:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field FunctionDescs", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.FunctionDescs = append(m.FunctionDescs, &descpb.FunctionDescriptor{})
			if err := m.FunctionDescs[len(m.FunctionDescs)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 28:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProtectedTimestampRecord", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			var v github_com_cockroachdb_cockroach_pkg_util_uuid.UUID
			m.ProtectedTimestampRecord = &v
			if err := m.ProtectedTimestampRecord.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 29:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SkipLocalitiesCheck", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.SkipLocalitiesCheck = bool(v != 0)
		case 30:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExecutionLocality", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ExecutionLocality.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 31:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExperimentalOnline", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.ExperimentalOnline = bool(v != 0)
		case 32:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field DownloadSpans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.DownloadSpans = append(m.DownloadSpans, roachpb.Span{})
			if err := m.DownloadSpans[len(m.DownloadSpans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 33:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field RemoveRegions", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.RemoveRegions = bool(v != 0)
		case 34:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UnsafeRestoreIncompatibleVersion", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.UnsafeRestoreIncompatibleVersion = bool(v != 0)
		case 35:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field PostDownloadTableAutoStatsSettings", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.PostDownloadTableAutoStatsSettings == nil {
				m.PostDownloadTableAutoStatsSettings = make(map[uint32]*catpb.AutoStatsSettings)
			}
			var mapkey uint32
			var mapvalue *catpb.AutoStatsSettings
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapkey |= uint32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else if fieldNum == 2 {
					var mapmsglen int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapmsglen |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					if mapmsglen < 0 {
						return ErrInvalidLengthJobs
					}
					postmsgIndex := iNdEx + mapmsglen
					if postmsgIndex < 0 {
						return ErrInvalidLengthJobs
					}
					if postmsgIndex > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = &catpb.AutoStatsSettings{}
					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
						return err
					}
					iNdEx = postmsgIndex
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipJobs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthJobs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.PostDownloadTableAutoStatsSettings[mapkey] = mapvalue
			iNdEx = postIndex
		case 36:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DownloadJob", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.DownloadJob = bool(v != 0)
		case 37:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExperimentalCopy", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.ExperimentalCopy = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *RestoreDetails_BackupLocalityInfo) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: BackupLocalityInfo: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: BackupLocalityInfo: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field URIsByOriginalLocalityKV", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.URIsByOriginalLocalityKV == nil {
				m.URIsByOriginalLocalityKV = make(map[string]string)
			}
			var mapkey string
			var mapvalue string
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthJobs
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthJobs
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var stringLenmapvalue uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapvalue |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapvalue := int(stringLenmapvalue)
					if intStringLenmapvalue < 0 {
						return ErrInvalidLengthJobs
					}
					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
					if postStringIndexmapvalue < 0 {
						return ErrInvalidLengthJobs
					}
					if postStringIndexmapvalue > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
					iNdEx = postStringIndexmapvalue
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipJobs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthJobs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.URIsByOriginalLocalityKV[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *RestoreDetails_DatabaseModifier) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: DatabaseModifier: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: DatabaseModifier: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExtraTypeDescs", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ExtraTypeDescs = append(m.ExtraTypeDescs, &descpb.TypeDescriptor{})
			if err := m.ExtraTypeDescs[len(m.ExtraTypeDescs)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RegionConfig", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.RegionConfig == nil {
				m.RegionConfig = &descpb.DatabaseDescriptor_RegionConfig{}
			}
			if err := m.RegionConfig.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *RestoreProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: RestoreProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: RestoreProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field HighWater", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.HighWater = append(m.HighWater[:0], dAtA[iNdEx:postIndex]...)
			if m.HighWater == nil {
				m.HighWater = []byte{}
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Checkpoint", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Checkpoint = append(m.Checkpoint, RestoreProgress_FrontierEntry{})
			if err := m.Checkpoint[len(m.Checkpoint)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TotalDownloadRequired", wireType)
			}
			m.TotalDownloadRequired = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TotalDownloadRequired |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *RestoreProgress_FrontierEntry) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: FrontierEntry: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: FrontierEntry: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Span", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Span.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Timestamp", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Timestamp.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ImportDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ImportDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ImportDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tables", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Tables = append(m.Tables, ImportDetails_Table{})
			if err := m.Tables[len(m.Tables)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field URIs", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.URIs = append(m.URIs, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Format", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Format.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Walltime", wireType)
			}
			m.Walltime = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Walltime |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ParentID", wireType)
			}
			m.ParentID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ParentID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 12:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field PrepareComplete", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.PrepareComplete = bool(v != 0)
		case 13:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TablesPublished", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.TablesPublished = bool(v != 0)
		case 26:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Types", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Types = append(m.Types, ImportDetails_Type{})
			if err := m.Types[len(m.Types)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 27:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field DatabasePrimaryRegion", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.DatabasePrimaryRegion = github_com_cockroachdb_cockroach_pkg_sql_catalog_catpb.RegionName(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ImportDetails_Table) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Table: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Table: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Desc", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Desc == nil {
				m.Desc = &descpb.TableDescriptor{}
			}
			if err := m.Desc.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 18:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Name = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 19:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SeqVal", wireType)
			}
			m.SeqVal = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.SeqVal |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 21:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TargetCols", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TargetCols = append(m.TargetCols, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 22:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field WasEmpty", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.WasEmpty = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ImportDetails_Type) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Type: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Type: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Desc", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Desc == nil {
				m.Desc = &descpb.TypeDescriptor{}
			}
			if err := m.Desc.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SequenceValChunk) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SequenceValChunk: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SequenceValChunk: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ChunkStartVal", wireType)
			}
			m.ChunkStartVal = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ChunkStartVal |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ChunkSize", wireType)
			}
			m.ChunkSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ChunkSize |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ChunkStartRow", wireType)
			}
			m.ChunkStartRow = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ChunkStartRow |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field NextChunkStartRow", wireType)
			}
			m.NextChunkStartRow = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.NextChunkStartRow |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SequenceDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SequenceDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SequenceDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SeqIdToChunks", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.SeqIdToChunks == nil {
				m.SeqIdToChunks = make(map[int32]*SequenceDetails_SequenceChunks)
			}
			var mapkey int32
			var mapvalue *SequenceDetails_SequenceChunks
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapkey |= int32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else if fieldNum == 2 {
					var mapmsglen int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapmsglen |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					if mapmsglen < 0 {
						return ErrInvalidLengthJobs
					}
					postmsgIndex := iNdEx + mapmsglen
					if postmsgIndex < 0 {
						return ErrInvalidLengthJobs
					}
					if postmsgIndex > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = &SequenceDetails_SequenceChunks{}
					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
						return err
					}
					iNdEx = postmsgIndex
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipJobs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthJobs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.SeqIdToChunks[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SequenceDetails_SequenceChunks) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SequenceChunks: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SequenceChunks: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Chunks", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Chunks = append(m.Chunks, &SequenceValChunk{})
			if err := m.Chunks[len(m.Chunks)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ImportProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ImportProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ImportProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 5 {
				var v uint32
				if (iNdEx + 4) > l {
					return io.ErrUnexpectedEOF
				}
				v = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))
				iNdEx += 4
				v2 := float32(math.Float32frombits(v))
				m.SamplingProgress = append(m.SamplingProgress, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				elementCount = packedLen / 4
				if elementCount != 0 {
					if m.SamplingProgress == nil {
						m.SamplingProgress = make([]float32, 0, elementCount)
					} else {
						m.SamplingProgress = slices.Grow(m.SamplingProgress, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v uint32
					if (iNdEx + 4) > l {
						return io.ErrUnexpectedEOF
					}
					v = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))
					iNdEx += 4
					v2 := float32(math.Float32frombits(v))
					m.SamplingProgress = append(m.SamplingProgress, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field SamplingProgress", wireType)
			}
		case 2:
			if wireType == 5 {
				var v uint32
				if (iNdEx + 4) > l {
					return io.ErrUnexpectedEOF
				}
				v = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))
				iNdEx += 4
				v2 := float32(math.Float32frombits(v))
				m.ReadProgress = append(m.ReadProgress, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				elementCount = packedLen / 4
				if elementCount != 0 {
					if m.ReadProgress == nil {
						m.ReadProgress = make([]float32, 0, elementCount)
					} else {
						m.ReadProgress = slices.Grow(m.ReadProgress, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v uint32
					if (iNdEx + 4) > l {
						return io.ErrUnexpectedEOF
					}
					v = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))
					iNdEx += 4
					v2 := float32(math.Float32frombits(v))
					m.ReadProgress = append(m.ReadProgress, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field ReadProgress", wireType)
			}
		case 3:
			if wireType == 5 {
				var v uint32
				if (iNdEx + 4) > l {
					return io.ErrUnexpectedEOF
				}
				v = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))
				iNdEx += 4
				v2 := float32(math.Float32frombits(v))
				m.WriteProgress = append(m.WriteProgress, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				elementCount = packedLen / 4
				if elementCount != 0 {
					if m.WriteProgress == nil {
						m.WriteProgress = make([]float32, 0, elementCount)
					} else {
						m.WriteProgress = slices.Grow(m.WriteProgress, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v uint32
					if (iNdEx + 4) > l {
						return io.ErrUnexpectedEOF
					}
					v = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))
					iNdEx += 4
					v2 := float32(math.Float32frombits(v))
					m.WriteProgress = append(m.WriteProgress, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field WriteProgress", wireType)
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SpanProgress", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.SpanProgress = append(m.SpanProgress, roachpb.Span{})
			if err := m.SpanProgress[len(m.SpanProgress)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType == 0 {
				var v int64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= int64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.ResumePos = append(m.ResumePos, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 {
					if m.ResumePos == nil {
						m.ResumePos = make([]int64, 0, elementCount)
					} else {
						m.ResumePos = slices.Grow(m.ResumePos, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v int64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= int64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.ResumePos = append(m.ResumePos, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field ResumePos", wireType)
			}
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SequenceDetails", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.SequenceDetails = append(m.SequenceDetails, &SequenceDetails{})
			if err := m.SequenceDetails[len(m.SequenceDetails)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Summary", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Summary.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *TypeSchemaChangeDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TypeSchemaChangeDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TypeSchemaChangeDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TypeID", wireType)
			}
			m.TypeID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TypeID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TransitioningMembers", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TransitioningMembers = append(m.TransitioningMembers, make([]byte, postIndex-iNdEx))
			copy(m.TransitioningMembers[len(m.TransitioningMembers)-1], dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *TypeSchemaChangeProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TypeSchemaChangeProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TypeSchemaChangeProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NewSchemaChangeDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NewSchemaChangeDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NewSchemaChangeDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field BackfillProgress", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.BackfillProgress = append(m.BackfillProgress, BackfillProgress{})
			if err := m.BackfillProgress[len(m.BackfillProgress)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field MergeProgress", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.MergeProgress = append(m.MergeProgress, MergeProgress{})
			if err := m.MergeProgress[len(m.MergeProgress)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProtectedTimestampRecord", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			var v github_com_cockroachdb_cockroach_pkg_util_uuid.UUID
			m.ProtectedTimestampRecord = &v
			if err := m.ProtectedTimestampRecord.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *BackfillProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: BackfillProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: BackfillProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableID", wireType)
			}
			m.TableID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TableID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SourceIndexID", wireType)
			}
			m.SourceIndexID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.SourceIndexID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType == 0 {
				var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.DestIndexIDs = append(m.DestIndexIDs, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 {
					if m.DestIndexIDs == nil {
						m.DestIndexIDs = make([]github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID, 0, elementCount)
					} else {
						m.DestIndexIDs = slices.Grow(m.DestIndexIDs, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.DestIndexIDs = append(m.DestIndexIDs, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DestIndexIDs", wireType)
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field WriteTimestamp", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.WriteTimestamp.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CompletedSpans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.CompletedSpans = append(m.CompletedSpans, roachpb.Span{})
			if err := m.CompletedSpans[len(m.CompletedSpans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MergeProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MergeProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MergeProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableID", wireType)
			}
			m.TableID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TableID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field MergePairs", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.MergePairs = append(m.MergePairs, MergeProgress_MergePair{})
			if err := m.MergePairs[len(m.MergePairs)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MergeProgress_MergePair) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MergePair: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MergePair: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SourceIndexID", wireType)
			}
			m.SourceIndexID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.SourceIndexID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DestIndexID", wireType)
			}
			m.DestIndexID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DestIndexID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CompletedSpans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.CompletedSpans = append(m.CompletedSpans, roachpb.Span{})
			if err := m.CompletedSpans[len(m.CompletedSpans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NewSchemaChangeProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NewSchemaChangeProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NewSchemaChangeProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoSpanConfigReconciliationDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoSpanConfigReconciliationDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoSpanConfigReconciliationDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoSpanConfigReconciliationProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoSpanConfigReconciliationProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoSpanConfigReconciliationProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Checkpoint", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Checkpoint.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *KeyVisualizerDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: KeyVisualizerDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: KeyVisualizerDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *KeyVisualizerProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: KeyVisualizerProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: KeyVisualizerProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ResumeSpanList) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ResumeSpanList: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ResumeSpanList: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ResumeSpans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ResumeSpans = append(m.ResumeSpans, roachpb.Span{})
			if err := m.ResumeSpans[len(m.ResumeSpans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *DroppedTableDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: DroppedTableDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: DroppedTableDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Name = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ID", wireType)
			}
			m.ID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Status", wireType)
			}
			m.Status = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Status |= Status(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaChangeGCDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SchemaChangeGCDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SchemaChangeGCDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Indexes", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Indexes = append(m.Indexes, SchemaChangeGCDetails_DroppedIndex{})
			if err := m.Indexes[len(m.Indexes)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tables", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Tables = append(m.Tables, SchemaChangeGCDetails_DroppedID{})
			if err := m.Tables[len(m.Tables)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ParentID", wireType)
			}
			m.ParentID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ParentID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tenant", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Tenant == nil {
				m.Tenant = &SchemaChangeGCDetails_DroppedTenant{}
			}
			if err := m.Tenant.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaChangeGCDetails_DroppedIndex) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: DroppedIndex: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: DroppedIndex: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field IndexID", wireType)
			}
			m.IndexID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.IndexID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DropTime", wireType)
			}
			m.DropTime = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DropTime |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaChangeGCDetails_DroppedID) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: DroppedID: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: DroppedID: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ID", wireType)
			}
			m.ID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DropTime", wireType)
			}
			m.DropTime = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DropTime |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaChangeGCDetails_DroppedTenant) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: DroppedTenant: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: DroppedTenant: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ID", wireType)
			}
			m.ID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ID |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DropTime", wireType)
			}
			m.DropTime = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DropTime |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaChangeDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SchemaChangeDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SchemaChangeDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ResumeSpanList", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ResumeSpanList = append(m.ResumeSpanList, ResumeSpanList{})
			if err := m.ResumeSpanList[len(m.ResumeSpanList)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field DroppedTables", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.DroppedTables = append(m.DroppedTables, DroppedTableDetails{})
			if err := m.DroppedTables[len(m.DroppedTables)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DroppedDatabaseID", wireType)
			}
			m.DroppedDatabaseID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DroppedDatabaseID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DescID", wireType)
			}
			m.DescID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DescID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableMutationID", wireType)
			}
			m.TableMutationID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TableMutationID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.MutationID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 7:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field FormatVersion", wireType)
			}
			m.FormatVersion = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.FormatVersion |= SchemaChangeDetailsFormatVersion(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 8:
			if wireType == 0 {
				var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.DroppedTypes = append(m.DroppedTypes, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 {
					if m.DroppedTypes == nil {
						m.DroppedTypes = make([]github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID, 0, elementCount)
					} else {
						m.DroppedTypes = slices.Grow(m.DroppedTypes, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.DroppedTypes = append(m.DroppedTypes, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DroppedTypes", wireType)
			}
		case 9:
			if wireType == 0 {
				var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.DroppedSchemas = append(m.DroppedSchemas, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 {
					if m.DroppedSchemas == nil {
						m.DroppedSchemas = make([]github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID, 0, elementCount)
					} else {
						m.DroppedSchemas = slices.Grow(m.DroppedSchemas, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.DroppedSchemas = append(m.DroppedSchemas, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DroppedSchemas", wireType)
			}
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field WriteTimestamp", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.WriteTimestamp.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProtectedTimestampRecord", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			var v github_com_cockroachdb_cockroach_pkg_util_uuid.UUID
			m.ProtectedTimestampRecord = &v
			if err := m.ProtectedTimestampRecord.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 12:
			if wireType == 0 {
				var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.DroppedFunctions = append(m.DroppedFunctions, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 {
					if m.DroppedFunctions == nil {
						m.DroppedFunctions = make([]github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID, 0, elementCount)
					} else {
						m.DroppedFunctions = slices.Grow(m.DroppedFunctions, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.DroppedFunctions = append(m.DroppedFunctions, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DroppedFunctions", wireType)
			}
		case 13:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SessionData", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.SessionData == nil {
				m.SessionData = &sessiondatapb.SessionData{}
			}
			if err := m.SessionData.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaChangeProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SchemaChangeProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SchemaChangeProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaChangeGCProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SchemaChangeGCProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SchemaChangeGCProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Indexes", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Indexes = append(m.Indexes, SchemaChangeGCProgress_IndexProgress{})
			if err := m.Indexes[len(m.Indexes)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tables", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Tables = append(m.Tables, SchemaChangeGCProgress_TableProgress{})
			if err := m.Tables[len(m.Tables)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tenant", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Tenant == nil {
				m.Tenant = &SchemaChangeGCProgress_TenantProgress{}
			}
			if err := m.Tenant.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field RangesUnsplitDone", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.RangesUnsplitDone = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaChangeGCProgress_IndexProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: IndexProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: IndexProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field IndexID", wireType)
			}
			m.IndexID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.IndexID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Status", wireType)
			}
			m.Status = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Status |= SchemaChangeGCProgress_Status(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaChangeGCProgress_TableProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TableProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TableProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ID", wireType)
			}
			m.ID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Status", wireType)
			}
			m.Status = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Status |= SchemaChangeGCProgress_Status(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaChangeGCProgress_TenantProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TenantProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TenantProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Status", wireType)
			}
			m.Status = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Status |= SchemaChangeGCProgress_Status(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ChangefeedTargetTable) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ChangefeedTargetTable: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ChangefeedTargetTable: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StatementTimeName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.StatementTimeName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ChangefeedTargetSpecification) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ChangefeedTargetSpecification: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ChangefeedTargetSpecification: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
			}
			m.Type = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Type |= ChangefeedTargetSpecification_TargetType(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DescID", wireType)
			}
			m.DescID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DescID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field FamilyName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.FamilyName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StatementTimeName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.StatementTimeName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ChangefeedDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ChangefeedDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ChangefeedDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SinkURI", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.SinkURI = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Opts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Opts == nil {
				m.Opts = make(map[string]string)
			}
			var mapkey string
			var mapvalue string
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthJobs
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthJobs
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var stringLenmapvalue uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapvalue |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapvalue := int(stringLenmapvalue)
					if intStringLenmapvalue < 0 {
						return ErrInvalidLengthJobs
					}
					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
					if postStringIndexmapvalue < 0 {
						return ErrInvalidLengthJobs
					}
					if postStringIndexmapvalue > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
					iNdEx = postStringIndexmapvalue
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipJobs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthJobs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.Opts[mapkey] = mapvalue
			iNdEx = postIndex
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tables", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Tables == nil {
				m.Tables = make(ChangefeedTargets)
			}
			var mapkey uint32
			mapvalue := &ChangefeedTargetTable{}
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapkey |= uint32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else if fieldNum == 2 {
					var mapmsglen int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapmsglen |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					if mapmsglen < 0 {
						return ErrInvalidLengthJobs
					}
					postmsgIndex := iNdEx + mapmsglen
					if postmsgIndex < 0 {
						return ErrInvalidLengthJobs
					}
					if postmsgIndex > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = &ChangefeedTargetTable{}
					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
						return err
					}
					iNdEx = postmsgIndex
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipJobs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthJobs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.Tables[github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(mapkey)] = *mapvalue
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StatementTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.StatementTime.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TargetSpecifications", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TargetSpecifications = append(m.TargetSpecifications, ChangefeedTargetSpecification{})
			if err := m.TargetSpecifications[len(m.TargetSpecifications)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 9:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field EndTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.EndTime.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Select", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Select = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SessionData", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.SessionData == nil {
				m.SessionData = &sessiondatapb.SessionData{}
			}
			if err := m.SessionData.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ResolvedSpan) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ResolvedSpan: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ResolvedSpan: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Span", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Span.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Timestamp", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Timestamp.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field BoundaryType", wireType)
			}
			m.BoundaryType = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.BoundaryType |= ResolvedSpan_BoundaryType(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ResolvedSpans) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ResolvedSpans: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ResolvedSpans: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ResolvedSpans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ResolvedSpans = append(m.ResolvedSpans, ResolvedSpan{})
			if err := m.ResolvedSpans[len(m.ResolvedSpans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Stats", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Stats.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ResolvedSpans_Stats) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Stats: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Stats: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field RecentKvCount", wireType)
			}
			m.RecentKvCount = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.RecentKvCount |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *TimestampSpansMap) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TimestampSpansMap: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TimestampSpansMap: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Entries", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Entries = append(m.Entries, TimestampSpansMap_Entry{})
			if err := m.Entries[len(m.Entries)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *TimestampSpansMap_Entry) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Entry: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Entry: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Timestamp", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Timestamp.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Spans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Spans = append(m.Spans, roachpb.Span{})
			if err := m.Spans[len(m.Spans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ChangefeedProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ChangefeedProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ChangefeedProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProtectedTimestampRecord", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.ProtectedTimestampRecord.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SpanLevelCheckpoint", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.SpanLevelCheckpoint == nil {
				m.SpanLevelCheckpoint = &TimestampSpansMap{}
			}
			if err := m.SpanLevelCheckpoint.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *CreateStatsDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: CreateStatsDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: CreateStatsDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Name = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Table", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Table.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ColumnStats", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ColumnStats = append(m.ColumnStats, CreateStatsDetails_ColStat{})
			if err := m.ColumnStats[len(m.ColumnStats)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Statement", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Statement = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AsOf", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.AsOf == nil {
				m.AsOf = &hlc.Timestamp{}
			}
			if err := m.AsOf.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field FQTableName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.FQTableName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 7:
			if wireType != 1 {
				return fmt.Errorf("proto: wrong wireType = %d for field MaxFractionIdle", wireType)
			}
			var v uint64
			if (iNdEx + 8) > l {
				return io.ErrUnexpectedEOF
			}
			v = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))
			iNdEx += 8
			m.MaxFractionIdle = float64(math.Float64frombits(v))
		case 8:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DeleteOtherStats", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.DeleteOtherStats = bool(v != 0)
		case 9:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UsingExtremes", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.UsingExtremes = bool(v != 0)
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field WhereClause", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.WhereClause = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field WhereSpans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.WhereSpans = append(m.WhereSpans, roachpb.Span{})
			if err := m.WhereSpans[len(m.WhereSpans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 12:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field WhereIndexID", wireType)
			}
			m.WhereIndexID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.WhereIndexID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *CreateStatsDetails_ColStat) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ColStat: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ColStat: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 0 {
				var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ColumnID
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ColumnID(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.ColumnIDs = append(m.ColumnIDs, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 {
					if m.ColumnIDs == nil {
						m.ColumnIDs = make([]github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ColumnID, 0, elementCount)
					} else {
						m.ColumnIDs = slices.Grow(m.ColumnIDs, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ColumnID
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ColumnID(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.ColumnIDs = append(m.ColumnIDs, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field ColumnIDs", wireType)
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HasHistogram", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.HasHistogram = bool(v != 0)
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Inverted", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Inverted = bool(v != 0)
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HistogramMaxBuckets", wireType)
			}
			m.HistogramMaxBuckets = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.HistogramMaxBuckets |= uint32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *CreateStatsProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: CreateStatsProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: CreateStatsProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MigrationDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MigrationDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MigrationDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ClusterVersion", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.ClusterVersion == nil {
				m.ClusterVersion = &clusterversion.ClusterVersion{}
			}
			if err := m.ClusterVersion.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MigrationProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MigrationProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MigrationProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Watermark", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Watermark = append(m.Watermark[:0], dAtA[iNdEx:postIndex]...)
			if m.Watermark == nil {
				m.Watermark = []byte{}
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoSQLStatsCompactionDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoSQLStatsCompactionDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoSQLStatsCompactionDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoSQLStatsCompactionProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoSQLStatsCompactionProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoSQLStatsCompactionProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *RowLevelTTLDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: RowLevelTTLDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: RowLevelTTLDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableID", wireType)
			}
			m.TableID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TableID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Cutoff", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := github_com_gogo_protobuf_types.StdTimeUnmarshal(&m.Cutoff, dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableVersion", wireType)
			}
			m.TableVersion = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TableVersion |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.DescriptorVersion(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *RowLevelTTLProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: RowLevelTTLProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: RowLevelTTLProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field JobDeletedRowCount", wireType)
			}
			m.JobDeletedRowCount = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.JobDeletedRowCount |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProcessorProgresses", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ProcessorProgresses = append(m.ProcessorProgresses, RowLevelTTLProcessorProgress{})
			if err := m.ProcessorProgresses[len(m.ProcessorProgresses)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field JobTotalSpanCount", wireType)
			}
			m.JobTotalSpanCount = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.JobTotalSpanCount |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field JobProcessedSpanCount", wireType)
			}
			m.JobProcessedSpanCount = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.JobProcessedSpanCount |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *RowLevelTTLProcessorProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: RowLevelTTLProcessorProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: RowLevelTTLProcessorProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProcessorID", wireType)
			}
			m.ProcessorID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ProcessorID |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SQLInstanceID", wireType)
			}
			m.SQLInstanceID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.SQLInstanceID |= github_com_cockroachdb_cockroach_pkg_base.SQLInstanceID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DeletedRowCount", wireType)
			}
			m.DeletedRowCount = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DeletedRowCount |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TotalSpanCount", wireType)
			}
			m.TotalSpanCount = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TotalSpanCount |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProcessorConcurrency", wireType)
			}
			m.ProcessorConcurrency = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ProcessorConcurrency |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ProcessedSpanCount", wireType)
			}
			m.ProcessedSpanCount = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ProcessedSpanCount |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaTelemetryDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SchemaTelemetryDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SchemaTelemetryDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SchemaTelemetryProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SchemaTelemetryProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SchemaTelemetryProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *PollJobsStatsDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: PollJobsStatsDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: PollJobsStatsDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *PollJobsStatsProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: PollJobsStatsProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: PollJobsStatsProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoConfigRunnerDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoConfigRunnerDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoConfigRunnerDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoConfigRunnerProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoConfigRunnerProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoConfigRunnerProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoConfigEnvRunnerDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoConfigEnvRunnerDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoConfigEnvRunnerDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoConfigEnvRunnerProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoConfigEnvRunnerProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoConfigEnvRunnerProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoConfigTaskDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoConfigTaskDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoConfigTaskDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoConfigTaskProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoConfigTaskProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoConfigTaskProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoUpdateSQLActivityDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoUpdateSQLActivityDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoUpdateSQLActivityDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AutoUpdateSQLActivityProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AutoUpdateSQLActivityProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AutoUpdateSQLActivityProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MVCCStatisticsJobDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MVCCStatisticsJobDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MVCCStatisticsJobDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MVCCStatisticsJobProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MVCCStatisticsJobProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MVCCStatisticsJobProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *StandbyReadTSPollerDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: StandbyReadTSPollerDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: StandbyReadTSPollerDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *StandbyReadTSPollerProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: StandbyReadTSPollerProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: StandbyReadTSPollerProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *HotRangesLoggerDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: HotRangesLoggerDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: HotRangesLoggerDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *InspectDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: InspectDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: InspectDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Checks", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Checks = append(m.Checks, &InspectDetails_Check{})
			if err := m.Checks[len(m.Checks)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AsOf", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.AsOf.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *InspectDetails_Check) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Check: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Check: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
			}
			m.Type = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Type |= InspectDetails_Check_InspectCheckType(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableID", wireType)
			}
			m.TableID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TableID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field IndexID", wireType)
			}
			m.IndexID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.IndexID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.IndexID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *UpdateTableMetadataCacheDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: UpdateTableMetadataCacheDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: UpdateTableMetadataCacheDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *UpdateTableMetadataCacheProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: UpdateTableMetadataCacheProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: UpdateTableMetadataCacheProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field LastStartTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.LastStartTime == nil {
				m.LastStartTime = new(time.Time)
			}
			if err := github_com_gogo_protobuf_types.StdTimeUnmarshal(m.LastStartTime, dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field LastCompletedTime", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.LastCompletedTime == nil {
				m.LastCompletedTime = new(time.Time)
			}
			if err := github_com_gogo_protobuf_types.StdTimeUnmarshal(m.LastCompletedTime, dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Status", wireType)
			}
			m.Status = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Status |= UpdateTableMetadataCacheProgress_Status(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ImportRollbackDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ImportRollbackDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ImportRollbackDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableID", wireType)
			}
			m.TableID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TableID |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SqlActivityFlushDetails) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SqlActivityFlushDetails: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SqlActivityFlushDetails: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SqlActivityFlushProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SqlActivityFlushProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SqlActivityFlushProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *HotRangesLoggerProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: HotRangesLoggerProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: HotRangesLoggerProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *InspectProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: InspectProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: InspectProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ImportRollbackProgress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ImportRollbackProgress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ImportRollbackProgress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *Payload) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Payload: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Payload: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Description", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Description = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field UsernameProto", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.UsernameProto = github_com_cockroachdb_cockroach_pkg_security_username.SQLUsernameProto(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field StartedMicros", wireType)
			}
			m.StartedMicros = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.StartedMicros |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field FinishedMicros", wireType)
			}
			m.FinishedMicros = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.FinishedMicros |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType == 0 {
				var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.DescriptorIDs = append(m.DescriptorIDs, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowJobs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= int(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthJobs
				}
				postIndex := iNdEx + packedLen
				if postIndex < 0 {
					return ErrInvalidLengthJobs
				}
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				var elementCount int
				var count int
				for _, integer := range dAtA[iNdEx:postIndex] {
					if integer < 128 {
						count++
					}
				}
				elementCount = count
				if elementCount != 0 {
					if m.DescriptorIDs == nil {
						m.DescriptorIDs = make([]github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID, 0, elementCount)
					} else {
						m.DescriptorIDs = slices.Grow(m.DescriptorIDs, elementCount)
					}
				}
				for iNdEx < postIndex {
					var v github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowJobs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= github_com_cockroachdb_cockroach_pkg_sql_catalog_descpb.ID(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.DescriptorIDs = append(m.DescriptorIDs, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DescriptorIDs", wireType)
			}
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Error", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Error = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Backup", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_Backup
				field BackupDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.Backup = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Restore", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_Restore
				field RestoreDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.Restore = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 12:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SchemaChange", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_SchemaChange
				field SchemaChangeDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.SchemaChange = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 13:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Import", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_Import
				field ImportDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.Import = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 14:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Changefeed", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_Changefeed
				field ChangefeedDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.Changefeed = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CreateStats", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_CreateStats
				field CreateStatsDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.CreateStats = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 16:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Statement", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Statement = append(m.Statement, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 17:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ResumeErrors", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ResumeErrors = append(m.ResumeErrors, &errorspb.EncodedError{})
			if err := m.ResumeErrors[len(m.ResumeErrors)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 18:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CleanupErrors", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.CleanupErrors = append(m.CleanupErrors, &errorspb.EncodedError{})
			if err := m.CleanupErrors[len(m.CleanupErrors)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 19:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field FinalResumeError", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.FinalResumeError == nil {
				m.FinalResumeError = &errorspb.EncodedError{}
			}
			if err := m.FinalResumeError.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 20:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Noncancelable", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Noncancelable = bool(v != 0)
		case 21:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SchemaChangeGC", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_SchemaChangeGC
				field SchemaChangeGCDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.SchemaChangeGC = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 22:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TypeSchemaChange", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_TypeSchemaChange
				field TypeSchemaChangeDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.TypeSchemaChange = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 23:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StreamIngestion", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_StreamIngestion
				field StreamIngestionDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.StreamIngestion = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 24:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field NewSchemaChange", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_NewSchemaChange
				field NewSchemaChangeDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.NewSchemaChange = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 25:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Migration", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_Migration
				field MigrationDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.Migration = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 27:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AutoSpanConfigReconciliation", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_AutoSpanConfigReconciliation
				field AutoSpanConfigReconciliationDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.AutoSpanConfigReconciliation = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 28:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field PauseReason", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.PauseReason = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 30:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AutoSQLStatsCompaction", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_AutoSQLStatsCompaction
				field AutoSQLStatsCompactionDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.AutoSQLStatsCompaction = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 33:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StreamReplication", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_StreamReplication
				field StreamReplicationDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.StreamReplication = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 34:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RowLevelTTL", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_RowLevelTTL
				field RowLevelTTLDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.RowLevelTTL = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 35:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CreationClusterID", wireType)
			}
			var byteLen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				byteLen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if byteLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + byteLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.CreationClusterID.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 36:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CreationClusterVersion", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.CreationClusterVersion.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 37:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SchemaTelemetry", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_SchemaTelemetry
				field SchemaTelemetryDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.SchemaTelemetry = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 38:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field KeyVisualizerDetails", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_KeyVisualizerDetails
				field KeyVisualizerDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.KeyVisualizerDetails = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 39:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field PollJobsStats", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_PollJobsStats
				field PollJobsStatsDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.PollJobsStats = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 40:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field MaximumPTSAge", wireType)
			}
			m.MaximumPTSAge = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.MaximumPTSAge |= time.Duration(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 41:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AutoConfigRunner", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_AutoConfigRunner
				field AutoConfigRunnerDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.AutoConfigRunner = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 42:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AutoConfigEnvRunner", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_AutoConfigEnvRunner
				field AutoConfigEnvRunnerDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.AutoConfigEnvRunner = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 43:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AutoConfigTask", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_AutoConfigTask
				field AutoConfigTaskDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.AutoConfigTask = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 44:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AutoUpdateSqlActivities", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_AutoUpdateSqlActivities
				field AutoUpdateSQLActivityDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.AutoUpdateSqlActivities = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 45:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field MvccStatisticsDetails", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_MvccStatisticsDetails
				field MVCCStatisticsJobDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.MvccStatisticsDetails = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 46:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ImportRollbackDetails", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_ImportRollbackDetails
				field ImportRollbackDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.ImportRollbackDetails = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 47:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field HistoryRetentionDetails", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_HistoryRetentionDetails
				field HistoryRetentionDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.HistoryRetentionDetails = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 48:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field LogicalReplicationDetails", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_LogicalReplicationDetails
				field LogicalReplicationDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.LogicalReplicationDetails = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 49:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field UpdateTableMetadataCacheDetails", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_UpdateTableMetadataCacheDetails
				field UpdateTableMetadataCacheDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.UpdateTableMetadataCacheDetails = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 50:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StandbyReadTsPollerDetails", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_StandbyReadTsPollerDetails
				field StandbyReadTSPollerDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.StandbyReadTsPollerDetails = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 51:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SqlActivityFlushDetails", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_SqlActivityFlushDetails
				field SqlActivityFlushDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.SqlActivityFlushDetails = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 52:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field HotRangesLoggerDetails", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_HotRangesLoggerDetails
				field HotRangesLoggerDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.HotRangesLoggerDetails = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 53:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InspectDetails", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Payload_InspectDetails
				field InspectDetails
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.InspectDetails = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *Progress) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Progress: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Progress: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field FractionCompleted", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			v = uint32(encoding_binary.LittleEndian.Uint32(dAtA[iNdEx:]))
			iNdEx += 4
			m.Progress = &Progress_FractionCompleted{float32(math.Float32frombits(v))}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ModifiedMicros", wireType)
			}
			m.ModifiedMicros = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ModifiedMicros |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field HighWater", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_HighWater
				field hlc.Timestamp
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.HighWater = &alloc.field
			m.Progress = &alloc.value
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StatusMessage", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.StatusMessage = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Backup", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_Backup
				field BackupProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.Backup = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Restore", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_Restore
				field RestoreProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.Restore = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 12:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SchemaChange", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_SchemaChange
				field SchemaChangeProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.SchemaChange = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 13:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Import", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_Import
				field ImportProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.Import = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 14:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Changefeed", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_Changefeed
				field ChangefeedProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.Changefeed = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CreateStats", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_CreateStats
				field CreateStatsProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.CreateStats = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 16:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SchemaChangeGC", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_SchemaChangeGC
				field SchemaChangeGCProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.SchemaChangeGC = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 17:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TypeSchemaChange", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_TypeSchemaChange
				field TypeSchemaChangeProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.TypeSchemaChange = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 18:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StreamIngest", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_StreamIngest
				field StreamIngestionProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.StreamIngest = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 19:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field NewSchemaChange", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_NewSchemaChange
				field NewSchemaChangeProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.NewSchemaChange = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 20:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Migration", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_Migration
				field MigrationProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.Migration = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 21:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TraceID", wireType)
			}
			m.TraceID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TraceID |= github_com_cockroachdb_cockroach_pkg_util_tracing_tracingpb.TraceID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 22:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AutoSpanConfigReconciliation", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_AutoSpanConfigReconciliation
				field AutoSpanConfigReconciliationProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.AutoSpanConfigReconciliation = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 23:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AutoSQLStatsCompaction", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_AutoSQLStatsCompaction
				field AutoSQLStatsCompactionProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.AutoSQLStatsCompaction = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 24:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StreamReplication", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_StreamReplication
				field StreamReplicationProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.StreamReplication = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 25:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RowLevelTTL", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_RowLevelTTL
				field RowLevelTTLProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.RowLevelTTL = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 26:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SchemaTelemetry", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_SchemaTelemetry
				field SchemaTelemetryProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.SchemaTelemetry = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 27:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field KeyVisualizerProgress", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_KeyVisualizerProgress
				field KeyVisualizerProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.KeyVisualizerProgress = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 28:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field PollJobsStats", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_PollJobsStats
				field PollJobsStatsProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.PollJobsStats = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 29:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AutoConfigRunner", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_AutoConfigRunner
				field AutoConfigRunnerProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.AutoConfigRunner = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 30:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AutoConfigEnvRunner", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_AutoConfigEnvRunner
				field AutoConfigEnvRunnerProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.AutoConfigEnvRunner = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 31:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AutoConfigTask", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_AutoConfigTask
				field AutoConfigTaskProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.AutoConfigTask = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 32:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field UpdateSqlActivity", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_UpdateSqlActivity
				field AutoUpdateSQLActivityProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.UpdateSqlActivity = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 33:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field MvccStatisticsProgress", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_MvccStatisticsProgress
				field MVCCStatisticsJobProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.MvccStatisticsProgress = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 34:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ImportRollbackProgress", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_ImportRollbackProgress
				field ImportRollbackProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.ImportRollbackProgress = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 35:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field HistoryRetentionProgress", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_HistoryRetentionProgress
				field HistoryRetentionProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.HistoryRetentionProgress = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 36:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field LogicalReplication", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_LogicalReplication
				field LogicalReplicationProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.LogicalReplication = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 37:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TableMetadataCache", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_TableMetadataCache
				field UpdateTableMetadataCacheProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.TableMetadataCache = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 38:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StandbyReadTsPoller", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_StandbyReadTsPoller
				field StandbyReadTSPollerProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.StandbyReadTsPoller = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 39:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SqlActivityFlush", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_SqlActivityFlush
				field SqlActivityFlushProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.SqlActivityFlush = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 40:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field HotRangesLogger", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_HotRangesLogger
				field HotRangesLoggerProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.HotRangesLogger = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		case 41:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Inspect", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			alloc := new(struct {
				value Progress_Inspect
				field InspectProgress
			})
			if err := alloc.field.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			alloc.value.Inspect = &alloc.field
			m.Details = &alloc.value
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *Job) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Job: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Job: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Id", wireType)
			}
			m.Id = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Id |= JobID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Progress", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Progress == nil {
				m.Progress = &Progress{}
			}
			if err := m.Progress.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Payload", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Payload == nil {
				m.Payload = &Payload{}
			}
			if err := m.Payload.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *RetriableExecutionFailure) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: RetriableExecutionFailure: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: RetriableExecutionFailure: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Status", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Status = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExecutionStartMicros", wireType)
			}
			m.ExecutionStartMicros = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ExecutionStartMicros |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExecutionEndMicros", wireType)
			}
			m.ExecutionEndMicros = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ExecutionEndMicros |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InstanceID", wireType)
			}
			m.InstanceID = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.InstanceID |= github_com_cockroachdb_cockroach_pkg_base.SQLInstanceID(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Error", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Error == nil {
				m.Error = &errorspb.EncodedError{}
			}
			if err := m.Error.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TruncatedError", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TruncatedError = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *TraceData) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: TraceData: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: TraceData: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CollectedSpans", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthJobs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthJobs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.CollectedSpans = append(m.CollectedSpans, tracingpb.RecordedSpan{})
			if err := m.CollectedSpans[len(m.CollectedSpans)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipJobs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthJobs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipJobs(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	depth := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowJobs
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
		case 1:
			iNdEx += 8
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowJobs
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if length < 0 {
				return 0, ErrInvalidLengthJobs
			}
			iNdEx += length
		case 3:
			depth++
		case 4:
			if depth == 0 {
				return 0, ErrUnexpectedEndOfGroupJobs
			}
			depth--
		case 5:
			iNdEx += 4
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
		if iNdEx < 0 {
			return 0, ErrInvalidLengthJobs
		}
		if depth == 0 {
			return iNdEx, nil
		}
	}
	return 0, io.ErrUnexpectedEOF
}

var (
	ErrInvalidLengthJobs        = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowJobs          = fmt.Errorf("proto: integer overflow")
	ErrUnexpectedEndOfGroupJobs = fmt.Errorf("proto: unexpected end of group")
)

